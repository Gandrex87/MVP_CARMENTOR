# Mentor: Agente IA Recomendador de Veh√≠culos con LangGraph üöóüí¨

Este repositorio contiene el c√≥digo fuente de "Mentor", un agente conversacional basado en LLMs (Modelos Grandes de Lenguaje) construido con Python y el framework **LangGraph**. El objetivo principal del agente es entender las necesidades, preferencias y situaci√≥n econ√≥mica de un usuario a trav√©s de una conversaci√≥n turno a turno para, finalmente, poder recomendarle tipos de veh√≠culos que se ajusten a su perfil.

## ‚ú® Caracter√≠sticas Principales

* **Conversaci√≥n Multi-Turno:** Mantiene el contexto y recopila informaci√≥n a lo largo de varios intercambios con el usuario.
* **Recopilaci√≥n Estructurada de Datos:** Utiliza LLMs con salida estructurada (validada por Pydantic) para extraer informaci√≥n clave en diferentes etapas.
* **Flujo Multi-Etapa:** La conversaci√≥n sigue un flujo l√≥gico definido:
    1.  **Perfil de Usuario:** Recopila preferencias generales (altura, peso, uso profesional, est√©tica, el√©ctricos, transmisi√≥n, pasi√≥n por motor, nivel de aventura).
    2.  **Filtros T√©cnicos:** Infiere filtros t√©cnicos basados en el perfil (batalla m√≠nima, √≠ndice altura interior, est√©tica m√≠nima, tipo de mec√°nica, premium/singularidad m√≠nima).
    3.  **Perfil Econ√≥mico:** Recopila informaci√≥n econ√≥mica seg√∫n dos modos (asesoramiento financiero o presupuesto definido por el usuario).
    4.  **Finalizaci√≥n y Recomendaci√≥n:**
        * Utiliza **RAG (Retrieval-Augmented Generation)** sobre un documento PDF para recomendar tipos de carrocer√≠a adecuados.
        * Calcula **pesos num√©ricos** basados en las preferencias para una posible ponderaci√≥n futura de recomendaciones.
        * Presenta un **resumen final** en formato tabla Markdown.
* **Manejo Robusto de Conversaci√≥n:** Implementa el patr√≥n "Nodo Pregunta -> END" en LangGraph para asegurar un flujo conversacional estable turno a turno, incluso cuando se requieren aclaraciones.
* **Manejo de Errores:** Captura errores de validaci√≥n de los LLMs y solicita aclaraciones al usuario.
* **Modularidad:** C√≥digo organizado en m√≥dulos para el grafo, utilidades (procesamiento, validaci√≥n, formato, RAG, pesos), prompts y estado.
* **Pruebas Unitarias:** Incluye pruebas (usando `pytest` y `unittest.mock`) para verificar la l√≥gica de los nodos individuales del grafo.

## üèóÔ∏è Arquitectura y Tecnolog√≠as

El agente est√° construido sobre **LangGraph**, una extensi√≥n de LangChain para crear aplicaciones LLM stateful y c√≠clicas.

* **Orquestaci√≥n:** Se utiliza `langgraph.graph.StateGraph` para definir el flujo de la aplicaci√≥n.
* **Estado:** El estado de la conversaci√≥n se gestiona con un `TypedDict` que contiene modelos Pydantic (`PerfilUsuario`, `FiltrosInferidos`, `EconomiaUsuario`) y el historial de mensajes (`add_messages`).
* **Nodos:** Funciones Python que encapsulan la l√≥gica de cada paso (llamar a LLMs, validar, aplicar reglas, preguntar, finalizar).
* **Aristas:** Conexiones entre nodos, incluyendo `add_edge` (flujo directo) y `add_conditional_edges` (enrutamiento basado en el estado y funciones de validaci√≥n).
* **LLMs:** Se integra con modelos de OpenAI (inicialmente `gpt-4o-mini`, con posibilidad de usar `gpt-4o` para tareas complejas como la econom√≠a) a trav√©s de LangChain. Se utiliza `with_structured_output` para obtener respuestas JSON validadas con Pydantic.
* **RAG:** Utiliza `pdfplumber` para leer datos de carrocer√≠as desde un PDF, `langchain_openai.OpenAIEmbeddings` para generar embeddings y `langchain_community.vectorstores.FAISS` para crear y consultar un almac√©n vectorial.
* **Persistencia:** Utiliza `langgraph.checkpoint.memory.MemorySaver` para mantener el estado de la conversaci√≥n en memoria (adecuado para desarrollo/pruebas).
* **Pruebas:** `pytest` y `unittest.mock`.
* **Otros:** Pydantic (modelado de datos y validaci√≥n), Python est√°ndar.

## üìÇ Estructura del Proyecto (Ejemplo)

```python
‚îú‚îÄ‚îÄ graph/                  # L√≥gica principal del grafo LangGraph
‚îÇ   ‚îú‚îÄ‚îÄ perfil/             # Nodos, builder, state, etc. espec√≠ficos (o todo junto)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ builder.py      # Define y compila el StateGraph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes.py        # Funciones de los nodos (recopilar, validar, preguntar, inferir, finalizar)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py        # Definici√≥n del TypedDict y modelos Pydantic (Perfil, Filtros, Economia, Resultados LLM)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ memory.py       # Configuraci√≥n del checkpointer (MemorySaver)
‚îÇ   ‚îî‚îÄ‚îÄ init.py
‚îú‚îÄ‚îÄ utils/                  # Funciones de utilidad reutilizables
‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îú‚îÄ‚îÄ conversion.py     # Funciones de normalizaci√≥n, is_yes, get_enum_names
‚îÇ   ‚îú‚îÄ‚îÄ enums.py          # Definiciones de los Enums (TipoMecanica, NivelAventura, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ formatters.py     # formatear_preferencias_en_tabla
‚îÇ   ‚îú‚îÄ‚îÄ postprocessing.py # aplicar_postprocesamiento_perfil, aplicar_postprocesamiento_filtros
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py  # (Opcional) extraer_preferencias_iniciales
‚îÇ   ‚îú‚îÄ‚îÄ rag_carroceria.py # L√≥gica RAG para obtener carrocer√≠as
‚îÇ   ‚îú‚îÄ‚îÄ rag_reader.py     # Lector del PDF para RAG
‚îÇ   ‚îú‚îÄ‚îÄ validation.py     # Funciones check_*_completeness
‚îÇ   ‚îî‚îÄ‚îÄ weights.py        # L√≥gica para calcular pesos
‚îú‚îÄ‚îÄ prompts/                # Archivos de texto con los prompts del sistema
‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îú‚îÄ‚îÄ loader.py         # (Opcional) L√≥gica para cargar prompts
‚îÇ   ‚îú‚îÄ‚îÄ system_prompt_perfil.txt
‚îÇ   ‚îú‚îÄ‚îÄ system_prompt_filtros_template.txt
‚îÇ   ‚îî‚îÄ‚îÄ system_prompt_economia_structured.txt
‚îú‚îÄ‚îÄ tests/                  # Pruebas unitarias/integraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îú‚îÄ‚îÄ test_nodes.py       # Pruebas para los nodos del grafo
‚îÇ   ‚îú‚îÄ‚îÄ test_utils.py       # Pruebas para funciones de utilidad (opcional)
‚îÇ   ‚îî‚îÄ‚îÄ test_formatters.py  # Pruebas para la funci√≥n de formato
‚îú‚îÄ‚îÄ .env                    # Archivo para variables de entorno (¬°a√±adir a .gitignore!)
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias del proyecto
‚îú‚îÄ‚îÄ main_conversation.py    # (Ejemplo) Script principal para interactuar con el agente
‚îî‚îÄ‚îÄ README.md               # Este archivo
```

## üìà Estado Actual

* El flujo secuencial del grafo (Perfil -> Filtros -> Econom√≠a -> Finalizaci√≥n) est√° implementado y funcional.
* Los nodos individuales y las funciones de utilidad clave tienen pruebas unitarias que pasan.
* El patr√≥n "Nodo Pregunta -> END" asegura una conversaci√≥n estable turno a turno.
* El manejo de errores para ValidationErrors del LLM de econom√≠a est√° implementado.
√Åreas de Mejora / Pr√≥ximos Pasos:
Fiabilidad LLM Econom√≠a: Monitorizar y potencialmente seguir afinando el prompt system_prompt_economia_structured.txt o confirmar que el modelo m√°s potente (gpt-4o) resuelve los ValidationError de forma consistente.
* Calidad RAG: Revisar la l√≥gica de construcci√≥n de la query y los resultados de get_recommended_carrocerias para asegurar que las recomendaciones de carrocer√≠a sean pertinentes.
* L√≥gica de Pesos: Validar si el c√°lculo de pesos refleja adecuadamente la importancia de los atributos.
* Pruebas End-to-End: Realizar m√°s pruebas de conversaci√≥n completas con diferentes perfiles de usuario.





Aqu√≠ te explico los conceptos clave para lograr eso, sin entrar a√∫n en el c√≥digo espec√≠fico:

1. Lograr Mayor Variedad en las Preguntas del Agente:

El problema actual es que, para asegurar la robustez, hemos tendido a "forzar" preguntas espec√≠ficas (ya sea mediante los templates de _obtener_siguiente_pregunta_perfil o las instrucciones muy directas en <Reglas_Preguntas_Especificas> de los prompts). Para m√°s naturalidad:

A) Ingenier√≠a de Prompts Menos R√≠gida:

Instrucci√≥n: En lugar de "Usa esta pregunta EXACTA...", podr√≠as instruir al LLM (ej: llm_solo_perfil) de forma m√°s general: "Detecta qu√© informaci√≥n clave falta (ej: 'preferencia de transmisi√≥n'). Formula una pregunta amigable y natural para obtenerla. Puedes variar la formulaci√≥n, pero aseg√∫rate de que quede claro qu√© necesitas saber."
Ejemplos: Aseg√∫rate de que los ejemplos en el prompt muestren diferentes formas de preguntar por la misma cosa.
Ventaja: Aprovecha la capacidad del LLM para generar lenguaje natural.
Desventaja: Pierdes algo de control. El LLM podr√≠a generar una pregunta ambigua o menos efectiva. Requiere ajustar y probar el prompt hasta que funcione bien consistentemente.
B) M√∫ltiples Plantillas (Menos IA, M√°s Control):

Idea: En lugar de una pregunta fija en _obtener_siguiente_pregunta_perfil (nuestro fallback actual) o en las <Reglas_Preguntas_Especificas>, podr√≠as tener una lista de 3-4 variaciones para cada pregunta clave.
Implementaci√≥n: La funci√≥n Python (_obtener_siguiente_pregunta_perfil o una nueva) elegir√≠a una plantilla al azar de la lista correspondiente al campo faltante.
Ventaja: Tienes control total sobre las posibles preguntas.
Desventaja: M√°s trabajo manual para crear las plantillas. La variedad sigue siendo limitada a tus plantillas pre-escritas.
C) LLM dedicado a Re-formular (M√°s IA, M√°s Coste/Latencia):

Idea: Mantener la l√≥gica que detecta qu√© falta (ej: _obtener_siguiente_pregunta_perfil te dice que falta apasionado_motor y la pregunta base es "¬øEres un apasionado...?"). Luego, hacer una llamada r√°pida a un LLM "creativo" (quiz√°s llm_validacion con temperatura m√°s alta) dici√©ndole: "Reformula esta pregunta de forma m√°s conversacional: '¬øEres un apasionado del motor?'".
Ventaja: Mucha variedad y naturalidad potencial.
Desventaja: A√±ade una llamada LLM extra en cada turno de pregunta, incrementando coste y latencia.
Recomendaci√≥n Conceptual: Empezar√≠a probando la Opci√≥n A (Prompt Menos R√≠gido). Dale un poco m√°s de libertad al llm_solo_perfil (y similares) para formular las preguntas en contenido_mensaje, pero monitoriza de cerca si sigue siendo efectivo en obtener la informaci√≥n necesaria.

2. Manejar Preguntas Contextuales del Usuario:

Este es un desaf√≠o mayor pero fundamental para simular a un vendedor. El agente necesita poder salirse moment√°neamente del flujo de recopilaci√≥n para responder dudas.

A) Detecci√≥n de Intenci√≥n + Enrutamiento (El Enfoque M√°s Robusto):

Clasificar Entrada: Al inicio de cada nodo principal (recopilar_preferencias, recopilar_economia, etc.) o en un nuevo nodo inicial, a√±ade un paso para clasificar la intenci√≥n del √∫ltimo mensaje del usuario:
¬øEs una respuesta directa a mi √∫ltima pregunta?
¬øEs una pregunta sobre coches/finanzas/proceso?
¬øEs una petici√≥n para cambiar algo ya dicho?
¬øEs charla irrelevante? (Esto podr√≠a hacerse con otro LLM clasificador o con reglas heur√≠sticas si las preguntas son predecibles).
Nueva Condici√≥n: A√±ade una arista condicional basada en esta intenci√≥n.
Nodo/L√≥gica de Respuesta a Preguntas: Si la intenci√≥n es una pregunta del usuario ("¬ødiferencia h√≠brido/el√©ctrico?"), redirige el flujo a un nuevo nodo especializado: responder_pregunta_usuario_node.
Implementaci√≥n del Nodo de Respuesta: Este nodo usar√≠a un LLM generalista (llm base), posiblemente apoyado por RAG sobre una base de conocimiento espec√≠fica del sector automotriz que t√∫ le proporciones (¬°podr√≠as crearla!), o incluso una herramienta (Tool) que busque en la web. Generar√≠a la respuesta a la duda del usuario.
Volver al Flujo: Despu√©s de responder, este nodo necesita a√±adir la respuesta al historial y luego decidir c√≥mo continuar. Lo m√°s seguro es redirigir de vuelta al nodo que hizo la pregunta original (ej: preguntar_preferencias_node) para que repita la pregunta que hab√≠a quedado pendiente antes de que el usuario preguntara su duda. Esto asegura que no se pierda el objetivo principal de recopilar informaci√≥n.
B) Integrar en Prompts Principales (Menos Robusto):

Idea: Modificar los prompts de llm_solo_perfil, llm_solo_filtros, etc., para que tambi√©n intenten detectar y responder preguntas del usuario antes de extraer datos o hacer su propia pregunta.
Desventaja: Sobrecarga la tarea del LLM, aumenta la probabilidad de errores en la extracci√≥n de datos o en la respuesta a la pregunta. El control del flujo es mucho menor.
C) Usar Herramientas (Tools) de LangChain/LangGraph:

Idea: Si la respuesta a la pregunta del usuario requiere buscar informaci√≥n externa (tu base de conocimiento RAG, web), puedes definir esto como una "Herramienta". El LLM principal (llm_solo_perfil, etc.) puede ser instruido para que, si detecta una pregunta, en lugar de responderla √©l mismo, decida llamar a la herramienta apropiada. LangGraph tiene nodos espec√≠ficos (ToolNode, ToolExecutor) para manejar esto.
Ventaja: Arquitectura muy potente y modular para agentes que necesitan interactuar con el exterior.
Desventaja: A√±ade la complejidad de definir y manejar herramientas dentro del grafo.
Recomendaci√≥n Conceptual: El enfoque A (Detecci√≥n de Intenci√≥n + Enrutamiento + Nodo de Respuesta) es el m√°s s√≥lido y escalable para manejar interrupciones y preguntas del usuario de forma controlada dentro de un flujo principal de recopilaci√≥n de datos. Usar RAG o Tools (Opci√≥n C) dentro del nodo de respuesta lo har√≠a a√∫n m√°s potente.

En resumen:

Para hacerlo m√°s conversacional, necesitas dar m√°s libertad (controlada) al LLM para variar sus preguntas (Ingenier√≠a de Prompts) y, fundamentalmente, a√±adir una capa de detecci√≥n de intenci√≥n y una ruta alternativa en tu grafo para manejar las preguntas que te haga el usuario, idealmente con un nodo dedicado que pueda acceder a conocimiento relevante (general o RAG) antes de retomar el flujo principal.

Estos cambios son significativos, pero son los que realmente elevan al agente a un nivel superior de interacci√≥n. ¬øSobre cu√°l de estos conceptos te gustar√≠a profundizar m√°s?


Fuentes y contenido relacionado
