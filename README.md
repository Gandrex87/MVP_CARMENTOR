# Mentor: Agente IA Recomendador de Veh√≠culos con LangGraph üöóüí¨

Este repositorio contiene el c√≥digo fuente de "Mentor", un agente conversacional basado en LLMs (Modelos Grandes de Lenguaje) construido con Python y el framework **LangGraph**. El objetivo principal del agente es entender las necesidades, preferencias y situaci√≥n econ√≥mica de un usuario a trav√©s de una conversaci√≥n turno a turno para, finalmente, poder recomendarle tipos de veh√≠culos que se ajusten a su perfil.

## ‚ú® Caracter√≠sticas Principales

* **Conversaci√≥n Multi-Turno:** Mantiene el contexto y recopila informaci√≥n a lo largo de varios intercambios con el usuario.
* **Recopilaci√≥n Estructurada de Datos:** Utiliza LLMs con salida estructurada (validada por Pydantic) para extraer informaci√≥n clave en diferentes etapas.
* **Flujo Multi-Etapa:** La conversaci√≥n sigue un flujo l√≥gico definido:
    1.  **Perfil de Usuario:** Recopila preferencias generales (altura, peso, uso profesional, est√©tica, el√©ctricos, transmisi√≥n, pasi√≥n por motor, nivel de aventura).
    2.  **Filtros T√©cnicos:** Infiere filtros t√©cnicos basados en el perfil (batalla m√≠nima, √≠ndice altura interior, est√©tica m√≠nima, tipo de mec√°nica, premium/singularidad m√≠nima).
    3.  **Perfil Econ√≥mico:** Recopila informaci√≥n econ√≥mica seg√∫n dos modos (asesoramiento financiero o presupuesto definido por el usuario).
    4.  **Finalizaci√≥n y Recomendaci√≥n:**
        * Utiliza **RAG (Retrieval-Augmented Generation)** sobre un documento PDF para recomendar tipos de carrocer√≠a adecuados.
        * Calcula **pesos num√©ricos** basados en las preferencias para una posible ponderaci√≥n futura de recomendaciones.
        * Presenta un **resumen final** en formato tabla Markdown.
* **Manejo Robusto de Conversaci√≥n:** Implementa el patr√≥n "Nodo Pregunta -> END" en LangGraph para asegurar un flujo conversacional estable turno a turno, incluso cuando se requieren aclaraciones.
* **Manejo de Errores:** Captura errores de validaci√≥n de los LLMs y solicita aclaraciones al usuario.
* **Modularidad:** C√≥digo organizado en m√≥dulos para el grafo, utilidades (procesamiento, validaci√≥n, formato, RAG, pesos), prompts y estado.
* **Pruebas Unitarias:** Incluye pruebas (usando `pytest` y `unittest.mock`) para verificar la l√≥gica de los nodos individuales del grafo.

## üèóÔ∏è Arquitectura y Tecnolog√≠as

El agente est√° construido sobre **LangGraph**, una extensi√≥n de LangChain para crear aplicaciones LLM stateful y c√≠clicas.

* **Orquestaci√≥n:** Se utiliza `langgraph.graph.StateGraph` para definir el flujo de la aplicaci√≥n.
* **Estado:** El estado de la conversaci√≥n se gestiona con un `TypedDict` que contiene modelos Pydantic (`PerfilUsuario`, `FiltrosInferidos`, `EconomiaUsuario`) y el historial de mensajes (`add_messages`).
* **Nodos:** Funciones Python que encapsulan la l√≥gica de cada paso (llamar a LLMs, validar, aplicar reglas, preguntar, finalizar).
* **Aristas:** Conexiones entre nodos, incluyendo `add_edge` (flujo directo) y `add_conditional_edges` (enrutamiento basado en el estado y funciones de validaci√≥n).
* **LLMs:** Se integra con modelos de OpenAI (inicialmente `gpt-4o-mini`, con posibilidad de usar `gpt-4o` para tareas complejas como la econom√≠a) a trav√©s de LangChain. Se utiliza `with_structured_output` para obtener respuestas JSON validadas con Pydantic.
* **RAG:** Utiliza `pdfplumber` para leer datos de carrocer√≠as desde un PDF, `langchain_openai.OpenAIEmbeddings` para generar embeddings y `langchain_community.vectorstores.FAISS` para crear y consultar un almac√©n vectorial.
* **Persistencia:** Utiliza `langgraph.checkpoint.memory.MemorySaver` para mantener el estado de la conversaci√≥n en memoria (adecuado para desarrollo/pruebas).
* **Pruebas:** `pytest` y `unittest.mock`.
* **Otros:** Pydantic (modelado de datos y validaci√≥n), Python est√°ndar.

## üìÇ Estructura del Proyecto (Ejemplo)

```python
‚îú‚îÄ‚îÄ graph/                  # L√≥gica principal del grafo LangGraph
‚îÇ   ‚îú‚îÄ‚îÄ perfil/             # Nodos, builder, state, etc. espec√≠ficos (o todo junto)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ builder.py      # Define y compila el StateGraph
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ nodes.py        # Funciones de los nodos (recopilar, validar, preguntar, inferir, finalizar)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ state.py        # Definici√≥n del TypedDict y modelos Pydantic (Perfil, Filtros, Economia, Resultados LLM)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ memory.py       # Configuraci√≥n del checkpointer (MemorySaver)
‚îÇ   ‚îî‚îÄ‚îÄ init.py
‚îú‚îÄ‚îÄ utils/                  # Funciones de utilidad reutilizables
‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îú‚îÄ‚îÄ conversion.py     # Funciones de normalizaci√≥n, is_yes, get_enum_names
‚îÇ   ‚îú‚îÄ‚îÄ enums.py          # Definiciones de los Enums (TipoMecanica, NivelAventura, etc.)
‚îÇ   ‚îú‚îÄ‚îÄ formatters.py     # formatear_preferencias_en_tabla
‚îÇ   ‚îú‚îÄ‚îÄ postprocessing.py # aplicar_postprocesamiento_perfil, aplicar_postprocesamiento_filtros
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py  # (Opcional) extraer_preferencias_iniciales
‚îÇ   ‚îú‚îÄ‚îÄ rag_carroceria.py # L√≥gica RAG para obtener carrocer√≠as
‚îÇ   ‚îú‚îÄ‚îÄ rag_reader.py     # Lector del PDF para RAG
‚îÇ   ‚îú‚îÄ‚îÄ validation.py     # Funciones check_*_completeness
‚îÇ   ‚îî‚îÄ‚îÄ weights.py        # L√≥gica para calcular pesos
‚îú‚îÄ‚îÄ prompts/                # Archivos de texto con los prompts del sistema
‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îú‚îÄ‚îÄ loader.py         # (Opcional) L√≥gica para cargar prompts
‚îÇ   ‚îú‚îÄ‚îÄ system_prompt_perfil.txt
‚îÇ   ‚îú‚îÄ‚îÄ system_prompt_filtros_template.txt
‚îÇ   ‚îî‚îÄ‚îÄ system_prompt_economia_structured.txt
‚îú‚îÄ‚îÄ tests/                  # Pruebas unitarias/integraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ init.py
‚îÇ   ‚îú‚îÄ‚îÄ test_nodes.py       # Pruebas para los nodos del grafo
‚îÇ   ‚îú‚îÄ‚îÄ test_utils.py       # Pruebas para funciones de utilidad (opcional)
‚îÇ   ‚îî‚îÄ‚îÄ test_formatters.py  # Pruebas para la funci√≥n de formato
‚îú‚îÄ‚îÄ .env                    # Archivo para variables de entorno (¬°a√±adir a .gitignore!)
‚îú‚îÄ‚îÄ requirements.txt        # Dependencias del proyecto
‚îú‚îÄ‚îÄ main_conversation.py    # (Ejemplo) Script principal para interactuar con el agente
‚îî‚îÄ‚îÄ README.md               # Este archivo
```

## üìà Estado Actual

* El flujo secuencial del grafo (Perfil -> Filtros -> Econom√≠a -> Finalizaci√≥n) est√° implementado y funcional.
* Los nodos individuales y las funciones de utilidad clave tienen pruebas unitarias que pasan.
* El patr√≥n "Nodo Pregunta -> END" asegura una conversaci√≥n estable turno a turno.
* El manejo de errores para ValidationErrors del LLM de econom√≠a est√° implementado.
√Åreas de Mejora / Pr√≥ximos Pasos:
Fiabilidad LLM Econom√≠a: Monitorizar y potencialmente seguir afinando el prompt system_prompt_economia_structured.txt o confirmar que el modelo m√°s potente (gpt-4o) resuelve los ValidationError de forma consistente.
* Calidad RAG: Revisar la l√≥gica de construcci√≥n de la query y los resultados de get_recommended_carrocerias para asegurar que las recomendaciones de carrocer√≠a sean pertinentes.
* L√≥gica de Pesos: Validar si el c√°lculo de pesos refleja adecuadamente la importancia de los atributos.
* Pruebas End-to-End: Realizar m√°s pruebas de conversaci√≥n completas con diferentes perfiles de usuario.
  
## Pensando en pasos futuros para despliegue

¬°Excelente! Pensar en c√≥mo llevar tu agente a producci√≥n es un paso muy importante. Usar FastAPI y luego desplegarlo en Cloud Run es una excelente elecci√≥n y una ruta muy com√∫n y efectiva para aplicaciones basadas en Python como la tuya.

Aqu√≠ te presento un desglose conceptual de c√≥mo ser√≠a ese proceso y qu√© implicaciones tendr√≠a:

Hoja de Ruta Conceptual para la Puesta en Producci√≥n:

### Encapsular la L√≥gica del Agente:

Tu grafo LangGraph (build_sequential_agent_graph()) y la l√≥gica de conversaci√≥n (run_conversation o una versi√≥n adaptada) necesitan ser accesibles de una forma que una API pueda llamar.

* Crear una API con FastAPI:

  * Prop√≥sito: FastAPI actuar√° como la "puerta de entrada" a tu agente. Recibir√° solicitudes HTTP (por ejemplo, de un frontend, una app m√≥vil, u otro servicio) y las pasar√° a tu agente LangGraph.
  * Endpoints Clave:
POST /conversation/start: Podr√≠a iniciar una nueva conversaci√≥n, generar un thread_id (si no se proporciona uno) y devolver el primer mensaje del agente.
POST /conversation/{thread_id}/message: Recibe un mensaje del usuario para un thread_id existente, lo pasa al grafo LangGraph, y devuelve la respuesta del agente.
  * (Opcional) GET /conversation/{thread_id}/history: Para recuperar el historial de una conversaci√≥n.
  * Manejo de Estado: La persistencia de la conversaci√≥n (el thread_id y el estado asociado) es crucial.
  * Checkpointer: El MemorySaver que usamos para desarrollo no es adecuado para producci√≥n porque se pierde si la instancia se reinicia. Necesitar√°s un checkpointer persistente. LangGraph ofrece integraciones con:
Redis: Muy buena opci√≥n para estado en memoria r√°pido y persistente.
PostgreSQL/SQLite (con SqliteSaver o PgSaver): Buenas si ya tienes una base de datos relacional o quieres una soluci√≥n basada en archivos para empezar.
LangServe: Aunque LangServe puede desplegar grafos LangGraph directamente, si quieres m√°s control con FastAPI, usar√≠as un checkpointer compatible.
El thread_id ser√° la clave para recuperar y guardar el estado de cada conversaci√≥n.

* Contenerizaci√≥n con Docker:

  * Prop√≥sito: Empaquetar tu aplicaci√≥n FastAPI (junto con todas sus dependencias Python, tu c√≥digo LangGraph, prompts, etc.) en una imagen de contenedor Docker. Esto asegura que funcione de manera consistente en cualquier entorno.
Dockerfile: Definir√°s las instrucciones para construir la imagen (instalar Python, copiar tu c√≥digo, instalar requirements.txt, exponer el puerto de FastAPI, y el comando para iniciar el servidor Uvicorn con FastAPI).
requirements.txt: Debe listar todas las librer√≠as necesarias (fastapi, uvicorn, langgraph, langchain, langchain-openai, google-cloud-bigquery, python-dotenv, etc.).

* Despliegue en Cloud Run:

  * Prop√≥sito: Cloud Run es una plataforma serverless de Google Cloud que ejecuta contenedores Docker. Es ideal porque escala autom√°ticamente (incluso a cero si no hay tr√°fico, ahorrando costes) y gestiona la infraestructura por ti.

  * Pasos:
    * Construir y Subir la Imagen Docker: Construyes tu imagen Docker localmente y la subes a un registro de contenedores como Google Artifact Registry (o Google Container Registry).
    * Crear un Servicio en Cloud Run: Configuras un nuevo servicio en Cloud Run, apuntando a la imagen Docker que subiste.

* Configuraci√≥n:
  * Variables de Entorno: Configura variables de entorno en Cloud Run para tus secretos (como OPENAI_API_KEY, credenciales de BQ si no usas ADC del entorno, configuraci√≥n del checkpointer persistente).
  * Conexi√≥n a BigQuery: Si tu Cloud Run necesita acceder a BigQuery, aseg√∫rate de que la cuenta de servicio que usa Cloud Run tenga los permisos necesarios para BigQuery.
  * Conexi√≥n al Checkpointer Persistente: Si usas Redis o una base de datos SQL para el checkpointer, Cloud Run necesitar√° poder conectarse a esa instancia (ej: a trav√©s de VPC Connector si est√° en una red privada).
CPU y Memoria: Ajusta los recursos seg√∫n la carga esperada.
Escalado: Configura el m√≠nimo y m√°ximo de instancias.
URL P√∫blica: Cloud Run te dar√° una URL HTTPS p√∫blica para acceder a tu API.
  * (Opcional pero Recomendado) API Gateway / Load Balancer:
Para mayor seguridad, gesti√≥n de tr√°fico, SSL personalizado, etc., podr√≠as poner Google Cloud API Gateway o un Load Balancer delante de tu servicio Cloud Run.

* Consideraciones Adicionales:

  * Manejo de Errores en la API: Tu API FastAPI debe manejar errores de forma elegante (ej: si el grafo falla, si un thread_id no existe) y devolver c√≥digos de estado HTTP apropiados.
  * Seguridad de la API: Considera c√≥mo asegurar√°s tus endpoints (ej: claves API, autenticaci√≥n si es necesario).
Logging y Monitorizaci√≥n en Producci√≥n: Cloud Run se integra con Google Cloud Logging y Monitoring. Aseg√∫rate de que tu aplicaci√≥n FastAPI y LangGraph generen logs √∫tiles. LangSmith sigue siendo invaluable aqu√≠.
  * Costes: Ten en cuenta los costes de Cloud Run, BigQuery, el servicio de checkpointer (Redis/SQL), y las llamadas a la API de OpenAI.
  * Actualizaciones: Define un proceso para actualizar tu aplicaci√≥n (construir nueva imagen Docker, desplegar nueva revisi√≥n en Cloud Run).

### ¬øEs Complejo?

S√≠, llevar una aplicaci√≥n a producci√≥n siempre tiene su complejidad, pero la ruta FastAPI + Docker + Cloud Run es una de las m√°s directas y bien documentadas para aplicaciones Python. La mayor complejidad inicial estar√° en:

Configurar correctamente el checkpointer persistente para LangGraph.
Escribir el Dockerfile y configurar el despliegue en Cloud Run con las variables de entorno y permisos correctos.
En resumen:

Tu idea de FastAPI + Cloud Run es excelente. Es una pila tecnol√≥gica moderna, escalable y gestionada que se adapta muy bien a los agentes LangGraph. La clave ser√° manejar bien la persistencia del estado de la conversaci√≥n y la configuraci√≥n del entorno en la nube.

¬øTe gustar√≠a que profundicemos en alguno de estos puntos, por ejemplo, c√≥mo se ver√≠a un endpoint b√°sico de FastAPI o qu√© checkpointer podr√≠a ser m√°s adecuado para empezar?
