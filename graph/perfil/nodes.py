
from langchain_core.messages import HumanMessage, BaseMessage,AIMessage
from pydantic import ValidationError # Importar para manejo de errores si es necesario
from .state import (EstadoAnalisisPerfil, 
                    PerfilUsuario, ResultadoSoloPerfil , 
                    FiltrosInferidos, ResultadoSoloFiltros,
                    EconomiaUsuario,ResultadoEconomia ,
                    InfoPasajeros, ResultadoPasajeros,
                    InfoClimaUsuario, ResultadoCP, NivelAventura , FrecuenciaUso, DistanciaTrayecto, FrecuenciaViajesLargos
)
from config.llm import llm_solo_perfil, llm_economia, llm_pasajeros, llm_cp_extractor
from prompts.loader import system_prompt_perfil, prompt_economia_structured_sys_msg, system_prompt_pasajeros, system_prompt_cp
from utils.postprocessing import aplicar_postprocesamiento_perfil, aplicar_postprocesamiento_filtros
from utils.validation import check_perfil_usuario_completeness , check_economia_completa, check_pasajeros_completo
from utils.formatters import formatear_preferencias_en_tabla
from utils.weights import compute_raw_weights, normalize_weights
from utils.bigquery_tools import buscar_coches_bq
from utils.bq_data_lookups import obtener_datos_climaticos_por_cp # IMPORT para la funci√≥n de b√∫squeda de clima ---
from utils.conversion import is_yes 
from utils.bq_logger import log_busqueda_a_bigquery
from utils.sanitize_dict_for_json import sanitize_dict_for_json
import traceback
from langchain_core.runnables import RunnableConfig
import pandas as pd
import json # Para construir el contexto del prompt
from typing import Literal, Optional ,Dict, Any
from config.settings import (MAPA_RATING_A_PREGUNTA_AMIGABLE, UMBRAL_COMODIDAD_PARA_PENALIZAR_FLAGS, UMBRAL_TECNOLOGIA_PARA_PENALIZAR_ANTIGUEDAD_FLAG, UMBRAL_IMPACTO_AMBIENTAL_PARA_LOGICA_DISTINTIVO_FLAG, UMBRAL_COMODIDAD_PARA_FAVORECER_CARROCERIA)
from utils.explanation_generator import generar_explicacion_coche_mejorada # <-- NUEVO IMPORT
import logging

# --- Configuraci√≥n de Logging ---
logging.basicConfig(level=logging.DEBUG) #INFO PARA CUANDO PASE A PRODUCCION
logger = logging.getLogger(__name__) # Logger para este m√≥dulo

# En graph/nodes.py

# --- INICIO: NUEVOS NODOS PARA ETAPA DE C√ìDIGO POSTAL ---

# En graph/perfil/nodes.py
def preguntar_cp_inicial_node(state: EstadoAnalisisPerfil) -> dict:
    print("--- Ejecutando Nodo: preguntar_cp_inicial_node ---")
    mensaje_pendiente = state.get("pregunta_pendiente")
    historial_actual = state.get("messages", [])
    historial_nuevo = list(historial_actual) # Crear copia

    mensaje_a_mostrar = "Por favor, introduce tu c√≥digo postal de 5 d√≠gitos." # Fallback muy b√°sico

    if mensaje_pendiente and mensaje_pendiente.strip():
        mensaje_a_mostrar = mensaje_pendiente
        print(f"DEBUG (Preguntar CP Inicial) ‚ñ∫ Usando mensaje pendiente: {mensaje_a_mostrar}")
    else:
        # Esto podr√≠a pasar si validar_cp_node no puso un mensaje de fallback
        # cuando tipo_mensaje_cp_llm era None o inesperado.
        print("WARN (Preguntar CP Inicial) ‚ñ∫ No hab√≠a mensaje pendiente v√°lido, usando fallback.")

    ai_msg = AIMessage(content=mensaje_a_mostrar)
    if not historial_actual or historial_actual[-1].content != ai_msg.content:
        historial_nuevo.append(ai_msg)
        print(f"DEBUG (Preguntar CP Inicial) ‚ñ∫ Mensaje final a√±adido: {mensaje_a_mostrar}")
    else:
        print("DEBUG (Preguntar CP Inicial) ‚ñ∫ Mensaje duplicado, no se a√±ade.")

    # Devolver solo los campos modificados
    return {
        "messages": historial_nuevo,
        "pregunta_pendiente": None # Siempre limpiar
    }


def recopilar_cp_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Llama a llm_cp_extractor para obtener el c√≥digo postal del usuario.
    Guarda el mensaje del LLM (pregunta de aclaraci√≥n o confirmaci√≥n) 
    y el CP extra√≠do (si lo hay) en el estado.
    """
    print("--- Ejecutando Nodo: recopilar_cp_node ---")
    historial = state.get("messages", [])
    
    # No necesitamos la guarda de AIMessage aqu√≠ si este es el primer nodo real
    # o si el nodo anterior (preguntar_cp_inicial) ya es un AIMessage.
    # Si el flujo es START -> recopilar_cp_node, no habr√° AIMessage previo.
    
    codigo_postal_extraido_llm = None
    contenido_msg_llm = "Lo siento, no pude procesar tu c√≥digo postal en este momento." # Default
    tipo_msg_llm = "ERROR"

    try:
        # llm_cp_extractor devuelve ResultadoCP
        response: ResultadoCP = llm_cp_extractor.invoke(
            [system_prompt_cp, *historial], # Pasa el prompt y el historial
            config={"configurable": {"tags": ["llm_cp_extractor"]}} 
        )
        print(f"DEBUG (CP) ‚ñ∫ Respuesta llm_cp_extractor: {response}")

        codigo_postal_extraido_llm = response.codigo_postal_extraido
        tipo_msg_llm = response.tipo_mensaje
        contenido_msg_llm = response.contenido_mensaje
        
        print(f"DEBUG (CP) ‚ñ∫ CP extra√≠do por LLM: '{codigo_postal_extraido_llm}', Tipo Mensaje: '{tipo_msg_llm}'")

    except ValidationError as e_val:
        print(f"ERROR (CP) ‚ñ∫ Error de Validaci√≥n Pydantic en llm_cp_extractor: {e_val}")
        contenido_msg_llm = f"Hubo un problema al procesar tu c√≥digo postal (formato inv√°lido): {e_val}. ¬øPodr√≠as intentarlo de nuevo?"
        tipo_msg_llm = "PREGUNTA_ACLARACION" # Forzar pregunta si hay error de validaci√≥n
    except Exception as e:
        print(f"ERROR (CP) ‚ñ∫ Fallo general al invocar llm_cp_extractor: {e}")
        traceback.print_exc()
        # contenido_msg_llm ya tiene un default de error

    # Guardar el CP extra√≠do temporalmente en el estado para validaci√≥n,
    # y el mensaje del LLM en pregunta_pendiente.
    # El CP final validado se guardar√° en state['codigo_postal_usuario'] en el nodo de validaci√≥n.
    return {
        #**state,
        "pregunta_pendiente": contenido_msg_llm,
        "codigo_postal_extraido_temporal": codigo_postal_extraido_llm,
        "tipo_mensaje_cp_llm": tipo_msg_llm
    }

def validar_cp_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Valida el c√≥digo postal extra√≠do por el LLM.
    Si es v√°lido, lo guarda en state['codigo_postal_usuario'].
    Si no es v√°lido, prepara para re-preguntar.
    Devuelve una clave para la arista condicional: 'cp_valido' o 'repreguntar_cp'.
    """
    print("--- Ejecutando Nodo: validar_cp_node ---")
    cp_extraido = state.get("codigo_postal_extraido_temporal")
    tipo_mensaje_cp_llm = state.get("tipo_mensaje_cp_llm")
    
    decision = "repreguntar_cp" # Por defecto, repreguntar
    cp_validado_para_estado = None
    mensaje_para_siguiente_pregunta = state.get("pregunta_pendiente") # Mensaje del LLM

    if tipo_mensaje_cp_llm == "CP_OBTENIDO":
        if cp_extraido and cp_extraido.isdigit() and len(cp_extraido) == 5:
            print(f"DEBUG (CP Validation) ‚ñ∫ CP '{cp_extraido}' parece v√°lido. Procediendo a buscar clima.")
            cp_validado_para_estado = cp_extraido
            decision = "cp_valido_listo_para_clima"
            # No necesitamos un mensaje pendiente si el CP es v√°lido y el LLM ya confirm√≥
            # o dio mensaje vac√≠o. El siguiente nodo (buscar_info_clima) no necesita pregunta_pendiente.
            mensaje_para_siguiente_pregunta = None 
        elif cp_extraido is None and tipo_mensaje_cp_llm == "CP_OBTENIDO":
            # Caso donde el usuario se neg√≥ a dar CP, y el LLM lo manej√≥ (seg√∫n prompt)
            print("DEBUG (CP Validation) ‚ñ∫ Usuario no proporcion√≥ CP, pero LLM manej√≥ la situaci√≥n. Avanzando sin CP.")
            decision = "cp_valido_listo_para_clima" # Avanza, pero cp_validado_para_estado ser√° None
            mensaje_para_siguiente_pregunta = None
        else:
            # El LLM dijo que obtuvo CP, pero no es v√°lido en formato
            print(f"WARN (CP Validation) ‚ñ∫ LLM indic√≥ CP_OBTENIDO, pero CP '{cp_extraido}' es inv√°lido. Repreguntando.")
            # El mensaje_para_siguiente_pregunta ya deber√≠a ser la pregunta de aclaraci√≥n del LLM
            # Si no lo es, el nodo preguntar_cp_node deber√≠a tener un fallback.
            if not mensaje_para_siguiente_pregunta or mensaje_para_siguiente_pregunta.strip() == "":
                 mensaje_para_siguiente_pregunta = "El c√≥digo postal no parece correcto. ¬øPodr√≠as darme los 5 d√≠gitos de tu CP?"
            decision = "repreguntar_cp"
            
    elif tipo_mensaje_cp_llm == "PREGUNTA_ACLARACION":
        print("DEBUG (CP Validation) ‚ñ∫ LLM necesita aclarar CP. Repreguntando.")
        # mensaje_para_siguiente_pregunta ya contiene la pregunta del LLM
        decision = "repreguntar_cp"
    else: # ERROR o tipo inesperado
        print(f"ERROR (CP Validation) ‚ñ∫ Tipo de mensaje LLM inesperado o error: '{tipo_mensaje_cp_llm}'. Repreguntando por seguridad.")
        mensaje_para_siguiente_pregunta = "Hubo un problema con el c√≥digo postal. ¬øPodr√≠as intentarlo de nuevo con 5 d√≠gitos?"
        decision = "repreguntar_cp"

    # Actualizar el estado con el CP validado (si lo hay) y la decisi√≥n para el router
    # Limpiar los campos temporales
    return {
        "codigo_postal_usuario": cp_validado_para_estado,
        "pregunta_pendiente": mensaje_para_siguiente_pregunta,
        "codigo_postal_extraido_temporal": None,
        "tipo_mensaje_cp_llm": None,
        "_decision_cp_validation": decision
    }

def buscar_info_clima_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Si hay un c√≥digo postal v√°lido, busca la informaci√≥n clim√°tica en BQ.
    Actualiza state['info_clima_usuario'].
    """
    print("--- Ejecutando Nodo: buscar_info_clima_node ---")
    cp_usuario = state.get("codigo_postal_usuario")
    info_clima_calculada = None # Default

    if cp_usuario:
        print(f"DEBUG (Clima) ‚ñ∫ Buscando datos clim√°ticos para CP: {cp_usuario}")
        try:
            info_clima_calculada = obtener_datos_climaticos_por_cp(cp_usuario)
            if info_clima_calculada and info_clima_calculada.cp_valido_encontrado:
                print(f"DEBUG (Clima) ‚ñ∫ Datos clim√°ticos encontrados: {info_clima_calculada.model_dump()}")
            elif info_clima_calculada: # cp_valido_encontrado fue False
                 print(f"WARN (Clima) ‚ñ∫ CP {cp_usuario} procesado por BQ pero no arroj√≥ datos de zona espec√≠ficos o no se encontr√≥.")
                 # info_clima_calculada tendr√° los booleanos en False y cp_valido_encontrado=False
            else: # La funci√≥n devolvi√≥ None (error en la funci√≥n)
                 print(f"ERROR (Clima) ‚ñ∫ obtener_datos_climaticos_por_cp devolvi√≥ None para CP {cp_usuario}.")
                 info_clima_calculada = InfoClimaUsuario(codigo_postal_consultado=cp_usuario, cp_valido_encontrado=False)
        except Exception as e_clima:
            print(f"ERROR (Clima) ‚ñ∫ Fallo al buscar info de clima: {e_clima}")
            traceback.print_exc()
            info_clima_calculada = InfoClimaUsuario(codigo_postal_consultado=cp_usuario, cp_valido_encontrado=False) # Guardar con error
    else:
        print("INFO (Clima) ‚ñ∫ No hay c√≥digo postal de usuario, omitiendo b√∫squeda de clima.")
        # Crear un objeto InfoClimaUsuario con defaults (todos False) si no hay CP
        info_clima_calculada = InfoClimaUsuario(cp_valido_encontrado=False) 

    return {"info_clima_usuario": info_clima_calculada}

# --- FIN NUEVOS NODOS PARA ETAPA DE C√ìDIGO POSTAL ---

# --- Etapa 1: Recopilaci√≥n de Preferencias del Usuario ---

def recopilar_preferencias_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Procesa entrada humana, llama a llm_solo_perfil, actualiza preferencias_usuario,
    y guarda el contenido del mensaje devuelto en 'pregunta_pendiente'.
    Maneja errores de validaci√≥n de Pydantic para ratings fuera de rango.
    """
    print("--- Ejecutando Nodo: recopilar_preferencias_node ---")
    logging.debug("--- Ejecutando Nodo: recopilar_preferencias_node ---")
    
    historial = state.get("messages", [])
    # Obtener el estado actual de preferencias. Si no existe, inicializar uno nuevo.
    preferencias_actuales_obj = state.get("preferencias_usuario") or PerfilUsuario()

    # Si el √∫ltimo mensaje es de la IA, no llamar al LLM de nuevo.
    if historial and isinstance(historial[-1], AIMessage):
        logging.debug("DEBUG (Perfil) ‚ñ∫ √öltimo mensaje es AIMessage, omitiendo llamada a llm_solo_perfil.")
        return {"pregunta_pendiente": state.get("pregunta_pendiente")}

    logging.debug("DEBUG (Perfil) ‚ñ∫ √öltimo mensaje es HumanMessage o historial vac√≠o, llamando a llm_solo_perfil...")
    
    # Inicializar variables para la salida del nodo
    preferencias_para_actualizar_estado = preferencias_actuales_obj # Default: mantener las actuales si todo falla
    mensaje_para_pregunta_pendiente = "Lo siento, tuve un problema t√©cnico al procesar tus preferencias." # Default

    try:
        response: ResultadoSoloPerfil = llm_solo_perfil.invoke(
            [system_prompt_perfil, *historial],
            config={"configurable": {"tags": ["llm_solo_perfil"]}} 
        )
        logging.debug(f"DEBUG (Perfil) ‚ñ∫ Respuesta llm_solo_perfil: {response}")

        preferencias_del_llm = response.preferencias_usuario # Objeto PerfilUsuario del LLM
        mensaje_para_pregunta_pendiente = response.contenido_mensaje # Mensaje del LLM

        # Aplicar post-procesamiento a las preferencias obtenidas del LLM
        if preferencias_del_llm is None: # Si el LLM no devolvi√≥ un objeto de preferencias
            logging.warning("WARN (Perfil) ‚ñ∫ llm_solo_perfil devolvi√≥ preferencias_usuario como None.")
            preferencias_del_llm = PerfilUsuario() # Usar uno vac√≠o para el post-procesador

        preferencias_post_proc = aplicar_postprocesamiento_perfil(preferencias_del_llm)
        
        if preferencias_post_proc is not None:
            preferencias_para_actualizar_estado = preferencias_post_proc
            logging.debug(f"DEBUG (Perfil) ‚ñ∫ Preferencias TRAS post-procesamiento: {preferencias_para_actualizar_estado.model_dump_json(indent=2) if hasattr(preferencias_para_actualizar_estado, 'model_dump_json') else preferencias_para_actualizar_estado}")
        else:
            logging.warning("WARN (Perfil) ‚ñ∫ aplicar_postprocesamiento_perfil devolvi√≥ None. Usando preferencias del LLM sin post-procesar (o las actuales si LLM fall√≥).")
            preferencias_para_actualizar_estado = preferencias_del_llm if preferencias_del_llm else preferencias_actuales_obj

    except ValidationError as e_val:
        logging.error(f"ERROR (Perfil) ‚ñ∫ Error de Validaci√≥n Pydantic en llm_solo_perfil: {e_val.errors()}")
        
        custom_error_message = None
        campo_rating_erroneo_para_reset = None
        preferencias_para_reset = preferencias_actuales_obj.model_copy(deep=True) # Trabajar sobre una copia de las actuales

        for error in e_val.errors():
            loc = error.get('loc', ())
            # El error de Pydantic v2 para modelos anidados puede tener 'preferencias_usuario' como primer elemento de 'loc'
            if len(loc) > 0 and str(loc[0]) == 'preferencias_usuario' and len(loc) > 1 and str(loc[1]).startswith('rating_'):
                campo_rating = str(loc[1])
                tipo_error_pydantic = error.get('type')
                valor_input = error.get('input')

                if tipo_error_pydantic in ['less_than_equal', 'greater_than_equal', 'less_than', 'greater_than', 'finite_number', 'int_parsing']: # A√±adir int_parsing
                    nombre_amigable = MAPA_RATING_A_PREGUNTA_AMIGABLE.get(campo_rating, f"el campo '{campo_rating}'")
                    custom_error_message = (
                        f"Para {nombre_amigable}, necesito una puntuaci√≥n entre 0 y 10. "
                        f"Parece que ingresaste '{valor_input}'. ¬øPodr√≠as darme un valor en la escala de 0 a 10, por favor?"
                    )
                    campo_rating_erroneo_para_reset = campo_rating
                    break 
        
        if custom_error_message:
            mensaje_para_pregunta_pendiente = custom_error_message
            if campo_rating_erroneo_para_reset and hasattr(preferencias_para_reset, campo_rating_erroneo_para_reset):
                setattr(preferencias_para_reset, campo_rating_erroneo_para_reset, None)
                logging.debug(f"DEBUG (Perfil) ‚ñ∫ Campo err√≥neo '{campo_rating_erroneo_para_reset}' reseteado a None.")
            preferencias_para_actualizar_estado = preferencias_para_reset # Usar la versi√≥n con el campo reseteado
        else:
            error_msg_detalle = e_val.errors()[0]['msg'] if e_val.errors() else 'Error desconocido'
            mensaje_para_pregunta_pendiente = f"Hubo un problema al entender tus preferencias (formato inv√°lido). ¬øPodr√≠as reformular? Detalle: {error_msg_detalle}"
            preferencias_para_actualizar_estado = preferencias_actuales_obj # Revertir a las preferencias antes de la llamada LLM

    except Exception as e_general:
        logging.error(f"ERROR (Perfil) ‚ñ∫ Fallo general al invocar llm_solo_perfil o en post-procesamiento: {e_general}", exc_info=True)
        mensaje_para_pregunta_pendiente = "Lo siento, tuve un problema t√©cnico al procesar tus preferencias. ¬øPodr√≠amos intentarlo de nuevo con la √∫ltima pregunta?"
        preferencias_para_actualizar_estado = preferencias_actuales_obj # Revertir a las preferencias antes de la llamada LLM

    # Asegurar que pregunta_pendiente tenga un valor si no se estableci√≥
    if not mensaje_para_pregunta_pendiente or not mensaje_para_pregunta_pendiente.strip():
        # Esto podr√≠a pasar si el LLM devuelve tipo_mensaje=CONFIRMACION y contenido_mensaje=""
        # pero el perfil a√∫n no est√° completo seg√∫n check_perfil_usuario_completeness.
        # En ese caso, el nodo preguntar_preferencias_node usar√° su fallback.
        logging.debug(f"DEBUG (Perfil) ‚ñ∫ No hay mensaje espec√≠fico para pregunta_pendiente, se limpiar√° o usar√° fallback.")
        mensaje_para_pregunta_pendiente = None
    logging.debug(f"DEBUG (Perfil) ‚ñ∫ Estado preferencias_usuario a actualizar: {preferencias_para_actualizar_estado.model_dump_json(indent=2) if hasattr(preferencias_para_actualizar_estado, 'model_dump_json') else None}")
    logging.debug(f"DEBUG (Perfil) ‚ñ∫ Guardando mensaje para pregunta_pendiente: {mensaje_para_pregunta_pendiente}")
        
    return {
        "preferencias_usuario": preferencias_para_actualizar_estado,
        "pregunta_pendiente": mensaje_para_pregunta_pendiente
    }


def validar_preferencias_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Comprueba si el PerfilUsuario en el estado est√° completo usando una funci√≥n de utilidad.
    Este nodo es simple: solo realiza la comprobaci√≥n. La decisi√≥n de qu√© hacer
    (repetir pregunta o avanzar) se tomar√° en la condici√≥n del grafo.
    """
    print("--- Ejecutando Nodo: validar_preferencias_node ---")
    preferencias = state.get("preferencias_usuario")
    
    # Llamar a la funci√≥n de utilidad para verificar la completitud SOLO del perfil
    # ¬°Aseg√∫rate de que esta funci√≥n exista en utils.validation!
    if check_perfil_usuario_completeness(preferencias):
        print("DEBUG (Perfil) ‚ñ∫ Validaci√≥n: PerfilUsuario considerado COMPLETO.")
    else:
        print("DEBUG (Perfil) ‚ñ∫ Validaci√≥n: PerfilUsuario considerado INCOMPLETO.")

    # La l√≥gica de enrutamiento (volver a preguntar o avanzar a filtros) 
    # se definir√° en la arista condicional que salga de este nodo.
    return {**state} 

def _obtener_siguiente_pregunta_perfil(prefs: Optional[PerfilUsuario]) -> str:
    """Genera una pregunta espec√≠fica basada en el primer campo obligatorio que falta."""
    if prefs is None: 
        return "¬øPodr√≠as contarme un poco sobre qu√© buscas o para qu√© usar√°s el coche?"
    # Revisa los campos en orden de prioridad deseado para preguntar
    if prefs.apasionado_motor is None: return "¬øTe consideras una persona entusiasta del mundo del motor y la tecnolog√≠a automotriz?"
    if prefs.valora_estetica is None: return "¬øLa Est√©tica es importante para ti o crees que hay factores m√°s importantes?"
    if prefs.coche_principal_hogar is None: return "¬øEl coche que estamos buscando ser√° el veh√≠culo principal de tu hogar?."
    if prefs.frecuencia_uso is None: return "¬øCon qu√© frecuencia usar√°s el coche?\n üí® A diario (incluso varias veces al d√≠a)\n üîÑ Frecuentemente (varias veces por semana)\n  üïê Ocasionalmente (pocas veces al mes)"
    if prefs.distancia_trayecto is None:  return "¬øCu√°l es la distancia de tu trayecto m√°s habitual?\n üü¢ Hasta 10 km\n üü° 10-50 km\n üü† 51-150 km\n üî¥ M√°s de 150 km" 
    # Solo pregunta por viajes largos si el trayecto habitual NO es ya un viaje largo
    # L√≥gica anidada para viajes largos
    if (prefs.distancia_trayecto is not None and
            prefs.distancia_trayecto != DistanciaTrayecto.MAS_150_KM.value and
            prefs.realiza_viajes_largos is None):
        return "¬øHaces recorridos de m√°s de 150 km?\n ‚úÖ S√≠\n ‚ùå No"
    
    if is_yes(prefs.realiza_viajes_largos) and prefs.frecuencia_viajes_largos is None:
        return ("¬øY con qu√© frecuencia realizas estos viajes largos?\n"
                "üí® Frecuentemente (Unas cuantas veces por mes)\n"
                "üóìÔ∏è Ocasionalmente (Unas pocas veces por mes)\n"
                "üïê Espor√°dicamente (Unas pocas veces por a√±o)")
    if prefs.circula_principalmente_ciudad is None: return "Cuentame, ¬øcirculas principalmente por ciudad?\n ‚úÖ S√≠\n ‚ùå No"
    if prefs.uso_profesional is None: return "¬øEl coche lo destinaras principalmente para uso personal o m√°s para fines profesionales (trabajo)?"
    if is_yes(prefs.uso_profesional) and prefs.tipo_uso_profesional is None:
        return "¬øY ese uso profesional ser√° principalmente para llevar pasajeros, transportar carga, o un uso mixto?"
    if prefs.prefiere_diseno_exclusivo is None: return "En cuanto al estilo del coche, ¬øte inclinas m√°s por un dise√±o exclusivo y llamativo, o por algo m√°s discreto y convencional?"
    if prefs.altura_mayor_190 is None: return "Para recomendarte un veh√≠culo con espacio adecuado, ¬øtu altura supera los 1.90 metros?"
    if prefs.peso_mayor_100 is None: return "Para garantizar tu m√°xima comodidad, ¬øtienes un peso superior a 100 kg?"
    if prefs.transporta_carga_voluminosa is None: return "¬øAcostumbras a viajar con el maletero muy cargado?\n ‚úÖ S√≠\n ‚ùå No"
    if is_yes(prefs.transporta_carga_voluminosa) and prefs.necesita_espacio_objetos_especiales is None:
        return "¬øY ese transporte de carga incluye objetos de dimensiones especiales como bicicletas, tablas de surf, cochecitos para beb√©, sillas de ruedas, instrumentos musicales, etc?"
    if prefs.arrastra_remolque is None: return "¬øVas a arrastrar remolque pesado o caravana?"
    if prefs.aventura is None: return "Para conocer tu esp√≠ritu aventurero, dime que prefieres:\n üõ£Ô∏è Solo asfalto (ninguna)\n üå≤ Salidas off‚Äëroad de vez en cuando (ocasional)\n üèîÔ∏è Aventurero extremo en terrenos dif√≠ciles (extrema)"
    if prefs.estilo_conduccion is None: return "¬øC√≥mo describir√≠as tu estilo de conducci√≥n habitual? Por ejemplo: tranquilo, deportivo, o una mezcla de ambos (mixto)."
     # --- NUEVA L√ìGICA DE PREGUNTAS PARA GARAJE/APARCAMIENTO ---
    # if prefs.tiene_garage is None:
    #     return "Hablemos un poco de d√≥nde aparcar√°s. ¬øTienes garaje o plaza de aparcamiento propia?"
    # if prefs.tiene_garage is not None and not is_yes(prefs.tiene_garage): # Si respondi√≥ 'no' a tiene_garage
    #     if prefs.problemas_aparcar_calle is None:
    #         return "Entendido. En ese caso, al aparcar en la calle, ¬øsueles encontrar dificultades por el tama√±o del coche o la disponibilidad de sitios?"
    # elif prefs.tiene_garage is not None and is_yes(prefs.tiene_garage): # Si respondi√≥ 's√≠' a tiene_garage
    #     if prefs.espacio_sobra_garage is None:
    #         return "¬°Genial lo del garaje/plaza! Y dime, ¬øel espacio que tienes es amplio y te permite aparcar un coche de cualquier tama√±o con comodidad?"
    #     if prefs.espacio_sobra_garage is not None and not is_yes(prefs.espacio_sobra_garage): # Si respondi√≥ 'no' a espacio_sobra_garage
    #         if prefs.problema_dimension_garage is None or not prefs.problema_dimension_garage: # Si es None o lista vac√≠a
    #             return "Comprendo que el espacio es ajustado. ¬øCu√°l es la principal limitaci√≥n de dimensi√≥n? Podr√≠a ser el largo, el ancho, o la altura del coche. (Puedes mencionar una o varias, ej: 'largo y ancho')"
    if prefs.tiene_garage is None:
        return "Hablemos un poco de d√≥nde aparcar√°s. ¬øTienes garaje o plaza de aparcamiento propia?\n ‚úÖ S√≠\n ‚ùå No"
    else:
        # Si ya sabemos si tiene garaje, entramos en las sub-preguntas
        if is_yes(prefs.tiene_garage): # --- CASO S√ç TIENE GARAJE ---
            if prefs.espacio_sobra_garage is None:
                return "¬°Genial lo del garaje/plaza! Y dime, ¬øel espacio que tienes es amplio y te permite aparcar un coche de cualquier tama√±o con comodidad?"
            # Esta sub-pregunta solo se hace si el espacio NO sobra
            elif not is_yes(prefs.espacio_sobra_garage) and not prefs.problema_dimension_garage:
                return "Comprendo que el espacio es ajustado. ¬øCu√°l es la principal limitaci√≥n de dimensi√≥n? (largo, ancho, o alto)"
        else: # --- CASO NO TIENE GARAJE ---
            if prefs.problemas_aparcar_calle is None:
                return "Entendido. En ese caso, al aparcar en la calle, ¬øsueles encontrar dificultades por el tama√±o del coche o la disponibilidad de sitios?"
    # --- FIN NUEVA L√ìGICA DE PREGUNTAS ---
    if prefs.tiene_punto_carga_propio is None:
        return "¬øcuentas con un punto de carga para veh√≠culo el√©ctrico en tu domicilio o lugar de trabajo habitual?\n ‚úÖ S√≠\n ‚ùå No"
    # --- FIN NUEVAS PREGUNTAS DE CARGA ---
    if prefs.solo_electricos is None: return "¬øEst√°s interesado exclusivamente en veh√≠culos con motorizaci√≥n el√©ctrica?\n ‚úÖ S√≠\n ‚ùå No"
    if prefs.transmision_preferida is None: return "En cuanto a la transmisi√≥n, ¬øqu√© opci√≥n se ajusta mejor a tus preferencias?\n 1) Autom√°tico\n 2) Manual\n 3) Ambos, puedo considerar ambas opciones"
    if prefs.prioriza_baja_depreciacion is None: return "¬øEs importante para ti que la depreciaci√≥n del coche sea lo m√°s baja posible?\n ‚úÖ S√≠\n ‚ùå No"
     # --- NUEVAS PREGUNTAS DE RATING (0-10) ---
    if prefs.rating_fiabilidad_durabilidad is None: return "¬øqu√© tan importante es para ti la Fiabilidad y Durabilidad del coche? \n üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)"
    if prefs.rating_seguridad is None:return "Pensando en la Seguridad, ¬øqu√© puntuaci√≥n le dar√≠as en importancia? \n üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)"
    if prefs.rating_comodidad is None:return "Y en cuanto a la comodidad y confort del vehiculo que tan importante es que se maximice?\n üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)"
    if prefs.rating_impacto_ambiental is None: return "Considerando el Bajo Impacto Medioambiental, ¬øqu√© importancia tiene esto para tu elecci√≥n? \n üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)" 
    if prefs.rating_costes_uso is None: return "¬øqu√© tan importante es para ti que el veh√≠culo sea econ√≥mico en su uso diario y mantenimiento? \n üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)" 
    if prefs.rating_tecnologia_conectividad is None: return "finalmente, en cuanto a la Tecnolog√≠a y Conectividad del coche, \n üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)"
    # --- FIN NUEVAS PREGUNTAS DE RATING --- 
    return "¬øPodr√≠as darme alg√∫n detalle m√°s sobre tus preferencias?" # Fallback muy gen√©rico 

def preguntar_preferencias_node(state: EstadoAnalisisPerfil) -> dict:
    """
    A√±ade la pregunta de seguimiento correcta al historial.
    Si el perfil no est√° completo, SIEMPRE prioriza la pregunta generada por la l√≥gica
    interna para asegurar el flujo correcto de preguntas anidadas.
    """
    print("--- Ejecutando Nodo: preguntar_preferencias_node ---")
    preferencias = state.get("preferencias_usuario")
    historial_actual = state.get("messages", [])
    historial_nuevo = list(historial_actual) 
    
    mensaje_a_enviar = None 

    perfil_esta_completo = check_perfil_usuario_completeness(preferencias)

    # --- L√ìGICA CORREGIDA ---
    if not perfil_esta_completo:
        # Si el perfil est√° incompleto, nuestra l√≥gica determinista tiene el control total
        # para asegurar que no se salten preguntas anidadas.
        print("DEBUG (Preguntar Perfil) ‚ñ∫ Perfil a√∫n INCOMPLETO. La l√≥gica interna tiene prioridad.")
        try:
            mensaje_a_enviar = _obtener_siguiente_pregunta_perfil(preferencias)
            print(f"DEBUG (Preguntar Perfil) ‚ñ∫ Pregunta correcta generada y seleccionada: {mensaje_a_enviar}")
        except Exception as e:
            print(f"ERROR (Preguntar Perfil) ‚ñ∫ Error generando pregunta: {e}")
            mensaje_a_enviar = "¬øPodr√≠as darme m√°s detalles sobre tus preferencias?"
            
    else: # El perfil S√ç est√° completo
        # Si el perfil ya est√° completo, podemos usar el mensaje de confirmaci√≥n del LLM.
        print("DEBUG (Preguntar Perfil) ‚ñ∫ Perfil COMPLETO seg√∫n checker.")
        mensaje_pendiente = state.get("pregunta_pendiente")
        if mensaje_pendiente and mensaje_pendiente.strip():
             print(f"DEBUG (Preguntar Perfil) ‚ñ∫ Usando mensaje de confirmaci√≥n pendiente: {mensaje_pendiente}")
             mensaje_a_enviar = mensaje_pendiente
        else:
             print("WARN (Preguntar Perfil) ‚ñ∫ Perfil completo pero no hab√≠a mensaje pendiente. Usando confirmaci√≥n gen√©rica.")
             mensaje_a_enviar = "¬°Perfecto! He recopilado todas tus preferencias. Ahora continuar√© con el siguiente paso."

    # A√±adir el mensaje decidido al historial (esta parte no cambia)
    if mensaje_a_enviar and mensaje_a_enviar.strip():
        ai_msg = AIMessage(content=mensaje_a_enviar)
        if not historial_actual or historial_actual[-1].content != ai_msg.content:
            historial_nuevo.append(ai_msg)
            print(f"DEBUG (Preguntar Perfil) ‚ñ∫ Mensaje final a√±adido: {mensaje_a_enviar}") 
        else:
             print("DEBUG (Preguntar Perfil) ‚ñ∫ Mensaje final duplicado, no se a√±ade.")
    else:
         print("ERROR (Preguntar Perfil) ‚ñ∫ No se determin√≥ ning√∫n mensaje a enviar.")
         ai_msg = AIMessage(content="No estoy seguro de qu√© preguntar ahora. ¬øPuedes darme m√°s detalles?")
         historial_nuevo.append(ai_msg)

    # Devolver estado
    return {**state, "messages": historial_nuevo, "pregunta_pendiente": None}


# def preguntar_preferencias_node(state: EstadoAnalisisPerfil) -> dict:
#     """
#     A√±ade la pregunta de seguimiento correcta al historial.
#     Verifica si el perfil est√° realmente completo ANTES de a√±adir un mensaje 
#     de confirmaci√≥n/transici√≥n. Si no lo est√°, asegura que se a√±ada una pregunta real.
#     """
#     print("--- Ejecutando Nodo: preguntar_preferencias_node ---")
#     mensaje_pendiente = state.get("pregunta_pendiente") 
#     preferencias = state.get("preferencias_usuario")
#     historial_actual = state.get("messages", [])
#     historial_nuevo = list(historial_actual) 
    
#     mensaje_a_enviar = None 

#     # 1. Comprobar si el perfil est√° REALMENTE completo AHORA
#     perfil_esta_completo = check_perfil_usuario_completeness(preferencias)

#     if not perfil_esta_completo:
#         print("DEBUG (Preguntar Perfil) ‚ñ∫ Perfil a√∫n INCOMPLETO seg√∫n checker.")
#         pregunta_generada_fallback = None 

#         # Generar la pregunta espec√≠fica AHORA por si la necesitamos
#         try:
#              pregunta_generada_fallback = _obtener_siguiente_pregunta_perfil(preferencias)
#              print(f"DEBUG (Preguntar Perfil) ‚ñ∫ Pregunta fallback generada: {pregunta_generada_fallback}")
#         except Exception as e_fallback:
#              print(f"ERROR (Preguntar Perfil) ‚ñ∫ Error generando pregunta fallback: {e_fallback}")
#              pregunta_generada_fallback = "¬øPodr√≠as darme m√°s detalles sobre tus preferencias?" 

#         # ¬øTenemos un mensaje pendiente del LLM?
#         if mensaje_pendiente and mensaje_pendiente.strip():
#             # Comprobar si el mensaje pendiente PARECE una confirmaci√≥n
#             es_confirmacion = (
#                 mensaje_pendiente.startswith("¬°Perfecto!") or 
#                 mensaje_pendiente.startswith("¬°Genial!") or 
#                 mensaje_pendiente.startswith("¬°Estupendo!") or 
#                 mensaje_pendiente.startswith("Ok,") or 
#                 "¬øPasamos a" in mensaje_pendiente
#             )

#             if es_confirmacion:
#                 # IGNORAR la confirmaci√≥n err√≥nea y USAR el fallback
#                 print(f"WARN (Preguntar Perfil) ‚ñ∫ Mensaje pendiente ('{mensaje_pendiente}') parece confirmaci√≥n, pero perfil incompleto. IGNORANDO y usando fallback.")
#                 mensaje_a_enviar = pregunta_generada_fallback
#             else:
#                 # El mensaje pendiente parece una pregunta v√°lida, la usamos.
#                  print(f"DEBUG (Preguntar Perfil) ‚ñ∫ Usando mensaje pendiente (pregunta LLM): {mensaje_pendiente}")
#                  mensaje_a_enviar = mensaje_pendiente
#         else:
#             # No hab√≠a mensaje pendiente v√°lido, usamos la fallback generada.
#             print("WARN (Preguntar Perfil) ‚ñ∫ Nodo ejecutado para preguntar, pero no hab√≠a mensaje pendiente v√°lido. Generando pregunta fallback.")
#             mensaje_a_enviar = pregunta_generada_fallback
            
#     else: # El perfil S√ç est√° completo
#         print("DEBUG (Preguntar Perfil) ‚ñ∫ Perfil COMPLETO seg√∫n checker.")
#         # Usamos el mensaje pendiente (que deber√≠a ser de confirmaci√≥n)
#         if mensaje_pendiente and mensaje_pendiente.strip():
#              print(f"DEBUG (Preguntar Perfil) ‚ñ∫ Usando mensaje de confirmaci√≥n pendiente: {mensaje_pendiente}")
#              mensaje_a_enviar = mensaje_pendiente
#         else:
#              print("WARN (Preguntar Perfil) ‚ñ∫ Perfil completo pero no hab√≠a mensaje pendiente. Usando confirmaci√≥n gen√©rica.")
#              mensaje_a_enviar = "¬°Entendido! Ya tenemos tu perfil completo." # Mensaje simple

#     # A√±adir el mensaje decidido al historial
#     if mensaje_a_enviar and mensaje_a_enviar.strip():
#         ai_msg = AIMessage(content=mensaje_a_enviar)
#         if not historial_actual or historial_actual[-1].content != ai_msg.content:
#             historial_nuevo.append(ai_msg)
#             print(f"DEBUG (Preguntar Perfil) ‚ñ∫ Mensaje final a√±adido: {mensaje_a_enviar}") 
#         else:
#              print("DEBUG (Preguntar Perfil) ‚ñ∫ Mensaje final duplicado, no se a√±ade.")
#     else:
#          print("ERROR (Preguntar Perfil) ‚ñ∫ No se determin√≥ ning√∫n mensaje a enviar.")
#          ai_msg = AIMessage(content="No estoy seguro de qu√© preguntar ahora. ¬øPuedes darme m√°s detalles?")
#          historial_nuevo.append(ai_msg)

#     # Devolver estado
#     return {**state, "messages": historial_nuevo, "pregunta_pendiente": None}


# --- NUEVA ETAPA: PASAJEROS ---

def recopilar_info_pasajeros_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Llama a llm_pasajeros para extraer/actualizar InfoPasajeros siguiendo el nuevo flujo.
    Realiza inferencias adicionales (ej: frecuencia='nunca' si no lleva acompa√±antes).
    Guarda la informaci√≥n y el mensaje/pregunta del LLM en el estado.
    """
    logger.debug("--- Ejecutando Nodo: recopilar_info_pasajeros_node ---")
    
    historial = state.get("messages", [])
    info_pasajeros_actual_obj = state.get("info_pasajeros") 
    
    # Si no hay objeto InfoPasajeros en el estado, inicializar uno nuevo.Esto es importante para que el LLM tenga un objeto base sobre el cual trabajar y para que el prompt que le pide rellenar campos null funcione correctamente.
    if info_pasajeros_actual_obj is None:
        info_pasajeros_actual_obj = InfoPasajeros()
        logger.debug("DEBUG (Pasajeros) ‚ñ∫ InfoPasajeros no exist√≠a en el estado, inicializando uno nuevo.")

    # Si el √∫ltimo mensaje es un AIMessage (del propio agente), no llamar al LLM de nuevo. Esto evita bucles si el nodo se re-ejecuta sin nueva entrada del usuario.
    if historial and isinstance(historial[-1], AIMessage):
        logger.debug("DEBUG (Pasajeros) ‚ñ∫ √öltimo mensaje es AIMessage, omitiendo llamada a llm_pasajeros.")
        return {"pregunta_pendiente": state.get("pregunta_pendiente")} # Propagar pregunta_pendiente si existe

    logger.debug("DEBUG (Pasajeros) ‚ñ∫ Llamando a llm_pasajeros...")
    
    # Variables para la salida del nodo
    info_pasajeros_para_actualizar_estado = info_pasajeros_actual_obj # Default: mantener las actuales si todo falla
    mensaje_para_pregunta_pendiente = "Lo siento, tuve un problema t√©cnico al procesar la informaci√≥n de pasajeros." # Default

    try:
        # El LLM ahora recibe el objeto info_pasajeros actual como parte del contexto (impl√≠cito en el historial o expl√≠cito en el prompt) y debe devolver un objeto InfoPasajeros completo o parcialmente relleno.
        # El prompt system_prompt_pasajeros debe guiarlo.
        response: ResultadoPasajeros = llm_pasajeros.invoke(
            [system_prompt_pasajeros, *historial], # Pasar el prompt y el historial
            config={"configurable": {"tags": ["llm_pasajeros"]}} 
        )
        logger.debug(f"DEBUG (Pasajeros) ‚ñ∫ Respuesta llm_pasajeros: {response}")

        info_pasajeros_del_llm = response.info_pasajeros 
        mensaje_para_pregunta_pendiente = response.contenido_mensaje
        
        if info_pasajeros_del_llm:
            # --- L√ìGICA DE INFERENCIA ADICIONAL BASADA EN EL NUEVO FLUJO ---
            if info_pasajeros_del_llm.suele_llevar_acompanantes is False:
                logger.debug("DEBUG (Pasajeros) ‚ñ∫ Usuario NO suele llevar acompa√±antes. Estableciendo defaults.")
                info_pasajeros_del_llm.frecuencia = "nunca"
                info_pasajeros_del_llm.num_ninos_silla = 0
                info_pasajeros_del_llm.num_otros_pasajeros = 0
                info_pasajeros_del_llm.frecuencia_viaje_con_acompanantes = None # Limpiar si se hab√≠a puesto
                info_pasajeros_del_llm.composicion_pasajeros_texto = None # Limpiar
            elif info_pasajeros_del_llm.suele_llevar_acompanantes is True:
                if info_pasajeros_del_llm.frecuencia_viaje_con_acompanantes:
                    info_pasajeros_del_llm.frecuencia = info_pasajeros_del_llm.frecuencia_viaje_con_acompanantes
                    logger.debug(f"DEBUG (Pasajeros) ‚ñ∫ Frecuencia general establecida a: {info_pasajeros_del_llm.frecuencia} desde frecuencia_viaje.")
                # NO establecer num_ninos_silla y num_otros_pasajeros a 0 por defecto aqu√≠.
                # Deben permanecer None si el LLM no los infiri√≥, para que se pregunten.
                # El LLM es responsable de rellenarlos o dejarlos None si a√∫n no tiene la info.
                if info_pasajeros_del_llm.num_ninos_silla is None:
                    logger.debug("DEBUG (Pasajeros) ‚ñ∫ num_ninos_silla es None (esperando pregunta de composici√≥n/sillas).")
                if info_pasajeros_del_llm.num_otros_pasajeros is None:
                    logger.debug("DEBUG (Pasajeros) ‚ñ∫ num_otros_pasajeros es None (esperando pregunta de composici√≥n).")
            
            info_pasajeros_para_actualizar_estado = info_pasajeros_del_llm # Usar el objeto del LLM (con inferencias)
        else:
            logger.warning("WARN (Pasajeros) ‚ñ∫ llm_pasajeros devolvi√≥ info_pasajeros como None.")
            info_pasajeros_para_actualizar_estado = info_pasajeros_actual_obj 

    except ValidationError as e_val:
        logger.error(f"ERROR (Pasajeros) ‚ñ∫ Error de Validaci√≥n Pydantic en llm_pasajeros: {e_val.errors()}")
        # Aqu√≠ podr√≠as a√±adir l√≥gica para construir un mensaje de error amigable si el error es sobre un campo espec√≠fico de InfoPasajeros.
        error_msg_detalle = e_val.errors()[0]['msg'] if e_val.errors() else 'Error desconocido'
        mensaje_para_pregunta_pendiente = f"Hubo un problema al entender la informaci√≥n de los pasajeros (formato inv√°lido). ¬øPodr√≠as reformular? Detalle: {error_msg_detalle}"
        #info_pasajeros_para_actualizar_estado = info_pasajeros_actual_obj # Revertir

    except Exception as e_general:
        logger.error(f"ERROR (Pasajeros) ‚ñ∫ Fallo general al invocar llm_pasajeros: {e_general}", exc_info=True)
        mensaje_para_pregunta_pendiente = "Lo siento, tuve un problema t√©cnico al procesar la informaci√≥n de pasajeros. ¬øPodr√≠amos intentarlo de nuevo?"
        #info_pasajeros_para_actualizar_estado = info_pasajeros_actual_obj # Revertir

    # Asegurar que pregunta_pendiente tenga un valor si no se estableci√≥
    if not mensaje_para_pregunta_pendiente or not mensaje_para_pregunta_pendiente.strip():
        logger.debug(f"DEBUG (Pasajeros) ‚ñ∫ No hay mensaje espec√≠fico para pregunta_pendiente, se limpiar√° o usar√° fallback.")
        mensaje_para_pregunta_pendiente = None

    logger.debug(f"DEBUG (Pasajeros) ‚ñ∫ Estado info_pasajeros a actualizar: {info_pasajeros_para_actualizar_estado.model_dump_json(indent=2) if hasattr(info_pasajeros_para_actualizar_estado, 'model_dump_json') else None}")
    logger.debug(f"DEBUG (Pasajeros) ‚ñ∫ Guardando mensaje para pregunta_pendiente: {mensaje_para_pregunta_pendiente}")
        
    return {
        **state,  # Mantener el estado original
        "info_pasajeros": info_pasajeros_para_actualizar_estado,
        "pregunta_pendiente": mensaje_para_pregunta_pendiente
    }


def validar_info_pasajeros_node(state: EstadoAnalisisPerfil) -> dict:
    """Nodo simple que comprueba si la informaci√≥n de pasajeros est√° completa."""
    print("--- Ejecutando Nodo: validar_info_pasajeros_node ---")
    info_pasajeros = state.get("info_pasajeros")
    # Llama a la funci√≥n de utilidad (que crearemos en el siguiente paso)
    if check_pasajeros_completo(info_pasajeros):
        print("DEBUG (Pasajeros) ‚ñ∫ Validaci√≥n: Info Pasajeros considerada COMPLETA.")
    else:
        print("DEBUG (Pasajeros) ‚ñ∫ Validaci√≥n: Info Pasajeros considerada INCOMPLETA.")
    # No modifica el estado, solo valida para la condici√≥n
    return {**state}


def _obtener_siguiente_pregunta_pasajeros(info: Optional[InfoPasajeros]) -> str:
    """
    Genera la siguiente pregunta de fallback para la informaci√≥n de pasajeros,
    siguiendo el nuevo flujo condicional.
    """
    if info is None: # Si no hay objeto InfoPasajeros, empezar por la primera pregunta
        return "¬øSueles viajar con acompa√±antes en el coche habitualmente? \n ‚úÖ S√≠\n ‚ùå No"

    # 1. Pregunta inicial
    if info.suele_llevar_acompanantes is None:
        return "¬øSueles viajar con acompa√±antes en el coche habitualmente? \n ‚úÖ S√≠\n ‚ùå No"

    # Si la respuesta fue 'no', no deber√≠a llegar aqu√≠ si el LLM y la validaci√≥n funcionan,
    # ya que se considerar√≠a completo. Pero por si acaso:
    if info.suele_llevar_acompanantes is False:
        return "Entendido, normalmente viajas solo. (No se necesitan m√°s preguntas de pasajeros)" # O un mensaje para indicar fin de esta etapa

    # Si la respuesta fue 's√≠', continuar con las sub-preguntas:
    if info.suele_llevar_acompanantes is True:
        if info.frecuencia_viaje_con_acompanantes is None:
            return "Entendido. Y, ¬øcon qu√© frecuencia sueles llevar a estos acompa√±antes? Por ejemplo, ¬øde manera ocasional o frecuentemente?"
        
        # Preguntar por composici√≥n si los n√∫meros finales no est√°n definidos
        # El campo composicion_pasajeros_texto es m√°s una ayuda para el LLM.
        # Nos centramos en los campos num√©ricos finales.
        if info.num_otros_pasajeros is None: # Podr√≠amos preguntar por composici√≥n antes
            frecuencia_texto = info.frecuencia_viaje_con_acompanantes or "con esa frecuencia"
            return (f"De acuerdo, los llevas de forma {frecuencia_texto}. "
                    "Cu√©ntame un poco m√°s, ¬øqui√©nes suelen ser estos acompa√±antes y cu√°ntos son en total (sin contarte a ti)? "
                    "Por ejemplo, 'dos adultos', 'un ni√±o y un adulto', 'dos ni≈Ños peque√±os'.")

        # Preguntar por sillas si hay ni√±os impl√≠citos o expl√≠citos y num_ninos_silla es None
        # Esta l√≥gica puede ser compleja para un fallback simple. El LLM deber√≠a manejarla mejor.
        # Si num_otros_pasajeros ya tiene un valor, y num_ninos_silla es None, es el siguiente.
        if info.num_ninos_silla is None:
            # Podr√≠amos intentar ser m√°s inteligentes si 'composicion_pasajeros_texto' mencion√≥ ni√±os.
            # Por ahora, una pregunta gen√©rica si num_otros_pasajeros ya se obtuvo.
            return "¬øAlguno de estos acompa√±antes necesita silla infantil?"

    # Si todos los campos necesarios seg√∫n el flujo est√°n llenos,
    # esta funci√≥n no deber√≠a ser llamada por un nodo "preguntar" que ya valid√≥.
    # Pero si llega aqu√≠, es un estado inesperado.
    logging.warning("WARN (_obtener_siguiente_pregunta_pasajeros) ‚ñ∫ Todos los campos de pasajeros parecen estar completos seg√∫n esta l√≥gica, pero se pidi√≥ una pregunta fallback.")
    return "¬øPodr√≠as darme m√°s detalles sobre tus acompa√±antes habituales?"


def preguntar_info_pasajeros_node(state: EstadoAnalisisPerfil) -> dict:
    """
    A√±ade la pregunta de seguimiento correcta de pasajeros al historial.
    Verifica si la info de pasajeros est√° completa ANTES de a√±adir un mensaje 
    de confirmaci√≥n. Si no lo est√°, asegura que se a√±ada una pregunta real.
    """
    print("--- Ejecutando Nodo: preguntar_info_pasajeros_node ---")
    mensaje_pendiente = state.get("pregunta_pendiente") # Mensaje del nodo anterior (LLM)
    info_pasajeros = state.get("info_pasajeros") 
    historial_actual = state.get("messages", [])
    historial_nuevo = list(historial_actual) 
    
    mensaje_a_enviar = None # El mensaje final que a√±adiremos

    # 1. Comprobar si la info de pasajeros est√° REALMENTE completa AHORA
    pasajeros_esta_completo = check_pasajeros_completo(info_pasajeros)

    if not pasajeros_esta_completo:
        print("DEBUG (Preguntar Pasajeros) ‚ñ∫ Info Pasajeros a√∫n INCOMPLETA seg√∫n checker.")
        pregunta_generada_fallback = None 

        # Generar la pregunta espec√≠fica AHORA por si la necesitamos
        try:
             pregunta_generada_fallback = _obtener_siguiente_pregunta_pasajeros(info_pasajeros)
             print(f"DEBUG (Preguntar Pasajeros) ‚ñ∫ Pregunta fallback generada: {pregunta_generada_fallback}")
        except Exception as e_fallback:
             print(f"ERROR (Preguntar Pasajeros) ‚ñ∫ Error generando pregunta fallback: {e_fallback}")
             pregunta_generada_fallback = "¬øPodr√≠as darme m√°s detalles sobre los pasajeros?" 

        # ¬øTenemos un mensaje pendiente del LLM?
        if mensaje_pendiente and mensaje_pendiente.strip():
            # Comprobar si el mensaje pendiente PARECE una confirmaci√≥n
            # Puedes a√±adir m√°s frases si detectas otras confirmaciones err√≥neas
            es_confirmacion = (
                mensaje_pendiente.startswith("¬°Perfecto!") or 
                mensaje_pendiente.startswith("¬°Genial!") or 
                mensaje_pendiente.startswith("¬°Estupendo!") or 
                mensaje_pendiente.startswith("Ok,") or 
                mensaje_pendiente.startswith("Entendido,") # <-- ¬°Tu caso reciente!
            )

            if es_confirmacion:
                # IGNORAR la confirmaci√≥n err√≥nea y USAR el fallback
                print(f"WARN (Preguntar Pasajeros) ‚ñ∫ Mensaje pendiente ('{mensaje_pendiente}') parece confirmaci√≥n, pero pasajeros incompleto. IGNORANDO y usando fallback.")
                mensaje_a_enviar = pregunta_generada_fallback
            else:
                # El mensaje pendiente parece una pregunta v√°lida, la usamos.
                 print(f"DEBUG (Preguntar Pasajeros) ‚ñ∫ Usando mensaje pendiente (pregunta LLM): {mensaje_pendiente}")
                 mensaje_a_enviar = mensaje_pendiente
        else:
            # No hab√≠a mensaje pendiente, usamos la fallback generada.
            print("WARN (Preguntar Pasajeros) ‚ñ∫ Nodo ejecutado para preguntar, pero no hab√≠a mensaje pendiente v√°lido. Generando pregunta fallback.")
            mensaje_a_enviar = pregunta_generada_fallback
            
    else: # La info de pasajeros S√ç est√° completa
        print("DEBUG (Preguntar Pasajeros) ‚ñ∫ Info Pasajeros COMPLETA seg√∫n checker.")
        # Usamos el mensaje pendiente (que deber√≠a ser de confirmaci√≥n)
        if mensaje_pendiente and mensaje_pendiente.strip():
             print(f"DEBUG (Preguntar Pasajeros) ‚ñ∫ Usando mensaje de confirmaci√≥n pendiente: {mensaje_pendiente}")
             mensaje_a_enviar = mensaje_pendiente
        else:
             print("WARN (Preguntar Pasajeros) ‚ñ∫ Info Pasajeros completa pero no hab√≠a mensaje pendiente. Usando confirmaci√≥n gen√©rica.")
             mensaje_a_enviar = "¬°Entendido! Informaci√≥n de pasajeros registrada."

    # A√±adir el mensaje decidido al historial
    if mensaje_a_enviar and mensaje_a_enviar.strip():
        ai_msg = AIMessage(content=mensaje_a_enviar)
        if not historial_actual or historial_actual[-1].content != ai_msg.content:
            historial_nuevo.append(ai_msg)
            print(f"DEBUG (Preguntar Pasajeros) ‚ñ∫ Mensaje final a√±adido: {mensaje_a_enviar}") 
        else:
             print("DEBUG (Preguntar Pasajeros) ‚ñ∫ Mensaje final duplicado, no se a√±ade.")
    else:
         print("ERROR (Preguntar Pasajeros) ‚ñ∫ No se determin√≥ ning√∫n mensaje a enviar.")
         ai_msg = AIMessage(content="No estoy seguro de qu√© preguntar sobre pasajeros. ¬øContinuamos?")
         historial_nuevo.append(ai_msg)

    # Devolver estado
    return {**state, "messages": historial_nuevo, "pregunta_pendiente": None}



def aplicar_filtros_pasajeros_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Calcula filtros/indicadores basados en la informaci√≥n de pasajeros completa
    y los actualiza en el estado.
    Calcula: plazas_min (siempre), penalizar_puertas_bajas.
    """
    print("--- Ejecutando Nodo: aplicar_filtros_pasajeros_node ---")
    logger.debug("--- Ejecutando Nodo: aplicar_filtros_pasajeros_node ---")
    info_pasajeros_obj = state.get("info_pasajeros") # <-- Renombrado para claridad
    filtros_actuales_obj = state.get("filtros_inferidos") or FiltrosInferidos() 

    # Valores por defecto para los flags penalizar_puertas
    penalizar_p = False 
    
    # Valores para X y Z (default 0)
    X = 0
    Z = 0
    frecuencia = None

    if info_pasajeros_obj: 
        # Usar frecuencia_viaje_con_acompanantes si est√°, sino la general 'frecuencia'
        # La nueva l√≥gica de InfoPasajeros deber√≠a priorizar frecuencia_viaje_con_acompanantes
        frecuencia = info_pasajeros_obj.frecuencia_viaje_con_acompanantes or info_pasajeros_obj.frecuencia
        X = info_pasajeros_obj.num_ninos_silla or 0
        Z = info_pasajeros_obj.num_otros_pasajeros or 0
        logger.debug(f"DEBUG (Aplicar Filtros Pasajeros) ‚ñ∫ Info recibida: freq='{frecuencia}', X={X}, Z={Z}")
        print(f"DEBUG (Aplicar Filtros Pasajeros) ‚ñ∫ Info recibida: freq='{frecuencia}', X={X}, Z={Z}")
    else:
        logger.error("ERROR (Aplicar Filtros Pasajeros) ‚ñ∫ No hay informaci√≥n de pasajeros en el estado. Se usar√°n defaults.")
        frecuencia = "nunca" # Asumir 'nunca' si no hay info

    plazas_calc = X + Z + 1 
    logger.debug(f"DEBUG (Aplicar Filtros Pasajeros) ‚ñ∫ Calculado plazas_min = {plazas_calc}")

    if frecuencia and frecuencia != "nunca": # Nota: frecuencia ahora puede ser 'ocasional' o 'frecuente'
        # Regla Penalizar Puertas Bajas (solo si frecuente y X>=1)
        if frecuencia == "frecuente" and X >= 1:
            penalizar_p = True
            logger.debug("DEBUG (Aplicar Filtros Pasajeros) ‚ñ∫ Indicador penalizar_puertas_bajas = True")
    else:
        logger.debug("DEBUG (Aplicar Filtros Pasajeros) ‚ñ∫ Frecuencia es 'nunca' o None. penalizar_puertas se mantiene False.")

    update_filtros_dict = {"plazas_min": plazas_calc}
    filtros_actualizados = filtros_actuales_obj.model_copy(update=update_filtros_dict)
    logger.debug(f"DEBUG (Aplicar Filtros Pasajeros) ‚ñ∫ Filtros actualizados (con plazas_min): {filtros_actualizados}")
    return {
    **state, # Pasa todas las claves existentes del estado
    "filtros_inferidos": filtros_actualizados, # Sobrescribe solo la clave que has modificado
    "penalizar_puertas_bajas": penalizar_p,      # Y la nueva flag que has calculado
}

# --- Fin Nueva Etapa Pasajeros ---
# --- Fin Etapa 1 ---

# --- Etapa 2: Inferencia y Validaci√≥n de Filtros T√©cnicos ---
def inferir_filtros_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Construye y refina los filtros de b√∫squeda de forma determinista
    llamando a la funci√≥n de post-procesamiento. No utiliza LLM.
    """
    print("--- Ejecutando Nodo: inferir_filtros_node/construir_filtros_node ---")
    
    preferencias_obj = state.get("preferencias_usuario")
    info_clima_obj = state.get("info_clima_usuario")

    # Verificar pre-condiciones
    if not preferencias_obj:
        print("ERROR (Filtros) ‚ñ∫ Nodo ejecutado pero 'preferencias_usuario' no existe. No se pueden construir filtros.")
        # Devolvemos un objeto vac√≠o para no romper el flujo
        return {"filtros_inferidos": FiltrosInferidos()}

    print("DEBUG (Filtros) ‚ñ∫ Preferencias e info_clima disponibles. Construyendo filtros...")

    filtros_finales = None
    try:
        # 1. Creamos un objeto FiltrosInferidos vac√≠o para empezar.
        #    Ya no dependemos de una inferencia inicial del LLM.
        filtros_iniciales = FiltrosInferidos()
        
        # 2. El √∫nico trabajo del nodo es llamar a esta funci√≥n determinista.
        filtros_finales = aplicar_postprocesamiento_filtros(
            filtros=filtros_iniciales,
            preferencias=preferencias_obj,
            info_clima=info_clima_obj 
        )
        print(f"DEBUG (Filtros) ‚ñ∫ Filtros finales construidos: {filtros_finales}")

    except Exception as e_post:
        print(f"ERROR (Filtros) ‚ñ∫ Fallo construyendo los filtros: {e_post}")
        traceback.print_exc()
        # En caso de un error inesperado, devolvemos filtros vac√≠os para seguridad.
        filtros_finales = FiltrosInferidos()
        
    # 3. Devolvemos el estado actualizado. Ya no necesitamos 'pregunta_pendiente'.
    return {
        "filtros_inferidos": filtros_finales
    }

# def validar_filtros_node(state: EstadoAnalisisPerfil) -> dict:
#     """
#     Comprueba si los FiltrosInferidos en el estado est√°n completos 
#     (seg√∫n los criterios definidos en la funci√≥n de utilidad `check_filtros_completos`).
#     """
#     print("--- Ejecutando Nodo: validar_filtros_node ---")
#     filtros = state.get("filtros_inferidos")
    
#     # Usar una funci√≥n de utilidad para verificar la completitud SOLO de los filtros
#     # ¬°Aseg√∫rate de que esta funci√≥n exista en utils.validation!
#     if check_filtros_completos(filtros):
#         print("DEBUG (Filtros) ‚ñ∫ Validaci√≥n: FiltrosInferidos considerados COMPLETOS.")
#     else:
#         print("DEBUG (Filtros) ‚ñ∫ Validaci√≥n: FiltrosInferidos considerados INCOMPLETOS.")
        
#     return {**state}
# --- Fin Etapa 2 ---


# --- Etapa 3: Inferencia y Validaci√≥n de Recopilaci√≥n de Econom√≠a ---
def preguntar_economia_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Toma la pregunta econ√≥mica pendiente y la a√±ade como AIMessage al historial.
    Limpia la pregunta pendiente. Podr√≠a generar pregunta default si no hay pendiente.
    """
    print("--- Ejecutando Nodo: preguntar_economia_node ---")
    pregunta = state.get("pregunta_pendiente")
    historial_actual = state.get("messages", [])
    historial_nuevo = historial_actual 

    mensaje_a_enviar = None

    # Usamos la pregunta guardada si existe
    if pregunta and pregunta.strip():
        print(f"DEBUG (Preguntar Econom√≠a) ‚ñ∫ Usando pregunta guardada: {pregunta}")
        mensaje_a_enviar = pregunta
    else:
        # Si no hab√≠a pregunta pendiente (raro, pero podr√≠a pasar si el LLM no la gener√≥)
        # podr√≠amos poner una pregunta gen√©rica de econom√≠a.
        print("WARN (Preguntar Econom√≠a) ‚ñ∫ Nodo ejecutado pero no hab√≠a pregunta pendiente. Usando pregunta gen√©rica.")
        # TODO: Podr√≠amos llamar aqu√≠ a _obtener_siguiente_pregunta_economia si tuvi√©ramos esa funci√≥n
        mensaje_a_enviar = "Necesito algo m√°s de informaci√≥n sobre tu presupuesto. ¬øPodr√≠as darme m√°s detalles?"

    # A√±adir el mensaje decidido al historial (evitando duplicados)
    if mensaje_a_enviar and mensaje_a_enviar.strip():
        ai_msg = AIMessage(content=mensaje_a_enviar)
        if not historial_actual or historial_actual[-1].content != ai_msg.content:
            historial_nuevo = historial_actual + [ai_msg]
            print(f"DEBUG (Preguntar Econom√≠a) ‚ñ∫ Mensaje final a√±adido: {mensaje_a_enviar}")
        else:
             print("DEBUG (Preguntar Econom√≠a) ‚ñ∫ Mensaje final duplicado, no se a√±ade.")
    else:
         print("WARN (Preguntar Econom√≠a) ‚ñ∫ No se determin√≥ ning√∫n mensaje a enviar.")

    # Devolver estado: historial actualizado y pregunta_pendiente reseteada
    return {
        **state,
        "messages": historial_nuevo,
        "pregunta_pendiente": None # Limpiar la pregunta pendiente
    }


def recopilar_economia_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Gestiona la recopilaci√≥n de datos econ√≥micos. Llama a llm_economia,
    actualiza el estado 'economia' y guarda la pregunta pendiente.
    """
    print("--- Ejecutando Nodo: recopilar_economia_node ---")
    historial = state.get("messages", [])
    econ_actual = state.get("economia") or EconomiaUsuario() 
    
    print("DEBUG (Econom√≠a) ‚ñ∫ Llamando a llm_economia...")
    
    mensaje_validacion = None # Inicializar
    economia_actualizada = econ_actual # Inicializar con el estado actual

    # Llamar al LLM de Econom√≠a
    try:
        parsed: ResultadoEconomia = llm_economia.invoke(
            [prompt_economia_structured_sys_msg, *historial],
            config={"configurable": {"tags": ["llm_economia"]}} 
        )
        print(f"DEBUG (Econom√≠a) ‚ñ∫ Respuesta llm_economia: {parsed}")

        economia_nueva = parsed.economia 
        mensaje_validacion = parsed.mensaje_validacion

        # Actualizar el estado 'economia' fusionando lo nuevo
        if economia_nueva:
             update_data = economia_nueva.model_dump(exclude_unset=True) 
             economia_actualizada = econ_actual.model_copy(update=update_data)
             print(f"DEBUG (Econom√≠a) ‚ñ∫ Estado econom√≠a actualizado: {economia_actualizada}")
        # else: # Si no devuelve nada, mantenemos econ_actual que ya ten√≠a el valor antes del try

    except ValidationError as e_val:
        print(f"ERROR (Econom√≠a) ‚ñ∫ Error de Validaci√≥n Pydantic en llm_economia: {e_val}")
        mensaje_validacion = f"Hubo un problema al procesar tu informaci√≥n econ√≥mica: faltan datos requeridos ({e_val}). ¬øPodr√≠as aclararlo?"
        # Mantenemos el estado econ√≥mico anterior en caso de error de validaci√≥n LLM
        economia_actualizada = econ_actual 
    except Exception as e:
        print(f"ERROR (Econom√≠a) ‚ñ∫ Fallo al invocar llm_economia: {e}")
        mensaje_validacion = "Lo siento, tuve un problema t√©cnico procesando tus datos econ√≥micos."
        # Mantenemos el estado econ√≥mico anterior
        economia_actualizada = econ_actual

    # --- Guardar Pregunta Pendiente ---
    pregunta_para_siguiente_nodo = None
    if mensaje_validacion and mensaje_validacion.strip():
        pregunta_para_siguiente_nodo = mensaje_validacion.strip()
        print(f"DEBUG (Econom√≠a) ‚ñ∫ Guardando pregunta pendiente: {pregunta_para_siguiente_nodo}")
    else:
        print(f"DEBUG (Econom√≠a) ‚ñ∫ No hay pregunta de validaci√≥n pendiente.")
        
    # Devolver estado actualizado SIN modificar messages, pero CON pregunta_pendiente
    return {
        **state,
        "economia": economia_actualizada, # Guardar econom√≠a actualizada
        # 'messages' NO se modifica aqu√≠
        "pregunta_pendiente": pregunta_para_siguiente_nodo # Guardar la pregunta
    }

def validar_economia_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Comprueba si la informaci√≥n econ√≥mica ('economia') en el estado est√° completa
    utilizando la funci√≥n de utilidad `check_economia_completa`.
    """
    print("--- Ejecutando Nodo: validar_economia_node ---")
    economia = state.get("economia")
    
    # Llamar a la funci√≥n de utilidad que usa el validador Pydantic
    if check_economia_completa(economia):
        print("DEBUG (Econom√≠a) ‚ñ∫ Validaci√≥n: Econom√≠a considerada COMPLETA.")
    else:
        print("DEBUG (Econom√≠a) ‚ñ∫ Validaci√≥n: Econom√≠a considerada INCOMPLETA.")
        
    # Este nodo solo valida, no modifica el estado.
    # La condici√≥n del grafo decidir√° si volver a recopilar_economia_node o avanzar.
    return {**state}
# --- Fin Etapa 3 ---


# --- Etapa 4: Finalizaci√≥n y Presentaci√≥n ---
def calcular_recomendacion_economia_modo1_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Calcula la recomendaci√≥n econ√≥mica (modo_adquisicion_recomendado, 
    precio_max_contado_recomendado, cuota_max_calculada) si el usuario
    eligi√≥ el Modo 1 y proporcion√≥ los datos necesarios.
    Actualiza filtros_inferidos en el estado.
    """
    print("--- Ejecutando Nodo: calcular_recomendacion_economia_modo1_node ---")
    logging.debug("--- Ejecutando Nodo: calcular_recomendacion_economia_modo1_node ---")
    
    economia_obj = state.get("economia")
    filtros_obj = state.get("filtros_inferidos")

    # Si no hay filtros_obj (poco probable si el flujo es correcto), inicializar uno
    if filtros_obj is None:
        logging.warning("WARN (CalcEconModo1) ‚ñ∫ filtros_inferidos era None. Inicializando uno nuevo.")
        filtros_obj = FiltrosInferidos()
        
    filtros_actualizados = filtros_obj.model_copy(deep=True)
    cambios_realizados = False

    if economia_obj and economia_obj.modo == 1:
        logging.debug("DEBUG (CalcEconModo1) ‚ñ∫ Modo 1 detectado. Intentando calcular recomendaci√≥n econ√≥mica...")
        try:
            ingresos = economia_obj.ingresos
            ahorro = economia_obj.ahorro
            anos_posesion = economia_obj.anos_posesion
            
            if ingresos is not None and ahorro is not None and anos_posesion is not None:
                t = min(anos_posesion, 8) # a√±os para c√°lculo de ahorro, max 8
                ahorro_utilizable = ahorro * 0.75 # Usar el 75% del ahorro
                
                # Estimaci√≥n de capacidad de ahorro mensual dedicada al coche (ej: 10% de ingresos netos mensuales)
                # Si 'ingresos' son anuales, dividir por 12. Asumamos que 'ingresos' son anuales.
                capacidad_ahorro_mensual_coche = (ingresos / 12) * 0.10 
                
                # Potencial de ahorro total durante el plazo de posesi√≥n
                potencial_ahorro_total_plazo = capacidad_ahorro_mensual_coche * 12 * t
                
                # Decisi√≥n Contado vs. Financiado para Modo 1
                # Si el ahorro utilizable cubre una buena parte o todo el potencial de gasto v√≠a cuotas
                # o si el potencial de gasto es bajo, podr√≠a sugerir contado.
                # Esta l√≥gica puede necesitar refinamiento seg√∫n tus criterios de "inteligencia financiera".
                # Ejemplo simple: si el ahorro cubre al menos la mitad del gasto potencial total
                modo_adq_rec = "Financiado" # Default
                precio_max_rec = None
                cuota_max_calc = capacidad_ahorro_mensual_coche # La cuota m√°xima ser√≠a su capacidad de ahorro mensual

                if ahorro_utilizable >= (potencial_ahorro_total_plazo * 0.5) and potencial_ahorro_total_plazo <= 30000 : # Umbral ejemplo para "bajo gasto"
                    modo_adq_rec = "Contado"
                    # Si es contado, el precio m√°ximo podr√≠a ser el ahorro utilizable m√°s lo que ahorrar√≠a en 1-2 a√±os
                    precio_max_rec = ahorro_utilizable + (capacidad_ahorro_mensual_coche * 12 * 2) 
                    cuota_max_calc = None # No hay cuota si es contado
                
                logging.debug(f"DEBUG (CalcEconModo1) ‚ñ∫ Modo Adq Rec: {modo_adq_rec}, Precio Max Rec: {precio_max_rec}, Cuota Max Calc: {cuota_max_calc}")

                update_dict = {
                    "modo_adquisicion_recomendado": modo_adq_rec,
                    "precio_max_contado_recomendado": precio_max_rec,
                    "cuota_max_calculada": cuota_max_calc
                }
                filtros_actualizados = filtros_actualizados.model_copy(update=update_dict) 
                cambios_realizados = True
                logging.debug(f"DEBUG (CalcEconModo1) ‚ñ∫ Filtros actualizados con recomendaci√≥n Modo 1: {filtros_actualizados.modo_adquisicion_recomendado}, PrecioMax: {filtros_actualizados.precio_max_contado_recomendado}, CuotaMax: {filtros_actualizados.cuota_max_calculada}")
            else:
                 logging.warning("WARN (CalcEconModo1) ‚ñ∫ Faltan datos (ingresos, ahorro o a√±os) para c√°lculo Modo 1.")
        except Exception as e_calc:
            logging.error(f"ERROR (CalcEconModo1) ‚ñ∫ Fallo durante c√°lculo de recomendaci√≥n Modo 1: {e_calc}")
            traceback.print_exc()
            # En caso de error, filtros_actualizados mantiene la copia inicial (sin estos campos o con los anteriores)
    else:
         logging.debug("DEBUG (CalcEconModo1) ‚ñ∫ Modo no es 1 o no hay datos de econom√≠a, omitiendo c√°lculo de recomendaci√≥n econ√≥mica.")

    if cambios_realizados:
        return {"filtros_inferidos": filtros_actualizados}
    else:
        # Si no hubo cambios, devolvemos el estado sin modificar esta clave para evitar escrituras innecesarias
        # o devolvemos el filtros_actualizados que es una copia del original si no se toc√≥.
        # Para LangGraph, es mejor devolver el objeto aunque no haya cambiado, si la clave existe en el estado.
        return {"filtros_inferidos": filtros_actualizados} 

def calcular_flags_dinamicos_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Calcula todos los flags booleanos din√°micos basados en las preferencias del usuario
    y la informaci√≥n clim√°tica. Estos flags se usar√°n para la l√≥gica de scoring en BQ.
    Actualiza el estado con estos flags.
    """
    print("--- Ejecutando Nodo: calcular_flags_dinamicos_node ---")
    logging.debug("--- Ejecutando Nodo: calcular_flags_dinamicos_node ---")
    preferencias_obj = state.get("preferencias_usuario")
    info_clima_obj = state.get("info_clima_usuario")
    penalizar_puertas_bajas_actual = state.get("penalizar_puertas_bajas", False) # # Los flags 'penalizar_puertas_bajas' y 'priorizar_ancho' vienen de aplicar_filtros_pasajeros_node ya deber√≠an estar en el estado si esa l√≥gica se ejecut√≥.
    info_pasajeros_obj = state.get("info_pasajeros") # <-- Obtener info de pasajeros
    print(f"DEBUG contenido de los objetos:  preferencias_obj: {preferencias_obj} - pasajeros {info_pasajeros_obj} - clima {info_clima_obj}") # Debug para ver qu√© contiene el objeto
    flag_pen_bev_reev_avent_ocas = False
    flag_pen_phev_avent_ocas = False
    flag_pen_electrif_avent_extr = False # Para BEV, REEV, PHEV en aventura extrema
    flag_penalizar_lc_comod = False
    flag_penalizar_dep_comod = False
    flag_penalizar_ant_tec = False
    flag_aplicar_dist_amb = False
    flag_es_zbe = False
    flag_fav_car_montana = False #  # --- NUEVOS FLAGS PARA L√ìGICA DE CARROCER√çA ---
    flag_fav_car_comercial = False
    flag_fav_car_pasajeros_pro = False
    flag_desfav_car_no_aventura = False#  
    flag_fav_suv_aventura_ocasional = False
    flag_fav_pickup_todoterreno_aventura_extrema = False
    flag_aplicar_logica_objetos_especiales = False
    flag_fav_carroceria_confort = False# --- NUEVOS FLAGS PARA L√ìGICA DE CARROCER√çA ---
    flag_logica_uso_ocasional = False # 
    flag_pen_bev_reev_avent_ocas = False
    flag_favorecer_bev_uso_definido = False 
    flag_penalizar_phev_uso_intensivo = False
    flag_favorecer_electrificados_por_punto_carga = False
    flag_logica_diesel_ciudad = False
    penalizar_awd_ninguna_aventura = False
    favorecer_awd_aventura_ocasional = False
    favorecer_awd_aventura_extrema = False
    flag_bonus_awd_nieve = False
    flag_bonus_awd_montana = False
    flag_logica_reductoras_aventura = False
    flag_bonus_awd_clima_adverso = False
     
    # Verificar que preferencias_obj exista para acceder a sus atributos
    if not preferencias_obj:
        logging.error("ERROR (CalcFlags) ‚ñ∫ 'preferencias_usuario' no existe en el estado. No se pueden calcular flags din√°micos.")
        # Devolver los flags con sus valores por defecto y mantener los existentes
        return {
            "penalizar_puertas_bajas": penalizar_puertas_bajas_actual,
            #"priorizar_ancho": priorizar_ancho_actual,
            "flag_penalizar_low_cost_comodidad": flag_penalizar_lc_comod,
            "flag_penalizar_deportividad_comodidad": flag_penalizar_dep_comod,
            "flag_penalizar_antiguo_por_tecnologia": flag_penalizar_ant_tec,
            "aplicar_logica_distintivo_ambiental": flag_aplicar_dist_amb,
            "penalizar_bev_reev_aventura_ocasional": flag_pen_bev_reev_avent_ocas,
            "penalizar_phev_aventura_ocasional": flag_pen_phev_avent_ocas,
            "penalizar_electrificados_aventura_extrema": flag_pen_electrif_avent_extr,
            "es_municipio_zbe": flag_es_zbe,
            "favorecer_carroceria_montana": flag_fav_car_montana,
            "favorecer_carroceria_comercial": flag_fav_car_comercial,
            "favorecer_carroceria_pasajeros_pro": flag_fav_car_pasajeros_pro,
            "desfavorecer_carroceria_no_aventura": flag_desfav_car_no_aventura,
            "favorecer_suv_aventura_ocasional": flag_fav_suv_aventura_ocasional,
            "favorecer_pickup_todoterreno_aventura_extrema": flag_fav_pickup_todoterreno_aventura_extrema,
            "aplicar_logica_objetos_especiales": flag_aplicar_logica_objetos_especiales,
            "favorecer_carroceria_confort": flag_fav_carroceria_confort,  
            "flag_logica_uso_ocasional": flag_logica_uso_ocasional,
            "flag_favorecer_bev_uso_definido": flag_favorecer_bev_uso_definido, 
            "flag_penalizar_phev_uso_intensivo": flag_penalizar_phev_uso_intensivo, #
            "flag_favorecer_electrificados_por_punto_carga" : flag_favorecer_electrificados_por_punto_carga,
            "flag_logica_diesel_ciudad" : flag_logica_diesel_ciudad,
            "penalizar_awd_ninguna_aventura" : penalizar_awd_ninguna_aventura,
            "favorecer_awd_aventura_ocasional" : favorecer_awd_aventura_ocasional,
            "favorecer_awd_aventura_extrema" : favorecer_awd_aventura_extrema,
            "flag_bonus_awd_nieve" : flag_bonus_awd_nieve,
            "flag_bonus_awd_montana" : flag_bonus_awd_montana,
            "flag_logica_reductoras_aventura" : flag_logica_reductoras_aventura,
            "flag_bonus_awd_clima_adverso" : flag_bonus_awd_clima_adverso
        }
    # --- NUEVA L√ìGICA PARA FLAGS DE CARROCER√çA ---
    # Regla 1: Zona de Monta√±a favorece SUV/TODOTERRENO
    if info_clima_obj and hasattr(info_clima_obj, 'ZONA_CLIMA_MONTA') and info_clima_obj.ZONA_CLIMA_MONTA is True:
        flag_fav_car_montana = True
        logging.info(f"DEBUG (CalcFlags) ‚ñ∫ ZONA_CLIMA_MONTA=True. Activando flag para favorecer carrocer√≠a de monta√±a.")
    # --- FLAGS DE TRACCI√ìN Y CLIMA ---
    if info_clima_obj: # Solo si existe el objeto de info clim√°tica
        if getattr(info_clima_obj, 'ZONA_NIEVE', False):
            flag_bonus_awd_nieve = True
            logging.info("DEBUG (CalcFlags) ‚ñ∫ Zona de nieve detectada. Activando bonus para ALL.")
        if getattr(info_clima_obj, 'ZONA_CLIMA_MONTA', False):
            flag_bonus_awd_montana = True
            logging.info("DEBUG (CalcFlags) ‚ñ∫ Zona de monta√±a detectada. Activando bonus para ALL.")    
    
    # Regla 2 y 3: Uso profesional con/sin pasajeros
    if is_yes(preferencias_obj.uso_profesional):
        if info_pasajeros_obj and info_pasajeros_obj.suele_llevar_acompanantes is False:
            flag_fav_car_comercial = True
            logging.info(f"DEBUG (CalcFlags) ‚ñ∫ Uso profesional sin pasajeros. Activando flag para favorecer carrocer√≠a COMERCIAL.")
        elif info_pasajeros_obj and info_pasajeros_obj.suele_llevar_acompanantes is True:
            flag_fav_car_pasajeros_pro = True
            logging.info(f"DEBUG (CalcFlags) ‚ñ∫ Uso profesional con pasajeros. Activando flag para favorecer 3VOL/MONOVOLUMEN.")

    # Regla 4: Aventura nula y no en monta√±a desfavorece PICKUP/TODOTERRENO
    if (hasattr(preferencias_obj, 'aventura') and preferencias_obj.aventura == NivelAventura.ninguna and
        (not info_clima_obj or not getattr(info_clima_obj, 'ZONA_CLIMA_MONTA', False))):
        flag_desfav_car_no_aventura = True
        logging.info(f"DEBUG (CalcFlags) ‚ñ∫ Aventura 'Ninguna' y no es clima de monta√±a. Activando flag para desfavorecer PICKUP/TODOTERRENO.")
    
    
    # Regla 5 y 6: Aventura
    aventura_val = preferencias_obj.aventura
    if aventura_val:
        if aventura_val == NivelAventura.ocasional:
            flag_fav_suv_aventura_ocasional = True
            logging.info(f"DEBUG (CalcFlags) ‚ñ∫ Aventura OCASIONAL. Activando flag para favorecer carrocer√≠a SUV.")
        elif aventura_val == NivelAventura.extrema:
            flag_fav_pickup_todoterreno_aventura_extrema = True
            logging.info(f"DEBUG (CalcFlags) ‚ñ∫ Aventura EXTREMA. Activando flag para favorecer PICKUP/TODOTERRENO.")
            
      # ---  AVENTURA ---
    if hasattr(preferencias_obj, 'aventura'):
        aventura_val = preferencias_obj.aventura
        print(f"DEBUG (CalcFlags) ‚ñ∫ Valor de preferencias_obj.aventura: {aventura_val} (Tipo: {type(aventura_val)})")
        logger.debug(f"DEBUG (CalcFlags) ‚ñ∫ Valor de preferencias_obj.aventura: {aventura_val} (Tipo: {type(aventura_val)})")
        logger.debug(f"DEBUG (CalcFlags) ‚ñ∫ Comparando con NivelAventura.OCASIONAL (Valor: {NivelAventura.ocasional}, Tipo: {type(NivelAventura.ocasional)})")
        logger.debug(f"DEBUG (CalcFlags) ‚ñ∫ Comparando con NivelAventura.EXTREMA (Valor: {NivelAventura.extrema}, Tipo: {type(NivelAventura.extrema)})")

        if aventura_val is not None:
            if aventura_val == NivelAventura.ocasional:
                flag_pen_bev_reev_avent_ocas = True
                flag_pen_phev_avent_ocas = True
                logger.debug(f"INFO (CalcFlags) ‚ñ∫ Aventura OCASIONAL. Activando penalizaciones para BEV/REEV y PHEV.") # Cambiado a INFO
            elif aventura_val == NivelAventura.extrema:
                flag_pen_electrif_avent_extr = True 
                logger.debug(f"INFO (CalcFlags) ‚ñ∫ Aventura EXTREMA. Activando penalizaci√≥n para todos los electrificados.") # Cambiado a INFO
            else:
                logger.debug(f"DEBUG (CalcFlags) ‚ñ∫ Nivel de aventura es '{aventura_val}', no OCASIONAL ni EXTREMA. No se activan penalizaciones espec√≠ficas de aventura/mec√°nica.")
        else:
            logger.debug("DEBUG (CalcFlags) ‚ñ∫ Nivel de aventura es None. No se activan penalizaciones de mec√°nica por aventura.")
    else:
        logging.warning("WARN (CalcFlags) ‚ñ∫ El objeto 'preferencias_usuario' no tiene el atributo 'aventura'.")

     # --- L√ìGICA REVISADA PARA FLAGS DE TRACCI√ìN, AVENTURA Y CLIMA ---
    aventura_val = preferencias_obj.aventura
    vive_en_clima_adverso = False
    if info_clima_obj:
        vive_en_clima_adverso = getattr(info_clima_obj, 'ZONA_NIEVE', False) or getattr(info_clima_obj, 'ZONA_CLIMA_MONTA', False)

    if aventura_val == NivelAventura.ninguna.value:
        if vive_en_clima_adverso:
            # EXCEPCI√ìN: El clima anula la preferencia. Se activa el bonus por clima.
            flag_bonus_awd_clima_adverso = True
            logging.info("DEBUG (CalcFlags) ‚ñ∫ Nivel Aventura 'ninguna' pero clima adverso(monta√±a - Nieve). Activando BONUS favorecer traccion ALL.")
        else:
            # Caso normal: Sin aventura y sin clima adverso. Se activa la penalizaci√≥n.
            penalizar_awd_ninguna_aventura = True
            logging.info("DEBUG (CalcFlags) ‚ñ∫ Nivel Aventura 'ninguna'. Activando PENALIZACI√ìN para ALL.")
    elif aventura_val == NivelAventura.ocasional.value:
        favorecer_awd_aventura_ocasional = True
        logging.info("DEBUG (CalcFlags) ‚ñ∫ Nivel Aventura 'ocasional'. Activando bonus para ALL.")
    elif aventura_val == NivelAventura.extrema.value:
        favorecer_awd_aventura_extrema = True
        logging.info("DEBUG (CalcFlags) ‚ñ∫ Nivel Aventura 'extrema'. Activando bonus para ALL.")
    
    
    # ---  L√ìGICA PARA FLAG DE REDUCTORAS Y AVENTURA ---
    aventura_val = preferencias_obj.aventura
    if aventura_val == NivelAventura.extrema.value:
        flag_logica_reductoras_aventura = True
        logging.info("DEBUG (CalcFlags) ‚ñ∫ Nivel Aventura 'extrema'. Activando bonus alto para Reductoras.")
        # --- FIN L√ìGICA ---
            
    # Regla 7: Objetos Especiales
    if is_yes(preferencias_obj.necesita_espacio_objetos_especiales) :
        flag_aplicar_logica_objetos_especiales = True
        logging.info(f"DEBUG (CalcFlags) ‚ñ∫ necesita_espacio_objetos_especiales=True. Activando l√≥gica de carrocer√≠a para objetos especiales.")

    # Regla 8: Alta Comodidad
    rating_comodidad_val = preferencias_obj.rating_comodidad
    if rating_comodidad_val is not None and rating_comodidad_val >= UMBRAL_COMODIDAD_PARA_FAVORECER_CARROCERIA:
        flag_fav_carroceria_confort = True
        logging.info(f"DEBUG (CalcFlags) ‚ñ∫ Rating Comodidad ({rating_comodidad_val}) >= {UMBRAL_COMODIDAD_PARA_FAVORECER_CARROCERIA}. Activando flag para favorecer carrocer√≠as confortables.")
        
    
    # L√≥gica para Flags de Penalizaci√≥n por Comodidad
    if preferencias_obj.rating_comodidad is not None:
        if preferencias_obj.rating_comodidad >= UMBRAL_COMODIDAD_PARA_PENALIZAR_FLAGS:
            flag_penalizar_lc_comod = True
            flag_penalizar_dep_comod = True
            logging.debug(f"DEBUG (CalcFlags) ‚ñ∫ Rating Comodidad ({preferencias_obj.rating_comodidad}). Activando flags penalizaci√≥n comodidad flag penalizar depor comod y flag penalizar lowcost comod")

    # L√≥gica para Flag de Penalizaci√≥n por Antig√ºedad y Tecnolog√≠a
    if preferencias_obj.rating_tecnologia_conectividad is not None:
        if preferencias_obj.rating_tecnologia_conectividad >= UMBRAL_TECNOLOGIA_PARA_PENALIZAR_ANTIGUEDAD_FLAG:
            flag_penalizar_ant_tec = True
            logging.debug(f"DEBUG (CalcFlags) ‚ñ∫ Rating Tecnolog√≠a ({preferencias_obj.rating_tecnologia_conectividad}). Activando flag penalizaci√≥n antig√ºedad.")

    # L√≥gica para Flag de Distintivo Ambiental (basado en rating_impacto_ambiental)
    if preferencias_obj.rating_impacto_ambiental is not None:
        if preferencias_obj.rating_impacto_ambiental >= UMBRAL_IMPACTO_AMBIENTAL_PARA_LOGICA_DISTINTIVO_FLAG:
            flag_aplicar_dist_amb = True
            logging.debug(f"DEBUG (CalcFlags) ‚ñ∫ Rating Impacto Ambiental ({preferencias_obj.rating_impacto_ambiental}). Activando l√≥gica de distintivo ambiental.")

    # L√≥gica para Flag ZBE (basado en info_clima_obj)
    if info_clima_obj and hasattr(info_clima_obj, 'cp_valido_encontrado') and info_clima_obj.cp_valido_encontrado and \
       hasattr(info_clima_obj, 'MUNICIPIO_ZBE') and info_clima_obj.MUNICIPIO_ZBE is True:
        flag_es_zbe = True
        logging.debug(f"DEBUG (CalcFlags) ‚ñ∫ CP en MUNICIPIO_ZBE. Activando flag es_municipio_zbe.")
    
    # --- L√ìGICA PARA EL NUEVO FLAG DE USO OCASIONAL ---
    if preferencias_obj.frecuencia_uso == FrecuenciaUso.OCASIONALMENTE.value:
        flag_logica_uso_ocasional = True
        logging.info("DEBUG (CalcFlags) ‚ñ∫ Uso OCASIONAL detectado. Activando l√≥gica de bonus para 'OCASION' y penalizaci√≥n para electrificados.")
   
    # --- L√ìGICA PARA FAVORECER BEV/REEV EN PERFIL DE USO IDEAL ---
    # Parte 1: El uso principal es intensivo
    es_uso_diario_frecuente = preferencias_obj.frecuencia_uso in [FrecuenciaUso.DIARIO.value, FrecuenciaUso.FRECUENTEMENTE.value]
    es_trayecto_medio_largo = preferencias_obj.distancia_trayecto in [DistanciaTrayecto.ENTRE_10_Y_50_KM.value, DistanciaTrayecto.ENTRE_51_Y_150_KM.value]
    
    # Parte 2: El problema de los viajes muy largos est√° mitigado
    sin_viajes_largos = not is_yes(preferencias_obj.realiza_viajes_largos) # Cubre 'no' y None
    viajes_largos_esporadicos = preferencias_obj.frecuencia_viajes_largos == FrecuenciaViajesLargos.ESPORADICAMENTE.value
    
    # Condici√≥n final combinada
    if (es_uso_diario_frecuente and es_trayecto_medio_largo) and (sin_viajes_largos or viajes_largos_esporadicos):
        flag_favorecer_bev_uso_definido = True
        print("DEBUG (CalcFlags) ‚ñ∫ Perfil de uso ideal para BEV/REEV detectado. Activando bonus.")
        logging.info("DEBUG (CalcFlags) ‚ñ∫ Perfil de uso BEV/REEV detectado: FrecuenciaUso.DIARIO o FRECUENTEMENTE y DistanciaTrayecto.ENTRE_10_Y_50_KM.value o ENTRE_51_Y_150_KM. Activando bonus.")
 
    # --- L√ìGICA PARA PENALIZAR PHEV EN TRAYECTOS LARGOS Y FRECUENTES ---
    es_uso_diario_frecuente = preferencias_obj.frecuencia_uso in [FrecuenciaUso.DIARIO.value, FrecuenciaUso.FRECUENTEMENTE.value]
    es_trayecto_muy_largo = preferencias_obj.distancia_trayecto == DistanciaTrayecto.MAS_150_KM.value
    #Falta revisar condiciones en el documento
    if es_uso_diario_frecuente and es_trayecto_muy_largo:
        flag_penalizar_phev_uso_intensivo = True
        logging.info("DEBUG (CalcFlags) ‚ñ∫ Patr√≥n de uso intensivo y larga distancia detectado. Activando penalizaci√≥n para PHEVs.")

     # --- L√ìGICA PARA PUNTO DE CARGA PROPIO ---
    if is_yes(preferencias_obj.tiene_punto_carga_propio):
        flag_favorecer_electrificados_por_punto_carga = True
        logging.info("DEBUG (CalcFlags) ‚ñ∫ Usuario tiene punto de carga propio. Activando bonus para BEV/PHEV/REEV.")
   
   # --- L√ìGICA PARA FLAG DI√âSEL - RECORRE CAMINOS CIUDAD - circula principalmente ciudad ---
    if is_yes(preferencias_obj.circula_principalmente_ciudad):
        if preferencias_obj.frecuencia_uso == FrecuenciaUso.OCASIONALMENTE.value and FrecuenciaViajesLargos.OCASIONALMENTE:
            # Caso excepcional: uso ocasional en ciudad, no se penaliza, se bonifica
            flag_logica_diesel_ciudad = "BONIFICAR"
            logging.info("DEBUG (CalcFlags) ‚ñ∫ Conductor urbano ocasional/ FrecuenciaUso.OCASIONALMENTE y FrecuenciaViajesLargos.OCASIONALMENTE. Activando peque√±o bonus para di√©sel.")
        else:
            # Caso general: conductor urbano, se penaliza di√©sel
            flag_logica_diesel_ciudad = "PENALIZAR"
            logging.info("DEBUG (CalcFlags) ‚ñ∫ Conductor urbano frecuente. Activando penalizaci√≥n para di√©sel.")
    
    logging.debug(f"DEBUG (CalcFlags) ‚ñ∫ Flags calculados: lowcost_comodidad={flag_penalizar_lc_comod}, deportividad_comodidad={flag_penalizar_dep_comod}, antiguo_por_tecnolog={flag_penalizar_ant_tec}, distint_ambiental={flag_aplicar_dist_amb}, zbe={flag_es_zbe}, penali_bev_reev_aventura_ocasional= {flag_pen_bev_reev_avent_ocas}...")

    return {
        "penalizar_puertas_bajas": penalizar_puertas_bajas_actual, # Propagar
       # "priorizar_ancho": priorizar_ancho_actual, # Propagar
        "flag_penalizar_low_cost_comodidad": flag_penalizar_lc_comod,
        "flag_penalizar_deportividad_comodidad": flag_penalizar_dep_comod, 
        "flag_penalizar_antiguo_por_tecnologia": flag_penalizar_ant_tec,
        "aplicar_logica_distintivo_ambiental": flag_aplicar_dist_amb,
        "penalizar_bev_reev_aventura_ocasional": flag_pen_bev_reev_avent_ocas,
        "penalizar_phev_aventura_ocasional": flag_pen_phev_avent_ocas,
        "penalizar_electrificados_aventura_extrema": flag_pen_electrif_avent_extr,
        "favorecer_carroceria_montana": flag_fav_car_montana,
        "favorecer_carroceria_comercial": flag_fav_car_comercial,
        "favorecer_carroceria_pasajeros_pro": flag_fav_car_pasajeros_pro,
        "desfavorecer_carroceria_no_aventura": flag_desfav_car_no_aventura,
        "favorecer_suv_aventura_ocasional": flag_fav_suv_aventura_ocasional,
        "favorecer_pickup_todoterreno_aventura_extrema": flag_fav_pickup_todoterreno_aventura_extrema,
        "penalizar_awd_ninguna_aventura": penalizar_awd_ninguna_aventura,
        "favorecer_awd_aventura_ocasional": favorecer_awd_aventura_ocasional,
        "favorecer_awd_aventura_extrema": favorecer_awd_aventura_extrema,
        "aplicar_logica_objetos_especiales": flag_aplicar_logica_objetos_especiales,
        "favorecer_carroceria_confort": flag_fav_carroceria_confort,
        "flag_favorecer_bev_uso_definido": flag_favorecer_bev_uso_definido,
        "flag_logica_uso_ocasional": flag_logica_uso_ocasional,
        "flag_penalizar_phev_uso_intensivo": flag_penalizar_phev_uso_intensivo,
        "flag_favorecer_electrificados_por_punto_carga": flag_favorecer_electrificados_por_punto_carga,
        "flag_logica_diesel_ciudad": flag_logica_diesel_ciudad,
        "flag_bonus_awd_nieve": flag_bonus_awd_nieve,
        "flag_bonus_awd_montana": flag_bonus_awd_montana,
        "flag_logica_reductoras_aventura": flag_logica_reductoras_aventura,
        "flag_bonus_awd_clima_adverso" : flag_bonus_awd_clima_adverso,
        "es_municipio_zbe": flag_es_zbe,       
    }
    
def calcular_pesos_finales_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Calcula los pesos crudos y normalizados finales basados en todas las
    preferencias del usuario, filtros inferidos (para *_min_val) y flags clim√°ticos/din√°micos.
    Actualiza state['pesos'].
    """
    print("--- Ejecutando Nodo: calcular_pesos_finales_node ---")
    logging.debug("--- Ejecutando Nodo: calcular_pesos_finales_node ---")

    preferencias_obj = state.get("preferencias_usuario")
    filtros_obj = state.get("filtros_inferidos") # Contiene estetica_min, premium_min, singular_min
    info_clima_obj = state.get("info_clima_usuario")
    info_pasajeros_obj = state.get("info_pasajeros")
    print(f"DEBUG_MIO (info_pasajeros_o     bj): {info_pasajeros_obj}")
    km_anuales_val = state.get("km_anuales_estimados")
    print(f"DEBUG_MIO_2: (km_anuales_val): {km_anuales_val}")
    # Por ahora, los extraemos aqu√≠ de info_clima_obj para pasarlos a compute_raw_weights.

    es_nieblas_val = False
    es_nieve_val = False
    es_monta_val = False
    if info_clima_obj and hasattr(info_clima_obj, 'cp_valido_encontrado') and info_clima_obj.cp_valido_encontrado:
        es_nieblas_val = getattr(info_clima_obj, 'ZONA_NIEBLAS', False) or False # Default a False si el atributo no existe
        es_nieve_val = getattr(info_clima_obj, 'ZONA_NIEVE', False) or False
        es_monta_val = getattr(info_clima_obj, 'ZONA_CLIMA_MONTA', False) or False

    pesos_calculados_normalizados = {} # Default a dict vac√≠o en caso de error

    if not preferencias_obj or not filtros_obj:
        logging.error("ERROR (CalcPesos) ‚ñ∫ Faltan preferencias_usuario o filtros_inferidos. No se pueden calcular pesos.")
        return {"pesos": pesos_calculados_normalizados} # Devolver pesos vac√≠os

    try:
        prefs_dict_para_weights = preferencias_obj.model_dump(mode='json', exclude_none=False)
        info_pasajeros_dict_para_weights = info_pasajeros_obj.model_dump(mode='json', exclude_none=False) if info_pasajeros_obj else None

        logging.debug(f"DEBUG (CalcPesos) ‚ñ∫ Entradas para compute_raw_weights:\n"
                      f"  Preferencias: {prefs_dict_para_weights.get('apasionado_motor')}, {prefs_dict_para_weights.get('aventura')}, etc.\n"
                      f"  InfoPasajeros: {info_pasajeros_dict_para_weights}\n"
                      f"  ZonaNieblas: {es_nieblas_val}, ZonaNieve: {es_nieve_val}, ZonaMonta: {es_monta_val}")

        raw_weights = compute_raw_weights(
            preferencias=prefs_dict_para_weights, # Usar el dict que ya ten√≠as
            info_pasajeros_dict=info_pasajeros_dict_para_weights,
            es_zona_nieblas=es_nieblas_val,
            # es_zona_nieve=es_nieve_val,
            # es_zona_clima_monta=es_monta_val,
            km_anuales_estimados=km_anuales_val
        )
        pesos_calculados_normalizados = normalize_weights(raw_weights)
        logging.debug(f"DEBUG (CalcPesos) ‚ñ∫ Pesos finales calculados y normalizados: {pesos_calculados_normalizados}") 
    
    except Exception as e_weights:
        logging.error(f"ERROR (CalcPesos) ‚ñ∫ Fallo calculando pesos: {e_weights}")
        traceback.print_exc()
        # pesos_calculados_normalizados se queda como {}

    return {"pesos": pesos_calculados_normalizados}

def formatear_tabla_resumen_node(state: EstadoAnalisisPerfil) -> dict:
    """
    Formatea la tabla resumen final de criterios y la guarda en
    state['tabla_resumen_criterios']. Ya NO a√±ade AIMessage al historial.
    """
    print("--- Ejecutando Nodo: formatear_tabla_resumen_node ---")
    logging.debug("--- Ejecutando Nodo: formatear_tabla_resumen_node ---")

    preferencias_obj = state.get("preferencias_usuario")
    filtros_actualizados_obj = state.get("filtros_inferidos") 
    economia_obj = state.get("economia")
    codigo_postal_val = state.get("codigo_postal_usuario")
    info_clima_obj = state.get("info_clima_usuario")
    info_pasajeros_obj = state.get("info_pasajeros")

    tabla_final_md = "Error al generar el resumen de criterios." # Default

    if not preferencias_obj or not filtros_actualizados_obj or not economia_obj:
        logging.error("ERROR (FormatearTabla) ‚ñ∫ Faltan datos esenciales para formatear la tabla.")
        tabla_final_md = "Lo siento, falta informaci√≥n para generar el resumen completo de tus preferencias."
    else:
        try:
            prefs_dict_para_tabla = preferencias_obj.model_dump(mode='json', exclude_none=False) if preferencias_obj else {}
            filtros_dict_para_tabla = filtros_actualizados_obj.model_dump(mode='json', exclude_none=False) if filtros_actualizados_obj else {}
            econ_dict_para_tabla = economia_obj.model_dump(mode='json', exclude_none=False) if economia_obj else {}
            info_clima_dict_para_tabla = info_clima_obj.model_dump(mode='json', exclude_none=False) if info_clima_obj else {}
            info_pasajeros_dict_para_tabla = info_pasajeros_obj.model_dump(mode='json', exclude_none=False) if info_pasajeros_obj else {}
            
            tabla_final_md = formatear_preferencias_en_tabla(
                preferencias=prefs_dict_para_tabla, 
                filtros=filtros_dict_para_tabla, 
                economia=econ_dict_para_tabla,
                codigo_postal_usuario=codigo_postal_val,
                info_clima_usuario=info_clima_dict_para_tabla,
                info_pasajeros=info_pasajeros_dict_para_tabla 
            )
            logging.debug("\n--- TABLA RESUMEN GENERADA INTERNAMENTE (DEBUG) ---\n" + tabla_final_md + "\n--------------------------------------\n")
        except Exception as e_format:
            logging.error(f"ERROR (FormatearTabla) ‚ñ∫ Fallo formateando la tabla: {e_format}")
            traceback.print_exc() 
            tabla_final_md = "Hubo un inconveniente al generar el resumen de tus preferencias."

    # Devolver solo las claves del estado que este nodo modifica
    return {
        "tabla_resumen_criterios": tabla_final_md,
        "pregunta_pendiente": None # Asegurar que se limpie
    }

  # --- Fin Etapa 4 ---
from config.settings import (MAPA_FRECUENCIA_USO, MAPA_DISTANCIA_TRAYECTO, MAPA_FRECUENCIA_VIAJES_LARGOS, MAPA_REALIZA_VIAJES_LARGOS_KM )

# --- ‚úÖ NUEVA FUNCI√ìN PARA SER USADA COMO NODO INDEPENDIENTE ---
def calcular_km_anuales_postprocessing_node(state: EstadoAnalisisPerfil) -> Dict[str, Optional[int]]:
    """
    Calcula los km_anuales_estimados bas√°ndose en las preferencias del usuario.
    Act√∫a como un nodo del grafo que lee el estado y devuelve el nuevo campo calculado.
    """
    print("--- Ejecutando Nodo: calcular_km_anuales_postprocessing_node ---")
    preferencias = state.get("preferencias_usuario")
    
    if not preferencias:
        logging.warning("WARN (CalcKM) ‚ñ∫ No hay 'preferencias_usuario' en el estado. No se pueden calcular los km.")
        return {"km_anuales_estimados": None}

    # --- Parte 1: Kilometraje por uso habitual (F√≥rmula: 52 * a * b) ---
    frecuencia_uso_val = getattr(preferencias, 'frecuencia_uso', None)
    a = MAPA_FRECUENCIA_USO.get(frecuencia_uso_val, 0)
    print(f"a: {a}")
    
    distancia_trayecto_val = getattr(preferencias, 'distancia_trayecto', None)
    b = MAPA_DISTANCIA_TRAYECTO.get(distancia_trayecto_val, 0)
    print(f"b: {b} -> 52 * {a} * {b}")
    
    km_habituales = 52 * a * b

    # --- Parte 2: Kilometraje por viajes largos (F√≥rmula: n * c) ---
    realiza_viajes_largos_val = getattr(preferencias, 'realiza_viajes_largos', 'no')
    n_key = "s√≠" if is_yes(realiza_viajes_largos_val) else "no"
    n = MAPA_REALIZA_VIAJES_LARGOS_KM.get(n_key, 0)

    frecuencia_viajes_largos_val = getattr(preferencias, 'frecuencia_viajes_largos', None)
    c = MAPA_FRECUENCIA_VIAJES_LARGOS.get(frecuencia_viajes_largos_val, 0)

    km_viajes_largos = n * c
    
    # --- Parte 3: C√°lculo Final ---
    km_totales = int(km_habituales + km_viajes_largos)

    logging.info(f"DEBUG (CalcKM) ‚ñ∫ C√°lculo: (52 * {a} * {b}) + ({n} * {c}) = {km_totales} km/a√±o")
    
    return {"km_anuales_estimados": km_totales}




def buscar_coches_finales_node(state: EstadoAnalisisPerfil, config: RunnableConfig) -> dict:
    """
    Usa los filtros y pesos finales, busca en BQ, y presenta un mensaje combinado
    con el resumen de criterios y los resultados de los coches.
    """
    print("--- Ejecutando Nodo: buscar_coches_finales_node ---")
    logging.debug(f"DEBUG (Buscar BQ Init) ‚ñ∫ Estado completo recibido: {state}") 
    k_coches = 12 
    historial = state.get("messages", [])
    tabla_resumen_criterios_md = state.get("tabla_resumen_criterios", "No se pudo generar el resumen de criterios.")
    preferencias_obj = state.get("preferencias_usuario") # Objeto PerfilUsuario
    filtros_finales_obj = state.get("filtros_inferidos") 
    pesos_finales = state.get("pesos")
    economia_obj = state.get("economia")
    penalizar_puertas_flag = state.get("penalizar_puertas_bajas", False)
    flag_penalizar_lc_comod = state.get("flag_penalizar_low_cost_comodidad", False)
    flag_penalizar_dep_comod = state.get("flag_penalizar_deportividad_comodidad", False)
    flag_penalizar_antiguo_tec_val = state.get("flag_penalizar_antiguo_por_tecnologia", False)
    flag_aplicar_distintivo_val = state.get("aplicar_logica_distintivo_ambiental", False)
    flag_es_zbe_val = state.get("es_municipio_zbe", False)
    # Flags de aventura y penalizaci√≥n de mec√°nica
    flag_pen_bev_reev_avent_ocas = state.get("penalizar_bev_reev_aventura_ocasional", False)
    flag_pen_phev_avent_ocas= state.get("penalizar_phev_aventura_ocasional", False)
    flag_pen_electrif_avent_extr = state.get("penalizar_electrificados_aventura_extrema", False)
    flag_fav_car_montana_val = state.get("favorecer_carroceria_montana", False)
    flag_fav_car_comercial_val = state.get("favorecer_carroceria_comercial", False)
    flag_fav_car_pasajeros_pro_val = state.get("favorecer_carroceria_pasajeros_pro", False)
    flag_desfav_car_no_aventura_val = state.get("desfavorecer_carroceria_no_aventura", False)
    flag_fav_suv_aventura_ocasional = state.get("favorecer_suv_aventura_ocasional")
    flag_fav_pickup_todoterreno_aventura_extrema = state.get("favorecer_pickup_todoterreno_aventura_extrema")
    flag_aplicar_logica_objetos_especiales= state.get("aplicar_logica_objetos_especiales")
    flag_fav_carroceria_confort= state.get("favorecer_carroceria_confort")
    flag_logica_uso_ocasional = state.get("flag_logica_uso_ocasional")
    flag_favorecer_bev_uso_definido = state.get("flag_favorecer_bev_uso_definido")
    flag_penalizar_phev_uso_intensivo = state.get("flag_penalizar_phev_uso_intensivo")
    flag_favorecer_electrificados_por_punto_carga = state.get("flag_favorecer_electrificados_por_punto_carga")
    flag_logica_diesel_ciudad= state.get("flag_logica_diesel_ciudad")
    penalizar_awd_ninguna_val = state.get("penalizar_awd_ninguna_aventura", False)
    favorecer_awd_ocasional_val = state.get("favorecer_awd_aventura_ocasional", False)
    favorecer_awd_extrema_val = state.get("favorecer_awd_aventura_extrema", False)
    flag_bonus_nieve_val = state.get("flag_bonus_awd_nieve", False)
    flag_bonus_montana_val = state.get("flag_bonus_awd_montana", False)
    flag_reductoras_aventura_val = state.get("flag_logica_reductoras_aventura")
    flag_bonus_awd_clima_adverso = state.get("flag_bonus_awd_clima_adverso")
    km_anuales_val = state.get("km_anuales_estimados")

    
    # 2. Obt√©n el thread_id directamente del objeto 'config'
    # Esta es la forma correcta y segura de accederlo.
    configurable_config = config.get("configurable", {})
    thread_id = configurable_config.get("thread_id", "unknown_thread_in_node") # Fallback por si acaso

    logging.info(f"INFO (Buscar BQ) ‚ñ∫ Ejecutando b√∫squeda para thread_id: {thread_id}")
    # thread_id = "unknown_thread"
    # if state.get("config") and isinstance(state["config"], dict) and \
    #    state["config"].get("configurable") and isinstance(state["config"]["configurable"], dict):
    #     thread_id = state["config"]["configurable"].get("thread_id", "unknown_thread")
    
    coches_encontrados_raw = [] 
    coches_encontrados = []
    sql_ejecutada = None 
    params_ejecutados = None 
    mensaje_coches = "No pude realizar la b√∫squeda de coches en este momento." # Default para la parte de coches

    if filtros_finales_obj and pesos_finales:
        filtros_para_bq = {}
        if hasattr(filtros_finales_obj, "model_dump"):
             filtros_para_bq.update(filtros_finales_obj.model_dump(mode='json', exclude_none=True))
        elif isinstance(filtros_finales_obj, dict): 
             filtros_para_bq.update({k: v for k, v in filtros_finales_obj.items() if v is not None})

        if economia_obj and economia_obj.modo == 2:
            filtros_para_bq['modo'] = 2
            filtros_para_bq['submodo'] = economia_obj.submodo
            if economia_obj.submodo == 1:
                 filtros_para_bq['pago_contado'] = economia_obj.pago_contado
            elif economia_obj.submodo == 2:
                 filtros_para_bq['cuota_max'] = economia_obj.cuota_max
        
        filtros_para_bq['penalizar_puertas_bajas'] = penalizar_puertas_flag
        filtros_para_bq['flag_penalizar_low_cost_comodidad'] = flag_penalizar_lc_comod
        filtros_para_bq['flag_penalizar_deportividad_comodidad'] = flag_penalizar_dep_comod
        filtros_para_bq['flag_penalizar_antiguo_por_tecnologia'] = flag_penalizar_antiguo_tec_val
        filtros_para_bq['aplicar_logica_distintivo_ambiental'] = flag_aplicar_distintivo_val
        filtros_para_bq['penalizar_bev_reev_aventura_ocasional'] = flag_pen_bev_reev_avent_ocas
        filtros_para_bq['penalizar_phev_aventura_ocasional'] = flag_pen_phev_avent_ocas
        filtros_para_bq['penalizar_electrificados_aventura_extrema'] = flag_pen_electrif_avent_extr
        filtros_para_bq['es_municipio_zbe'] = flag_es_zbe_val
        filtros_para_bq['favorecer_carroceria_montana'] = flag_fav_car_montana_val
        filtros_para_bq['favorecer_carroceria_comercial'] = flag_fav_car_comercial_val
        filtros_para_bq['favorecer_carroceria_pasajeros_pro'] = flag_fav_car_pasajeros_pro_val
        filtros_para_bq['desfavorecer_carroceria_no_aventura'] = flag_desfav_car_no_aventura_val
        filtros_para_bq['favorecer_suv_aventura_ocasional'] = flag_fav_suv_aventura_ocasional
        filtros_para_bq['favorecer_pickup_todoterreno_aventura_extrema'] = flag_fav_pickup_todoterreno_aventura_extrema
        filtros_para_bq['aplicar_logica_objetos_especiales'] = flag_aplicar_logica_objetos_especiales
        filtros_para_bq['favorecer_carroceria_confort'] = flag_fav_carroceria_confort
        filtros_para_bq['flag_logica_uso_ocasional'] = flag_logica_uso_ocasional
        filtros_para_bq['flag_favorecer_bev_uso_definido'] = flag_favorecer_bev_uso_definido
        filtros_para_bq['flag_penalizar_phev_uso_intensivo'] = flag_penalizar_phev_uso_intensivo
        filtros_para_bq['flag_favorecer_electrificados_por_punto_carga'] = flag_favorecer_electrificados_por_punto_carga
        filtros_para_bq['flag_logica_diesel_ciudad'] = flag_logica_diesel_ciudad
        filtros_para_bq['penalizar_awd_ninguna_aventura'] = penalizar_awd_ninguna_val
        filtros_para_bq['favorecer_awd_aventura_ocasional'] = favorecer_awd_ocasional_val
        filtros_para_bq['favorecer_awd_aventura_extrema'] = favorecer_awd_extrema_val
        filtros_para_bq['flag_bonus_nieve_val'] = flag_bonus_nieve_val
        filtros_para_bq['flag_bonus_montana_val'] = flag_bonus_montana_val
        filtros_para_bq['flag_logica_reductoras_aventura'] = flag_reductoras_aventura_val
        filtros_para_bq['flag_bonus_awd_clima_adverso'] = flag_bonus_awd_clima_adverso
        filtros_para_bq['km_anuales_estimados'] = km_anuales_val
        
        logging.debug(f"DEBUG (Buscar BQ) ‚ñ∫ Llamando a buscar_coches_bq con k={k_coches}")
        logging.debug(f"DEBUG (Buscar BQ) ‚ñ∫ Filtros para BQ: {filtros_para_bq}") 
        logging.debug(f"DEBUG (Buscar BQ) ‚ñ∫ Pesos para BQ: {pesos_finales}") 
        
        try:
            resultados_tupla = buscar_coches_bq(
                filtros=filtros_para_bq, 
                pesos=pesos_finales, 
                k=k_coches
            )
            if isinstance(resultados_tupla, tuple) and len(resultados_tupla) == 3: #val coches encontrados (coches_encontrados_raw),(sql_ejecutada),(params_ejecutados).
                coches_encontrados_raw, sql_ejecutada, params_ejecutados = resultados_tupla
            else: 
                logging.warning("WARN (Buscar BQ) ‚ñ∫ buscar_coches_bq no devolvi√≥ SQL/params. Logueo ser√° parcial.")
                coches_encontrados_raw = resultados_tupla if isinstance(resultados_tupla, list) else []
            # --- SANITIZACI√ìN DE NaN ---
            if coches_encontrados_raw:
                for coche_raw in coches_encontrados_raw:
                    coches_encontrados.append(sanitize_dict_for_json(coche_raw))
                logging.info(f"INFO (Buscar BQ) ‚ñ∫ {len(coches_encontrados_raw)} coches crudos se limpian NaN para ->  {len(coches_encontrados)} coches.")
            # --- FIN SANITIZACI√ìN ---
            
            if coches_encontrados:
                mensaje_coches = f"¬°Listo! Basado en todo lo que hablamos, aqu√≠ tienes {len(coches_encontrados)} coche(s) que podr√≠an interesarte:\n\n"
                
                ##CODIGO BUCLE PARA CUANDO INTEGREMOS LOGICA EXPLICACION LLM
                # #coches_para_df = []
                # for i, coche_dict_completo in enumerate(coches_encontrados):
                #     # --- LLAMAR AL NUEVO GENERADOR DE EXPLICACIONES ---
                #     explicacion_coche = generar_explicacion_coche_mejorada(
                #         coche_dict_completo=coche_dict_completo,
                #         preferencias_usuario=preferencias_obj,
                #         pesos_normalizados=pesos_finales,
                #         flag_penalizar_lc_comod=flag_penalizar_lc_comod,
                #         flag_penalizar_dep_comod=flag_penalizar_dep_comod,
                #         flag_penalizar_ant_tec=flag_penalizar_antiguo_tec_val,
                #         flag_es_zbe=flag_es_zbe_val,
                #         flag_aplicar_dist_gen=flag_aplicar_distintivo_val,
                #         flag_penalizar_puertas = penalizar_puertas_flag,                 
                #     )
                #     # --- FIN LLAMADA ---
                #     # A√±adir la explicaci√≥n al string del mensaje
                #     # (Formato m√°s integrado con la tabla)
                #     mensaje_coches += f"\n**{i+1}. {coche_dict_completo.get('nombre', 'Coche Desconocido')}**"
                #     if coche_dict_completo.get('precio_compra_contado') is not None:
                #         precio_f = f"{coche_dict_completo.get('precio_compra_contado'):,.0f}‚Ç¨".replace(",",".")
                #         mensaje_coches += f" - {precio_f}"
                #     if coche_dict_completo.get('score_total') is not None:
                #         score_f = f"{coche_dict_completo.get('score_total'):.3f}"
                #         mensaje_coches += f" (Score: {score_f})"
                #     mensaje_coches += f"\n   *Por qu√© podr√≠a interesarte:* {explicacion_coche}\n"


                # Si quieres una tabla resumen de los coches (adem√°s de la explicaci√≥n individual)
                # df_coches_display = pd.DataFrame(coches_para_df)
                # columnas_deseadas_tabla = ['N¬∫', 'nombre', 'marca', 'precio_compra_contado', 'score_total', 'tipo_carroceria', 'tipo_mecanica']
                # # ... (formateo de columnas del df_coches_display) ...
                # tabla_coches_md = df_coches_display[columnas_deseadas_tabla].to_markdown(index=False)
                # mensaje_coches += "\n" + tabla_coches_md + "\n"
                
                mensaje_coches += "\n¬øQu√© te parecen estas opciones? ¬øHay alguno que te interese para ver m√°s detalles?\n"
                try:
                    df_coches = pd.DataFrame(coches_encontrados)
                    columnas_deseadas = [ # Define tus columnas deseadas
                        'nombre', 'marca', 'precio_compra_contado', 'score_total',
                        'tipo_carroceria', 'tipo_mecanica', 'traccion', 'reductoras' 
                        # ... a√±ade m√°s columnas si las necesitas en la tabla de coches ...
                    ]
                    columnas_a_mostrar = [col for col in columnas_deseadas if col in df_coches.columns]
                    
                    if columnas_a_mostrar:
                        if 'precio_compra_contado' in df_coches.columns:
                            df_coches['precio_compra_contado'] = df_coches['precio_compra_contado'].apply(lambda x: f"{x:,.0f}‚Ç¨".replace(",",".") if isinstance(x, (int, float)) else "N/A")
                        if 'score_total' in df_coches.columns:
                             df_coches['score_total'] = df_coches['score_total'].apply(lambda x: f"{x:.3f}" if isinstance(x, float) else x)
                        tabla_coches_md = df_coches[columnas_a_mostrar].to_markdown(index=False)
                        mensaje_coches += tabla_coches_md
                    else:
                        mensaje_coches += "No se pudieron formatear los detalles de los coches."
                except Exception as e_format_coches:
                    logging.error(f"ERROR (Buscar BQ) ‚ñ∫ Fall√≥ el formateo de la tabla de coches: {e_format_coches}")
                    mensaje_coches += "Hubo un problema al mostrar los detalles. Aqu√≠ una lista simple:\n"
                    for i, coche in enumerate(coches_encontrados):
                        nombre = coche.get('nombre', 'N/D'); precio = coche.get('precio_compra_contado')
                        precio_str = f"{precio:,.0f}‚Ç¨".replace(",",".") if isinstance(precio, (int, float)) else "N/A"
                        mensaje_coches += f"{i+1}. {nombre} - {precio_str}\n"
                # mensaje_coches += "\n\n¬øQu√© te parecen estas opciones? ¬øHay alguno que te interese para ver m√°s detalles o hacemos otra b√∫squeda?"
                
                
            else:
                # ... (Tu l√≥gica de sugerencias heur√≠sticas para mensaje_coches) ...
                mensaje_coches = "He aplicado todos tus filtros, pero no encontr√© coches que coincidan exactamente. ¬øQuiz√°s quieras redefinir alg√∫n criterio?"
                print("INFO (Buscar BQ) ‚ñ∫ No se encontraron coches. Intentando generar sugerencia.")
                
                # Usaremos esta variable para construir la sugerencia
                _sugerencia_generada = None
                
                # Heur√≠stica 1: Tipo de Mec√°nica
                tipos_mecanica_actuales = filtros_para_bq.get("tipo_mecanica", [])
                mecanicas_electricas_puras = {"BEV", "REEV"} # Conjunto para chequeo eficiente
                es_solo_electrico_puro = all(m in mecanicas_electricas_puras for m in tipos_mecanica_actuales)
                
                if tipos_mecanica_actuales and es_solo_electrico_puro and len(tipos_mecanica_actuales) <= 3:
                    _sugerencia_generada = (
                        "No encontr√© coches que sean √∫nicamente 100% el√©ctricos (como BEV o REEV) "
                        "con el resto de tus criterios. ¬øTe gustar√≠a que ampl√≠e la b√∫squeda para incluir tambi√©n "
                        "veh√≠culos h√≠bridos (enchufables o no) y de gasolina?"
                    )
                
                # Heur√≠stica 2: Precio/Cuota (si no se sugiri√≥ mec√°nica)
                if not _sugerencia_generada: # Solo si no se hizo la sugerencia anterior
                    precio_actual = filtros_para_bq.get("precio_max_contado_recomendado") or filtros_para_bq.get("pago_contado")
                    cuota_actual = filtros_para_bq.get("cuota_max_calculada") or filtros_para_bq.get("cuota_max")

                    if precio_actual is not None:
                        nuevo_precio_sugerido = int(precio_actual * 1.20)
                        _sugerencia_generada = (
                            f"Con el presupuesto actual al contado de aproximadamente {precio_actual:,.0f}‚Ç¨ no he encontrado opciones que cumplan todo lo dem√°s. "
                            f"¬øEstar√≠as dispuesto a considerar un presupuesto hasta unos {nuevo_precio_sugerido:,.0f}‚Ç¨?"
                        )
                    elif cuota_actual is not None:
                        nueva_cuota_sugerida = int(cuota_actual * 1.20)
                        _sugerencia_generada = (
                            f"Con la cuota mensual de aproximadamente {cuota_actual:,.0f}‚Ç¨ no he encontrado opciones. "
                            f"¬øPodr√≠amos considerar una cuota hasta unos {nueva_cuota_sugerida:,.0f}‚Ç¨/mes?"
                        )
                if _sugerencia_generada:
                    mensaje_coches = _sugerencia_generada # Usar la sugerencia espec√≠fica
                
                if not _sugerencia_generada: # Si ninguna heur√≠stica aplic√≥
                    _sugerencia_generada = "He aplicado todos tus filtros, pero no encontr√© coches que coincidan exactamente en este momento. ¬øQuiz√°s quieras redefinir alg√∫n criterio general?"
                mensaje_coches = _sugerencia_generada

        except Exception as e_bq:
            logging.error(f"ERROR (Buscar BQ) ‚ñ∫ Fall√≥ la ejecuci√≥n de buscar_coches_bq: {e_bq}")
            traceback.print_exc()
            mensaje_coches = f"Lo siento, tuve un problema al buscar en la base de datos: {e_bq}"
    else:
        logging.error("ERROR (Buscar BQ) ‚ñ∫ Faltan filtros o pesos finales en el estado para la b√∫squeda.")
        mensaje_coches = "Lo siento, falta informaci√≥n interna para realizar la b√∫squeda final."

    # Logueo a BigQuery (como lo ten√≠as)
    if filtros_finales_obj and pesos_finales: 
        try:
            log_busqueda_a_bigquery(
                id_conversacion=thread_id,
                preferencias_usuario_obj=state.get("preferencias_usuario"),
                filtros_aplicados_obj=filtros_finales_obj, 
                economia_usuario_obj=economia_obj,
                pesos_aplicados_dict=pesos_finales,
                tabla_resumen_criterios_md=tabla_resumen_criterios_md, # <-- Viene del estado
                coches_recomendados_list=coches_encontrados,
                num_coches_devueltos=len(coches_encontrados),
                sql_query_ejecutada=sql_ejecutada, # <-- De la llamada a buscar_coches_bq
                sql_params_list=params_ejecutados  # <-- De la llamada a buscar_coches_bq
            )
        except Exception as e_log:
            print(f"ERROR (Buscar BQ) ‚ñ∫ Fall√≥ el logueo a BigQuery: {e_log}")
            traceback.print_exc()
#     # --- FIN LLAMADA AL LOGGER ---
        pass # Placeholder

    # --- CONSTRUIR MENSAJE FINAL COMBINADO ---
    mensaje_final_completo = f"{tabla_resumen_criterios_md}\n\n---\n\n{mensaje_coches}"
    
    final_ai_msg = AIMessage(content=mensaje_final_completo)
    historial_final = list(historial) 
    if not historial or historial[-1].content != final_ai_msg.content:
        historial_final.append(final_ai_msg)
    else:
        logging.debug("DEBUG (Buscar BQ) ‚ñ∫ Mensaje final combinado duplicado, no se a√±ade.")

    # Devolver estado final
    return {
        "messages": historial_final,
        "coches_recomendados": coches_encontrados, 
        "tabla_resumen_criterios": tabla_resumen_criterios_md, # Propagar la tabla (√∫til para logging)
        # Propagar otros campos del estado que no se modifican aqu√≠ pero son necesarios
        "preferencias_usuario": state.get("preferencias_usuario"),
        "info_pasajeros": state.get("info_pasajeros"),
        "filtros_inferidos": filtros_finales_obj, 
        "economia": economia_obj, 
        "pesos": pesos_finales, 
        "penalizar_puertas_bajas": penalizar_puertas_flag, 
       # "priorizar_ancho": state.get("priorizar_ancho"), 
        "flag_penalizar_low_cost_comodidad": flag_penalizar_lc_comod,
        "flag_penalizar_deportividad_comodidad": flag_penalizar_dep_comod, 
        "flag_penalizar_antiguo_por_tecnologia": flag_penalizar_antiguo_tec_val,
        "aplicar_logica_distintivo_ambiental": flag_aplicar_distintivo_val,
        "es_municipio_zbe": flag_es_zbe_val, 
        "penalizar_bev_reev_aventura_ocasional": flag_pen_bev_reev_avent_ocas,
        "penalizar_phev_aventura_ocasional": flag_pen_phev_avent_ocas,
        "penalizar_electrificados_aventura_extrema": flag_pen_electrif_avent_extr,
        "codigo_postal_usuario": state.get("codigo_postal_usuario"),
        "info_clima_usuario": state.get("info_clima_usuario"),
        "favorecer_carroceria_montana": flag_fav_car_montana_val,
        "favorecer_carroceria_comercial": flag_fav_car_comercial_val,
        "favorecer_carroceria_pasajeros_pro": flag_fav_car_pasajeros_pro_val,
        "desfavorecer_carroceria_no_aventura": flag_desfav_car_no_aventura_val,
        "favorecer_suv_aventura_ocasional" : flag_fav_suv_aventura_ocasional,
        'favorecer_pickup_todoterreno_aventura_extrema' : flag_fav_pickup_todoterreno_aventura_extrema,
        'aplicar_logica_objetos_especiales' : flag_aplicar_logica_objetos_especiales,
        'favorecer_carroceria_confort' : flag_fav_carroceria_confort,
        'flag_logica_uso_ocasional' : flag_logica_uso_ocasional,
        'flag_favorecer_bev_uso_definido' : flag_favorecer_bev_uso_definido,
        'flag_penalizar_phev_uso_intensivo': flag_penalizar_phev_uso_intensivo,
        'flag_favorecer_electrificados_por_punto_carga': flag_favorecer_electrificados_por_punto_carga,
        'flag_logica_diesel_ciudad': flag_logica_diesel_ciudad ,
        'penalizar_awd_ninguna_aventura' : penalizar_awd_ninguna_val,
        'favorecer_awd_aventura_ocasional' : favorecer_awd_ocasional_val,
        'favorecer_awd_aventura_extrema' : favorecer_awd_extrema_val,
        'flag_logica_reductoras_aventura' :flag_reductoras_aventura_val,
        'flag_bonus_awd_clima_adverso' : flag_bonus_awd_clima_adverso,
        "pregunta_pendiente": None, # Este nodo es final para el turno
    }

 