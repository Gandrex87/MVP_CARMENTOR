{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion del Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CONFIGURACI√ìN INICIAL (Tu c√≥digo actual) ---\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "from graph.perfil.builder import build_sequential_agent_graph # Ajusta la ruta si es necesario\n",
    "import logging\n",
    "\n",
    "# Configuraci√≥n del logging para ver todo el detalle\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Construir el grafo\n",
    "graph = build_sequential_agent_graph()\n",
    "\n",
    "# --- 2. DEFINE EL 'CONFIG MAESTRO' PARA LA CONVERSACI√ìN ---\n",
    "# Usamos tu 'thread_id' fijo y a√±adimos la clave 'interrupt_after'.\n",
    "# Este config se reutilizar√° en todas las llamadas para esta conversaci√≥n.\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"1\", # Usando tu thread_id\n",
    "    },\n",
    "    \"interrupt_after\": [\n",
    "        \"generar_mensaje_transicion_perfil\",\n",
    "        \"generar_mensaje_transicion_pasajeros\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n lista. Iniciando la prueba de conversaci√≥n.\")\n",
    "print(f\"   ID de Conversaci√≥n (thread_id): {config['configurable']['thread_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- TURNO 1: CP ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'HumanMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- TURNO 1: El usuario da su C√≥digo Postal ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- TURNO 1: CP ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m input_message_1 = \u001b[43mHumanMessage\u001b[49m(content=\u001b[33m\"\u001b[39m\u001b[33mmi cp es 46009\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m output_1 = graph.invoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [input_message_1]}, config) \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Imprimimos la respuesta del agente\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'HumanMessage' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- TURNO 1: El usuario da su C√≥digo Postal ---\n",
    "print(\"\\n\\n--- TURNO 1: CP ---\")\n",
    "input_message_1 = HumanMessage(content=\"mi cp es 46009\")\n",
    "output_1 = graph.invoke({\"messages\": [input_message_1]}, config) \n",
    "# Imprimimos la respuesta del agente\n",
    "if output_1['messages'][-1]:\n",
    "    output_1['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- TURNO 1: El usuario da su C√≥digo Postal ---\n",
    "print(\"\\n\\n--- TURNO 1: CP ---\")\n",
    "input_message_1 = HumanMessage(content=\"si\")\n",
    "output_1 = graph.invoke({\"messages\": [input_message_1]}, config) \n",
    "# Imprimimos la respuesta del agente\n",
    "if output_1['messages'][-1]:\n",
    "    output_1['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- TURNO 1: El usuario da su C√≥digo Postal ---\n",
    "print(\"\\n\\n--- TURNO 1: CP ---\")\n",
    "input_message_1 = HumanMessage(content=\"7\")\n",
    "output_1 = graph.invoke({\"messages\": [input_message_1]}, config) \n",
    "# Imprimimos la respuesta del agente\n",
    "if output_1['messages'][-1]:\n",
    "    output_1['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Esta es la llamada que activar√° la interrupci√≥n.\n",
    "print(\"\\n\\n--- TURNO CLAVE: El usuario completa el perfil ---\")\n",
    "input_message_final_perfil = HumanMessage(content=\"un 8, le doy mucha importancia\")\n",
    "\n",
    "# LLAMADA 1: El grafo se ejecutar√° y se detendr√° despu√©s del mensaje de transici√≥n.\n",
    "output_transicion = graph.invoke({\"messages\": [input_message_final_perfil]}, config)\n",
    "\n",
    "# Imprimimos el √∫ltimo mensaje. Deber√≠a ser el mensaje de transici√≥n.\n",
    "print(\"\\n================================== Ai Message (TRANSICI√ìN) ================================\")\n",
    "if output_transicion['messages'][-1]:\n",
    "    output_transicion['messages'][-1].pretty_print()\n",
    "print(\"========================================================================================\\n\")\n",
    "print(\"‚ÑπÔ∏è El grafo se ha detenido despu√©s del mensaje de transici√≥n, como se esperaba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLAMADA 2: El grafo contin√∫a desde la interrupci√≥n.\n",
    "output_continuacion = graph.invoke(None, config)\n",
    "\n",
    "# Imprimimos el √∫ltimo mensaje. Ahora deber√≠a ser la primera pregunta sobre pasajeros.\n",
    "print(\"\\n================================== Ai Message (CONTINUACI√ìN) ==============================\")\n",
    "if output_continuacion['messages'][-1]:\n",
    "    output_continuacion['messages'][-1].pretty_print()\n",
    "print(\"========================================================================================\\n\")\n",
    "print(\"‚úÖ ¬°√âxito! El agente ha formulado la siguiente pregunta de la nueva etapa.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno local detectado. Verificando GOOGLE_APPLICATION_CREDENTIALS del archivo .env...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from IPython.display import Image, display\n",
    "from graph.perfil.builder import build_sequential_agent_graph\n",
    "import logging\n",
    "\n",
    "# --- CONFIGURACI√ìN DEL LOGGING ---\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "#logging.getLogger().setLevel(level=logging.DEBUG)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG) #o level=logging.DEBUG\n",
    "\n",
    "\n",
    "# Construir el grafo\n",
    "graph = build_sequential_agent_graph()\n",
    "#display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? False\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_cp (Etapa CP no completada)\n",
      "--- Ejecutando Nodo: buscar_info_clima_node ---\n",
      "DEBUG (Clima) ‚ñ∫ Buscando datos clim√°ticos para CP: 46009\n",
      "DEBUG (BQ Clima) ‚ñ∫ Query: \n",
      "        SELECT\n",
      "            EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE MUNICIPIO_ZBE = @cp_param) AS MUNICIPIO_ZBE,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_LLUVIAS = @cp_param) AS ZONA_LLUVIAS,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_NIEBLAS = @cp_param) AS ZONA_NIEBLAS,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_NIEVE = @cp_param) AS ZONA_NIEVE,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_CLIMA_MONTA = @cp_param) AS ZONA_CLIMA_MONTA,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_GLP = @cp_param) AS ZONA_GLP,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_GNV = @cp_param) AS ZONA_GNV\n",
      "        \n",
      "DEBUG (BQ Clima) ‚ñ∫ Params: 46009\n",
      "DEBUG (Clima) ‚ñ∫ Datos clim√°ticos encontrados: {'MUNICIPIO_ZBE': True, 'ZONA_LLUVIAS': False, 'ZONA_NIEBLAS': False, 'ZONA_NIEVE': False, 'ZONA_CLIMA_MONTA': False, 'ZONA_GLP': True, 'ZONA_GNV': True, 'cp_valido_encontrado': True, 'codigo_postal_consultado': '46009'}\n",
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øLos coches son una de tus grandes aficiones?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"46009\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øEl aspecto del coche influye mucho en tu elecci√≥n, o no tanto?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øEste ser√° el coche que m√°s vas a utilizar en el d√≠a a d√≠a?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"el aspecto no influye mucho\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øCon qu√© frecuencia usar√°s el coche?\n",
      "* üí® A diario (incluso varias veces al d√≠a)\n",
      "* üîÑ Frecuentemente (varias veces por semana)\n",
      "* üïê Ocasionalmente (pocas veces al mes)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øCu√°ntos kil√≥metros haces, por lo general, en un trayecto t√≠pico?\n",
      "* üü£ Hasta 10 km\n",
      "* üü° 10-50 km\n",
      "* üü† 51-150 km\n",
      "* üîµ M√°s de 150 km\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"a diario\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Pensando en viajes m√°s largos, ¬ørealizas recorridos de m√°s de 150 km de vez en cuando?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hasta 10km\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øTu uso principal del coche es en ciudad?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øLo emplear√°s principalmente como coche de uso particular o como herramienta de trabajo?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øLo emplear√°s principalmente como coche de uso particular o como herramienta de trabajo?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"sera de uso particular\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øEres de los que conducen para diferenciarse o prefieres no destacar demasiado?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"particular\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øSuperas el 1,90 m de altura? Esto influye en el espacio del coche que elijamos.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"prefiero no destacar\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øAcostumbras a viajar con el maletero muy cargado?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øEl coche que buscas deber√≠a poder tirar de una caravana o remolque sin problemas?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no llevo nada en el maletero\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øCon qu√© tipo de terreno se enfrentar√° tu coche? :\n",
      "* üõ£Ô∏è Solo asfalto\n",
      "* üå≤ Tambi√©n por pistas sin asfaltar, de forma ocasional\n",
      "* üèîÔ∏è Frecuentemente por terrenos complicados o en condiciones extremas\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øConduces de forma relajada o prefieres sensaciones m√°s deportivas?\n",
      "* üöó Relajada\n",
      "* üèÅ Deportiva\n",
      "* ‚öñÔ∏è Depende del d√≠a, mixto\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"asfalto\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hablemos un poco de d√≥nde aparcar√°s. ¬øTienes garaje o plaza de aparcamiento propia?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la primera\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"preferencias_usuario\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬°Genial lo del garaje/plaza! Y dime, ¬øel espacio que tienes es amplio y te permite aparcar un coche de cualquier tama√±o con comodidad?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Comprendo que el espacio es ajustado. ¬øCu√°l es la principal limitaci√≥n de dimensi√≥n?\n",
      " ‚ÜîÔ∏è Ancho\n",
      " ‚ÜïÔ∏è Alto\n",
      " ‚¨ÖÔ∏è‚û°Ô∏è Largo\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øcuentas con un punto de carga para veh√≠culo el√©ctrico en tu domicilio o lugar de trabajo habitual?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tengo un garaje muy angosto\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apasionado_motor='s√≠' valora_estetica='no' coche_principal_hogar='s√≠' frecuencia_uso=<FrecuenciaUso.DIARIO: 'diario'> distancia_trayecto=<DistanciaTrayecto.MENOS_10_KM: 'no supera los 10 km'> realiza_viajes_largos='no' frecuencia_viajes_largos=None circula_principalmente_ciudad='s√≠' uso_profesional='no' tipo_uso_profesional=None prefiere_diseno_exclusivo='no' altura_mayor_190='no' transporta_carga_voluminosa='no' necesita_espacio_objetos_especiales=None arrastra_remolque='no' tiene_garage='s√≠' problemas_aparcar_calle=None espacio_sobra_garage='no' problema_dimension_garage=[<DimensionProblematica.ANCHO: 'ancho'>] tiene_punto_carga_propio=None aventura=<NivelAventura.ninguna: 'ninguna'> estilo_conduccion=<EstiloConduccion.TRANQUILO: 'tranquilo'> solo_electricos=None prioriza_baja_depreciacion=None transmision_preferida=None rating_fiabilidad_durabilidad=None rating_seguridad=None rating_comodidad=None rating_impacto_ambiental=None rating_tecnologia_conectividad=None rating_costes_uso=None\n"
     ]
    }
   ],
   "source": [
    "print(output['preferencias_usuario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øTu elecci√≥n se centra solo en coches el√©ctricos?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "DEBUG (PostProc Perfil) ‚ñ∫ Aplicando regla: solo_electricos='s√≠' y sin transmision -> asignando AUTOMATICO\n",
      "DEBUG (PostProc Perfil) ‚ñ∫ Perfil tras post-procesamiento: apasionado_motor='s√≠' valora_estetica='no' coche_principal_hogar='s√≠' frecuencia_uso=<FrecuenciaUso.DIARIO: 'diario'> distancia_trayecto=<DistanciaTrayecto.MENOS_10_KM: 'no supera los 10 km'> realiza_viajes_largos='no' frecuencia_viajes_largos=None circula_principalmente_ciudad='s√≠' uso_profesional='no' tipo_uso_profesional=None prefiere_diseno_exclusivo='no' altura_mayor_190='no' transporta_carga_voluminosa='no' necesita_espacio_objetos_especiales=None arrastra_remolque='no' tiene_garage='s√≠' problemas_aparcar_calle=None espacio_sobra_garage='no' problema_dimension_garage=[<DimensionProblematica.ANCHO: 'ancho'>] tiene_punto_carga_propio='no' aventura=<NivelAventura.ninguna: 'ninguna'> estilo_conduccion=<EstiloConduccion.TRANQUILO: 'tranquilo'> solo_electricos='s√≠' prioriza_baja_depreciacion=None transmision_preferida=<Transmision.AUTOMATICO: 'autom√°tico'> rating_fiabilidad_durabilidad=None rating_seguridad=None rating_comodidad=None rating_impacto_ambiental=None rating_tecnologia_conectividad=None rating_costes_uso=None\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øTe importa que el coche mantenga bien su valor con el tiempo?\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øCu√°nto valoras que el coche sea fiable y dure muchos a√±os sin dar problemas?\n",
      "üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øQu√© nivel de prioridad le das a la seguridad frente a otros aspectos del coche?\n",
      "üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Y en cuanto a la comodidad y confort del vehiculo como de importante es que sea elevado?\n",
      "üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øQu√© importancia le das a reducir las emisiones y cuidar el medio ambiente con tu coche?\n",
      "üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"4\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øCu√°nto te importa que el coche sea barato de mantener y eficiente en consumo?\n",
      "üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"8\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transici√≥n a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Y para terminar con las valoraciones, ¬øQu√© importancia le das a la tecnolog√≠a de a bordo y sistemas multimedia del veh√≠culo??\n",
      "üìä 0 (nada importante) ‚Äî‚Äî‚Äî‚Äî 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"3\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "‚úÖ Perfil completo. Pasando a 'generar_mensaje_transicion'.\n",
      "--- Ejecutando Nodo: generar_mensaje_transicion_perfil ---\n",
      "INFO: A√±adido mensaje de transici√≥n: '¬°Estupendo! Ya tengo una idea muy clara de tus gustos y preferencias. Ahora, para asegurarnos de que el coche se adapte perfectamente a quienes viajar√°n contigo, hablemos un poco sobre los pasajeros.'\n",
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_info_pasajeros\n",
      "--- [Edge/Pasajeros] Decidiendo siguiente paso de pasajeros ---\n",
      "‚ùå Info Pasajeros incompleta. Transici√≥n a 'preguntar_info_pasajeros'.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øSueles viajar con acompa√±antes en el coche habitualmente?\n",
      "\n",
      "* ‚úÖ S√≠\n",
      "* ‚ùå No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_info_pasajeros\n",
      "--- [Edge/Pasajeros] Decidiendo siguiente paso de pasajeros ---\n",
      "‚úÖ Info Pasajeros completa. Pasando a 'generar_mensaje_transicion_pasajeros'.\n",
      "--- Ejecutando Nodo: generar_mensaje_transicion_pasajeros ---\n",
      "INFO: A√±adido mensaje de transici√≥n de pasajeros: '¬°Genial! Con esto terminamos la secci√≥n de pasajeros. Ahora, si te parece, continuamos con el apartado econ√≥mico para acotar la b√∫squeda.'\n",
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_economia\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Para definir tu presupuesto, ¬øqu√© prefieres?\n",
      "\n",
      "* 1Ô∏è‚É£ Prefiero que me aconsejes con criterios de inteligencia financiera.\n",
      "* 2Ô∏è‚É£ Prefiero indicar yo mismo cu√°nto y c√≥mo gastar.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_economia\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬øCu√°les son tus ingresos netos anuales aproximados? Este dato es clave para darte una recomendaci√≥n financiera s√≥lida.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"1\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_economia\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Gracias. Ahora, ¬øde cu√°ntos ahorros dispones para la compra del veh√≠culo?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"mis ingresos son de 50.000 al a√±o\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Econom√≠a OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisi√≥n -> recopilar_economia\n",
      "--- Ejecutando Nodo: construir_filtros_node ---\n",
      "DEBUG (Filtros) ‚ñ∫ Preferencias e info_clima disponibles. Construyendo filtros...\n",
      "DEBUG (Filtros) ‚ñ∫ Filtros finales construidos: tipo_mecanica=[<TipoMecanica.BEV: 'BEV'>, <TipoMecanica.REEV: 'REEV'>] tipo_carroceria=None modo_adquisicion_recomendado='Financiado' precio_max_contado_recomendado=None cuota_max_calculada=395.8333333333333 plazas_min=1\n",
      "--- Ejecutando Nodo: calcular_km_anuales_postprocessing_node ---\n",
      "a: 10\n",
      "b: 10 -> 52 * 10 * 10\n",
      "--- Ejecutando Nodo: calcular_flags_dinamicos_node ---\n",
      "DEBUG contenido de los objetos:  preferencias_obj: apasionado_motor='s√≠' valora_estetica='no' coche_principal_hogar='s√≠' frecuencia_uso=<FrecuenciaUso.DIARIO: 'diario'> distancia_trayecto=<DistanciaTrayecto.MENOS_10_KM: 'no supera los 10 km'> realiza_viajes_largos='no' frecuencia_viajes_largos=None circula_principalmente_ciudad='s√≠' uso_profesional='no' tipo_uso_profesional=None prefiere_diseno_exclusivo='no' altura_mayor_190='no' transporta_carga_voluminosa='no' necesita_espacio_objetos_especiales=None arrastra_remolque='no' tiene_garage='s√≠' problemas_aparcar_calle=None espacio_sobra_garage='no' problema_dimension_garage=[<DimensionProblematica.ANCHO: 'ancho'>] tiene_punto_carga_propio='no' aventura=<NivelAventura.ninguna: 'ninguna'> estilo_conduccion=<EstiloConduccion.TRANQUILO: 'tranquilo'> solo_electricos='s√≠' prioriza_baja_depreciacion='no' transmision_preferida=<Transmision.AUTOMATICO: 'autom√°tico'> rating_fiabilidad_durabilidad=7 rating_seguridad=2 rating_comodidad=4 rating_impacto_ambiental=8 rating_tecnologia_conectividad=2 rating_costes_uso=3 - pasajeros suele_llevar_acompanantes=False frecuencia_viaje_con_acompanantes=None num_ninos_silla=None num_otros_pasajeros=None - clima MUNICIPIO_ZBE=True ZONA_LLUVIAS=False ZONA_NIEBLAS=False ZONA_NIEVE=False ZONA_CLIMA_MONTA=False ZONA_GLP=True ZONA_GNV=True cp_valido_encontrado=True codigo_postal_consultado='46009'\n",
      "DEBUG (CalcFlags) ‚ñ∫ Valor de preferencias_obj.aventura: NivelAventura.ninguna (Tipo: <enum 'NivelAventura'>)\n",
      "--- Ejecutando Nodo: calcular_pesos_finales_node ---\n",
      "DEBUG_MIO (info_pasajeros_o     bj): suele_llevar_acompanantes=False frecuencia_viaje_con_acompanantes=None num_ninos_silla=None num_otros_pasajeros=None\n",
      "DEBUG_MIO_2: (km_anuales_val): 5200\n",
      "DEBUG (Garaje) ‚ñ∫ Detectado: 'espacio_sobra_garage' es NO.\n",
      "DEBUG (Garaje) ‚ñ∫ Valor de 'problema_dimension_garage': ['ancho']\n",
      "DEBUG (Garaje) ‚ñ∫ ¬°CONDICI√ìN ANCHO CUMPLIDA! Aplicando multiplicador.\n",
      "DEBUG (compute_raw_weights) ‚ñ∫‚ñ∫ Pesos Crudos Finales (listos para normalizar): {'estetica': 0.09899494936611665, 'premium': 0.4979959839195493, 'singular': 0.0709929573971954, 'deportividad_style_score': 0.06557438524302, 'fav_menor_rel_peso_potencia_score': 0.21189620100417092, 'potencia_maxima_style_score': 0.15491933384829668, 'par_motor_style_score': 0.12, 'fav_menor_aceleracion_score': 0.18973665961010275, 'fav_bajo_consumo': 0.12529964086141668, 'fav_bajo_coste_uso_directo': 0.198997487421324, 'fav_bajo_coste_mantenimiento_directo': 0.10862780491200216, 'devaluacion': 0.06782329983125268, 'fav_bajo_peso': 0.09695359714832658, 'par_motor_remolque_score': 0.06782329983125268, 'cap_remolque_cf_score': 0.07681145747868608, 'cap_remolque_sf_score': 0.08306623862918075, 'maletero_minimo_score': 0.21656407827707713, 'maletero_maximo_score': 0.17492855684535902, 'largo_vehiculo_score': 0.11704699910719625, 'fav_menor_largo_garage': 0.15198684153570663, 'fav_menor_ancho_garage': 1.228495014234897, 'fav_menor_alto_garage': 0.13601470508735444, 'fav_menor_superficie_planta': 0.10488088481701516, 'altura_libre_suelo': 0.21517434791350012, 'fav_menor_diametro_giro': 2.1120191760493086, 'batalla': 0.15684387141358122, 'indice_altura_interior': 0.17175564037317667, 'ancho': 0.17888543819998318, 'indice_habitabilidad': 0.22181073012818833, 'autonomia_uso_maxima': 0.27147743920996453, 'autonomia_uso_2nd_drive': 0.12041594578792296, 'menor_tiempo_carga_min': 0.1944222209522358, 'potencia_maxima_carga_AC': 0.10770329614269007, 'potencia_maxima_carga_DC': 0.14247806848775008, 'rating_fiabilidad': 0.24919871588754225, 'rating_durabilidad': 0.1532970971675589, 'rating_comodidad': 0.058309518948453, 'rating_tecnologia_conectividad': 0.0412310562561766, 'rating_seguridad': 0.12041594578792296}\n",
      "DEBUG (Normalize Weights) ‚ñ∫ Pesos Normalizados: {'estetica': 0.011146989179411032, 'premium': 0.05607514201165278, 'singular': 0.007993920225103791, 'deportividad_style_score': 0.007383780358805474, 'fav_menor_rel_peso_potencia_score': 0.023859850172924583, 'potencia_maxima_style_score': 0.017444164062369785, 'par_motor_style_score': 0.013512191380413617, 'fav_menor_aceleracion_score': 0.02136465047110086, 'fav_bajo_consumo': 0.014108939393471303, 'fav_bajo_coste_uso_directo': 0.02240743445215318, 'fav_bajo_coste_mantenimiento_directo': 0.012231664076710065, 'devaluacion': 0.007637011728092174, 'fav_bajo_peso': 0.010917129664064273, 'par_motor_remolque_score': 0.007637011728092174, 'cap_remolque_cf_score': 0.008649092613837577, 'cap_remolque_sf_score': 0.009353390946738307, 'maletero_minimo_score': 0.024385460598356182, 'maletero_maximo_score': 0.019697234483283782, 'largo_vehiculo_score': 0.013179678770329481, 'fav_menor_largo_garage': 0.017113960751125548, 'fav_menor_ancho_garage': 0.13833049785188234, 'fav_menor_alto_garage': 0.015315472714090426, 'fav_menor_superficie_planta': 0.011809754898288548, 'altura_libre_suelo': 0.024228974743024313, 'fav_menor_diametro_giro': 0.2378167275490145, 'batalla': 0.017660870061544116, 'indice_altura_interior': 0.01933995902823216, 'ancho': 0.02014278563439438, 'indice_habitabilidad': 0.024976241964344646, 'autonomia_uso_maxima': 0.03056879261724704, 'autonomia_uso_2nd_drive': 0.013559027539499384, 'menor_tiempo_carga_min': 0.021892252150930606, 'potencia_maxima_carga_AC': 0.012127562914844934, 'potencia_maxima_carga_DC': 0.016043257740984647, 'rating_fiabilidad': 0.02806017284021492, 'rating_durabilidad': 0.017261497624915988, 'rating_comodidad': 0.00656574482776126, 'rating_tecnologia_conectividad': 0.004642682691250487, 'rating_seguridad': 0.013559027539499384}\n",
      "--- Ejecutando Nodo: formatear_tabla_resumen_node ---\n",
      "--- üß† SQL Query Template Enviada a BigQuery ---\n",
      "\n",
      "    WITH ScaledData AS (\n",
      "        SELECT\n",
      "            *,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(estetica, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS estetica_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(premium, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS premium_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(singular, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS singular_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(altura_libre_suelo, 79.0) - 79.0, NULLIF(314.0 - 79.0, 0)), 0) AS altura_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(batalla, 1650.0) - 1650.0, NULLIF(4035.0 - 1650.0, 0)), 0) AS batalla_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(indice_altura_interior, 0.9) - 0.9, NULLIF(2.7 - 0.9, 0)), 0) AS indice_altura_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(ancho, 1410.0) - 1410.0, NULLIF(2164.0 - 1410.0, 0)), 0) AS ancho_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(fiabilidad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS fiabilidad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(durabilidad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS durabilidad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(seguridad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS seguridad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(comodidad, 0.0) - 0.0, NULLIF(10.0 - 0.0, 0)), 0) AS comodidad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(31.0 - COALESCE(costes_de_uso, 31.0), NULLIF(31.0 - 3.0, 0)), 0) AS costes_de_uso_bajo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(10.0 - COALESCE(costes_mantenimiento, 10.0), NULLIF(10.0 - 1.0, 0)), 0) AS costes_mantenimiento_bajo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(tecnologia, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS tecnologia_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(acceso_low_cost, 0.0) - 0.0, NULLIF(10.0 - 0.0, 0)), 0) AS acceso_low_cost_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(deportividad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS deportividad_bq_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(devaluacion, 0.0) - 0.0, NULLIF(10.0 - 0.0, 0)), 0) AS devaluacion_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(maletero_minimo, 11.0) - 11.0, NULLIF(15000.0 - 11.0, 0)), 0) AS maletero_minimo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(maletero_maximo, 11.0) - 11.0, NULLIF(15000.0 - 11.0, 0)), 0) AS maletero_maximo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(largo, 2450.0) - 2450.0, NULLIF(6400.0 - 2450.0, 0)), 0) AS largo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(autonomia_uso_maxima, 30.8) - 30.8, NULLIF(1582.4 - 30.8, 0)), 0) AS autonomia_uso_maxima_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(3500.0 - COALESCE(peso, 3500.0), NULLIF(3500.0 - 470.0, 0)), 0) AS bajo_peso_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(133.0 - COALESCE(indice_consumo_energia, 133.0), NULLIF(133.0 - 7.4, 0)), 0) AS bajo_consumo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(par, 41.0) - 41.0, NULLIF(967.0 - 41.0, 0)), 0) AS par_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(capacidad_remolque_con_freno, 100.0) - 100.0, NULLIF(3600.0 - 100.0, 0)), 0) AS cap_remolque_cf_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(capacidad_remolque_sin_freno, 35.0) - 35.0, NULLIF(1250.0 - 35.0, 0)), 0) AS cap_remolque_sf_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(14.0 - COALESCE(superficie_planta, 14.0), NULLIF(14.0 - 2.9, 0)), 0) AS menor_superficie_planta_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(15.6 - COALESCE(diametro_giro, 15.6), NULLIF(15.6 - 7.0, 0)), 0) AS menor_diametro_giro_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(6400.0 - COALESCE(largo, 6400.0), NULLIF(6400.0 - 2450.0, 0)), 0) AS menor_largo_garage_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(2164.0 - COALESCE(ancho, 2164.0), NULLIF(2164.0 - 1410.0, 0)), 0) AS menor_ancho_garage_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(2940.0 - COALESCE(alto, 2940.0), NULLIF(2940.0 - 1052.0, 0)), 0) AS menor_alto_garage_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(deportividad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS deportividad_style_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(28.3 - COALESCE(relacion_peso_potencia, 28.3), NULLIF(28.3 - 1.8, 0)), 0) AS menor_rel_peso_potencia_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(potencia_maxima, 41.0) - 41.0, NULLIF(789.0 - 41.0, 0)), 0) AS potencia_maxima_style_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(34.0 - COALESCE(aceleracion_0_100, 34.0), NULLIF(34.0 - 2.5, 0)), 0) AS menor_aceleracion_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(autonomia_uso_principal, 21.8) - 21.8, NULLIF(1480.6 - 21.8, 0)), 0) AS autonomia_uso_principal_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(autonomia_uso_2nd_drive, 0.0) - 0.0, NULLIF(936.4 - 0.0, 0)), 0) AS autonomia_uso_2nd_drive_scaled, \n",
      "            (CASE WHEN COALESCE(tiempo_carga_min, 0) = 0 THEN 0.0 ELSE COALESCE(SAFE_DIVIDE(640.1 - tiempo_carga_min, NULLIF(640.1 - 18.0, 0)), 0) END) AS menor_tiempo_carga_min_scaled,\n",
      "            (CASE WHEN COALESCE(potencia_maxima_carga_AC, 0) = 0 THEN 0.0 ELSE COALESCE(SAFE_DIVIDE(potencia_maxima_carga_AC - 2.3, NULLIF(22.0 - 2.3, 0)), 0) END) AS potencia_maxima_carga_AC_scaled,\n",
      "            (CASE WHEN COALESCE(potencia_maxima_carga_DC, 0) = 0 THEN 0.0 ELSE COALESCE(SAFE_DIVIDE(potencia_maxima_carga_DC - 1.0, NULLIF(270.0 - 1.0, 0)), 0) END) AS potencia_maxima_carga_DC_scaled,\n",
      "            \n",
      "        FROM\n",
      "            `thecarmentor-mvp2.web_cars.coches_prueba_2`\n",
      "            --`thecarmentor-mvp2.web_cars.match_coches_pruebas`\n",
      "    ),      \n",
      "    -- ESTE ES EL CTE CLAVE CON TODOS LOS DESGLOSES\n",
      "    DebugScores AS (\n",
      "        SELECT\n",
      "            sd.*,\n",
      "            \n",
      "            -- Desglose de puntuacion_base\n",
      "            (sd.estetica_scaled * @peso_estetica * 100.0) AS dbg_score_estetica,\n",
      "            (sd.premium_scaled * @peso_premium * 100.0) AS dbg_score_premium,\n",
      "            (sd.singular_scaled * @peso_singular * 100.0) AS dbg_score_singular,\n",
      "            (sd.altura_scaled * @peso_altura * 100.0) AS dbg_score_altura_libre,\n",
      "            (sd.batalla_scaled * @peso_batalla * 100.0) AS dbg_score_batalla,\n",
      "            (sd.indice_altura_scaled * @peso_indice_altura * 100.0) AS dbg_score_altura_interior,\n",
      "            (sd.ancho_scaled * @peso_ancho_general_score * 100.0) AS dbg_score_ancho,\n",
      "            (sd.devaluacion_scaled * @peso_devaluacion * 100.0) AS dbg_score_devaluacion,\n",
      "            (sd.maletero_minimo_scaled * @peso_maletero_minimo_score * 100.0) AS dbg_score_maletero_min,\n",
      "            (sd.maletero_maximo_scaled * @peso_maletero_maximo_score * 100.0) AS dbg_score_maletero_max,\n",
      "            (sd.largo_scaled * @peso_largo_vehiculo_score * 100.0) AS dbg_score_largo,\n",
      "            (sd.autonomia_uso_maxima_scaled * @peso_autonomia_vehiculo * 100.0) AS dbg_score_autonomia_max,\n",
      "            (sd.bajo_peso_scaled * @peso_fav_bajo_peso * 100.0) AS dbg_score_bajo_peso,\n",
      "            (sd.par_scaled * @peso_par_motor_remolque_score * 100.0) AS dbg_score_par_remolque,\n",
      "            (sd.cap_remolque_cf_scaled * @peso_cap_remolque_cf_score * 100.0) AS dbg_score_remolque_cf,\n",
      "            (sd.cap_remolque_sf_scaled * @peso_cap_remolque_sf_score * 100.0) AS dbg_score_remolque_sf,\n",
      "            (sd.menor_superficie_planta_scaled * @peso_fav_menor_superficie_planta * 100.0) AS dbg_score_menor_superficie,\n",
      "            (sd.menor_diametro_giro_scaled * @peso_fav_menor_diametro_giro * 100.0) AS dbg_score_menor_giro,\n",
      "            (sd.menor_largo_garage_scaled * @peso_fav_menor_largo_garage * 100.0) AS dbg_score_menor_largo,\n",
      "            (sd.menor_ancho_garage_scaled * @peso_fav_menor_ancho_garage * 100.0) AS dbg_score_menor_ancho,\n",
      "            (sd.menor_alto_garage_scaled * @peso_fav_menor_alto_garage * 100.0) AS dbg_score_menor_alto,\n",
      "            (sd.deportividad_style_scaled * @peso_deportividad_style_score * 100.0) AS dbg_score_deportividad,\n",
      "            (sd.menor_rel_peso_potencia_scaled * @peso_fav_menor_rel_peso_potencia_score * 100.0) AS dbg_score_menor_rel_peso_pot,\n",
      "            (sd.potencia_maxima_style_scaled * @peso_potencia_maxima_style_score * 100.0) AS dbg_score_potencia,\n",
      "            (sd.par_scaled * @peso_par_motor_style_score * 100.0) AS dbg_score_par_deportivo,\n",
      "            --(sd.autonomia_uso_principal_scaled * @peso_autonomia_uso_principal * 100.0) AS dbg_score_autonomia_principal,\n",
      "            (sd.autonomia_uso_2nd_drive_scaled * @peso_autonomia_uso_2nd_drive * 100.0) AS dbg_score_autonomia_2nd,\n",
      "            (sd.menor_tiempo_carga_min_scaled * @peso_menor_tiempo_carga_min * 100.0) AS dbg_score_menor_t_carga,\n",
      "            (sd.potencia_maxima_carga_AC_scaled * @peso_potencia_maxima_carga_AC * 100.0) AS dbg_score_pot_carga_ac,\n",
      "            (sd.potencia_maxima_carga_DC_scaled * @peso_potencia_maxima_carga_DC * 100.0) AS dbg_score_pot_carga_dc,\n",
      "            (sd.menor_aceleracion_scaled * @peso_fav_menor_aceleracion_score * 100.0) AS dbg_score_menor_aceleracion, \n",
      "            -- Desglose de ajustes_experto --\n",
      "            ( (sd.seguridad_scaled * @peso_rating_seguridad) * (CASE WHEN @flag_bonus_seguridad_critico = TRUE THEN 6.0 WHEN @flag_bonus_seguridad_fuerte = TRUE THEN 3.0 ELSE 1.0 END) * 100.0 ) as dbg_bonus_seguridad,\n",
      "                -- Bonus Acumulativo para Fiabilidad\n",
      "            ( (sd.fiabilidad_scaled * @peso_rating_fiabilidad) * ((CASE WHEN @flag_aplicar_logica_distintivo = TRUE THEN 1.2 ELSE 1.0 END) * (CASE WHEN @flag_bonus_fiab_dur_critico = TRUE THEN 2.5 WHEN @flag_bonus_fiab_dur_fuerte = TRUE THEN 1.2 ELSE 1.0 END)) * 100.0 ) as dbg_bonus_fiabilidad,  \n",
      "                -- Bonus Acumulativo para Durabilidad\n",
      "            ( (sd.durabilidad_scaled * @peso_rating_durabilidad) * ((CASE WHEN @flag_aplicar_logica_distintivo = TRUE THEN 1.2 ELSE 1.0 END) * (CASE WHEN @flag_bonus_fiab_dur_critico = TRUE THEN 2.5 WHEN @flag_bonus_fiab_dur_fuerte = TRUE THEN 1.2 ELSE 1.0 END)) * 100.0) as dbg_bonus_durabilidad,\n",
      "            -- ‚úÖ NUEVA L√ìGICA: Bonus proporcional para caracter√≠sticas de COSTE\n",
      "            ( (sd.bajo_consumo_scaled * @peso_fav_bajo_consumo) * (CASE WHEN @flag_bonus_costes_critico = TRUE THEN 4.0 ELSE 1.0 END) * 100.0 )  as dbg_bonus_bajo_consumo,\n",
      "            ( (sd.costes_de_uso_bajo_scaled * @peso_fav_bajo_coste_uso_directo) * (CASE WHEN @flag_bonus_costes_critico = TRUE THEN 4.0 ELSE 1.0 END) * 100.0 )  as dbg_bonus_coste_uso,\n",
      "            ( (sd.costes_mantenimiento_bajo_scaled * @peso_fav_bajo_coste_mantenimiento_directo) * (CASE WHEN @flag_bonus_costes_critico = TRUE THEN 4.0 ELSE 1.0 END) * 100.0 )  as dbg_bonus_coste_mantenimiento,\n",
      "            (CASE WHEN COALESCE(sd.km_ocasion, 0) >= 250000 THEN -25 ELSE 0.0 END) as dbg_pen_km_extremo,\n",
      "            (CASE WHEN @penalizar_puertas = TRUE AND puertas <= 3 THEN -8 ELSE 0.0 END) as dbg_pen_puertas,\n",
      "            (CASE WHEN @flag_penalizar_low_cost_comodidad = TRUE THEN (sd.acceso_low_cost_scaled * -1.5) ELSE 0.0 END) as dbg_pen_low_cost_comodidad,\n",
      "            (CASE WHEN @flag_penalizar_deportividad_comodidad = TRUE THEN (sd.deportividad_bq_scaled * -1.5) ELSE 0.0 END) as dbg_pen_deportividad_comodidad,\n",
      "            (CASE WHEN @flag_penalizar_antiguo_tec = TRUE THEN CASE\n",
      "                WHEN sd.anos_vehiculo > 15 THEN -25\n",
      "                WHEN sd.anos_vehiculo > 10 THEN -20 \n",
      "                WHEN sd.anos_vehiculo > 7  THEN -15 \n",
      "                WHEN sd.anos_vehiculo > 5  THEN -7 \n",
      "            ELSE 0.0 END ELSE 0.0 END) as dbg_pen_antiguedad,\n",
      "            -- ‚úÖ NUEVA L√ìGICA: Penalizaci√≥n general por antig√ºedad\n",
      "            (CASE\n",
      "                WHEN sd.ano_unidad < 1990 THEN -50\n",
      "                WHEN sd.ano_unidad BETWEEN 1991 AND 1995 THEN -30\n",
      "                WHEN sd.ano_unidad BETWEEN 1996 AND 2000 THEN -20\n",
      "                WHEN sd.ano_unidad BETWEEN 2001 AND 2006 AND sd.tipo_mecanica = 'DIESEL' THEN -10\n",
      "                ELSE 0.0\n",
      "            END) as dbg_pen_antiguedad_general,\n",
      "            (CASE WHEN @flag_aplicar_logica_distintivo = TRUE THEN CASE WHEN UPPER(sd.distintivo_ambiental) IN ('CERO', '0', 'ECO', 'C') THEN 5 WHEN UPPER(sd.distintivo_ambiental) IN ('B', 'NA') THEN -8 ELSE 0.0 END ELSE 0.0 END) as dbg_ajuste_distintivo,\n",
      "            (CASE WHEN @flag_aplicar_logica_distintivo = TRUE AND COALESCE(sd.ocasion, FALSE) = TRUE THEN 8 ELSE 0.0 END) as dbg_bonus_ocasion_ambiental,\n",
      "            (CASE WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('CERO', '0', 'ECO') THEN 10 WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('C') THEN 8 WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('NA') THEN -10 WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('B') THEN -8 ELSE 0.0 END) as dbg_ajuste_zbe,\n",
      "            (CASE WHEN @flag_pen_bev_reev_avent_ocas = TRUE AND sd.tipo_mecanica IN ('BEV', 'REEV') THEN -10 ELSE 0.0 END) as dbg_pen_bev_reev_avent_ocas,\n",
      "            (CASE WHEN @flag_pen_phev_avent_ocas = TRUE AND sd.tipo_mecanica IN ('PHEVD', 'PHEVG') THEN -5 ELSE 0.0 END) as dbg_pen_phev_avent_ocas,\n",
      "            (CASE WHEN @flag_pen_electrif_avent_extr = TRUE AND sd.tipo_mecanica IN ('BEV', 'REEV', 'PHEVD', 'PHEVG') THEN -25 ELSE 0.0 END) as dbg_pen_electrif_avent_extr,\n",
      "            (CASE WHEN @flag_fav_car_montana = TRUE AND sd.tipo_carroceria IN ('SUV', 'TODOTERRENO') THEN 5 ELSE 0.0 END) as dbg_bonus_car_montana,\n",
      "            (CASE WHEN @flag_fav_car_comercial = TRUE AND sd.tipo_carroceria IN ('COMERCIAL') THEN 20 ELSE 0.0 END) as dbg_bonus_car_comercial,\n",
      "            (CASE WHEN @flag_fav_car_pasajeros_pro = TRUE AND sd.tipo_carroceria IN ('3VOL', 'MONOVOLUMEN') THEN 20 ELSE 0.0 END) as dbg_bonus_car_pasajeros,\n",
      "            (CASE WHEN @flag_desfav_car_no_aventura = TRUE AND sd.tipo_carroceria IN ('PICKUP', 'TODOTERRENO') THEN -15 ELSE 0.0 END) as dbg_pen_car_no_aventura,\n",
      "            (CASE WHEN @flag_fav_suv_aventura_ocasional = TRUE AND sd.tipo_carroceria IN ('SUV') THEN 10 ELSE 0.0 END) as dbg_bonus_suv_avent_ocas,\n",
      "            (CASE WHEN @flag_fav_pickup_todoterreno_aventura_extrema = TRUE AND sd.tipo_carroceria IN ('TODOTERRENO') THEN 25 ELSE 0.0 END) as dbg_bonus_tt_avent_extr,\n",
      "            (CASE WHEN @flag_fav_pickup_todoterreno_aventura_extrema = TRUE AND sd.tipo_carroceria IN ('PICKUP') THEN 5 ELSE 0.0 END) as dbg_bonus_pickup_avent_extr,\n",
      "            (CASE WHEN @flag_aplicar_logica_objetos_especiales = TRUE THEN CASE WHEN sd.tipo_carroceria IN ('MONOVOLUMEN', 'FURGONETA', 'FAMILIAR', 'SUV') THEN 10 WHEN sd.tipo_carroceria IN ('3VOL', 'COUPE', 'DESCAPOTABLE') THEN -10 ELSE 0.0 END ELSE 0.0 END) as dbg_ajuste_objetos_especiales,\n",
      "            (CASE WHEN @flag_fav_carroceria_confort = TRUE AND sd.tipo_carroceria IN ('3VOL', '2VOL', 'SUV', 'FAMILIAR', 'MONOVOLUMEN') THEN 5 ELSE 0.0 END) as dbg_bonus_car_confort,\n",
      "            (CASE WHEN @flag_logica_uso_ocasional = TRUE AND COALESCE(sd.ocasion, FALSE) = TRUE THEN 3 ELSE 0.0 END) as dbg_bonus_ocasion_uso_ocas,\n",
      "            (CASE WHEN @flag_logica_uso_ocasional = TRUE AND sd.tipo_mecanica IN ('PHEVD', 'PHEVG', 'BEV', 'REEV') THEN -10 ELSE 0.0 END) as dbg_pen_electrif_uso_ocas,\n",
      "            (CASE WHEN @flag_favorecer_bev_uso_definido = TRUE AND sd.tipo_mecanica IN ('BEV', 'REEV') THEN 10 ELSE 0.0 END) as dbg_bonus_bev_uso_definido,\n",
      "            (CASE WHEN @flag_penalizar_phev_uso_intensivo = TRUE AND sd.tipo_mecanica IN ('PHEVD', 'PHEVG') THEN -15 ELSE 0.0 END) as dbg_pen_phev_uso_intensivo,\n",
      "            (CASE WHEN @flag_favorecer_electrificados_por_punto_carga = TRUE AND sd.tipo_mecanica IN ('BEV', 'PHEVD', 'PHEVG', 'REEV') THEN 10 ELSE 0.0 END) as dbg_bonus_punto_carga,\n",
      "            (CASE WHEN @flag_bonus_awd_clima_adverso = TRUE AND sd.traccion = 'ALL' THEN 10 WHEN @penalizar_awd_ninguna_aventura = TRUE AND sd.traccion = 'ALL' THEN -10 WHEN @favorecer_awd_aventura_ocasional = TRUE AND sd.traccion = 'ALL' THEN 10 WHEN @favorecer_awd_aventura_extrema = TRUE AND sd.traccion = 'ALL' THEN 20 ELSE 0.0 END) as dbg_ajuste_awd_aventura,\n",
      "            (CASE WHEN @flag_bonus_awd_nieve = TRUE AND sd.traccion = 'ALL' THEN 10 ELSE 0.0 END) as dbg_bonus_awd_nieve,\n",
      "            (CASE WHEN @flag_bonus_awd_montana = TRUE AND sd.traccion = 'ALL' THEN 5 ELSE 0.0 END) as dbg_bonus_awd_montana,\n",
      "            (CASE WHEN @flag_logica_reductoras_aventura = 'FAVORECER_OCASIONAL' AND COALESCE(sd.reductoras, FALSE) = TRUE THEN 10 WHEN @flag_logica_reductoras_aventura = 'FAVORECER_EXTREMA' AND COALESCE(sd.reductoras, FALSE) = TRUE THEN 25 ELSE 0.0 END) as dbg_bonus_reductoras,\n",
      "            (CASE WHEN @flag_logica_diesel_ciudad = 'PENALIZAR' AND sd.tipo_mecanica IN ('DIESEL', 'HEVD', 'MHEVD') THEN -15 WHEN @flag_logica_diesel_ciudad = 'BONIFICAR' AND sd.tipo_mecanica IN ('DIESEL', 'HEVD', 'MHEVD') THEN 20 ELSE 0.0 END) as dbg_ajuste_diesel_ciudad,\n",
      "            -- ‚úÖ L√ìGICA MEJORADA: Penalizaci√≥n por tama√±o no compacto, AHORA CONTEXTUAL\n",
      "            (CASE \n",
      "                WHEN @flag_penalizar_tamano_no_compacto = TRUE AND\n",
      "                     (\n",
      "                        -- Si es conductor urbano, penaliza coches > 4.25m\n",
      "                        (@flag_es_conductor_urbano = TRUE AND sd.largo >= 4250) \n",
      "                        OR\n",
      "                        -- Si NO es conductor urbano, penaliza coches > 4.50m\n",
      "                        (@flag_es_conductor_urbano = FALSE AND sd.largo >= 4500)\n",
      "                     )\n",
      "                THEN -5 \n",
      "                ELSE 0.0 \n",
      "            END) as dbg_pen_tamano_no_compacto,\n",
      "             (CASE \n",
      "                WHEN @flag_bonus_singularidad_lifestyle = TRUE AND sd.tipo_carroceria = 'COUPE' THEN 5\n",
      "                WHEN @flag_bonus_singularidad_lifestyle = TRUE AND sd.tipo_carroceria = 'DESCAPOTABLE' THEN 4\n",
      "                ELSE 0.0 \n",
      "            END) as dbg_bonus_lifestyle,\n",
      "            (CASE\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'COUPE' THEN 4\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'DESCAPOTABLE' THEN 3\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'COMERCIAL' THEN -10\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'FURGONETA' THEN -7\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'SUV' THEN -5\n",
      "                ELSE 0.0\n",
      "            END) as dbg_ajuste_deportividad_lifestyle,\n",
      "            (CASE \n",
      "                WHEN @flag_deportividad_lifestyle = TRUE \n",
      "                     AND sd.tipo_mecanica = 'BEV' \n",
      "                     AND sd.tipo_carroceria NOT IN ('COUPE', 'DESCAPOTABLE')\n",
      "                THEN -5\n",
      "                ELSE 0.0 \n",
      "            END) as dbg_pen_bev_lifestyle,\n",
      "            (CASE\n",
      "                WHEN @flag_ajuste_maletero_personal = TRUE THEN\n",
      "                    -- Sumamos las tres penalizaciones posibles\n",
      "                    (CASE \n",
      "                        WHEN sd.plazas <= 3 AND sd.maletero_minimo < 450 THEN -5\n",
      "                        WHEN sd.plazas > 3 AND sd.maletero_minimo < 550 THEN -5\n",
      "                        ELSE 0.0\n",
      "                    END)\n",
      "                    +\n",
      "                    (CASE\n",
      "                        WHEN sd.tipo_carroceria = 'COMERCIAL' THEN -10\n",
      "                        ELSE 0.0\n",
      "                    END)\n",
      "                ELSE 0.0 \n",
      "            END) as dbg_ajuste_maletero_personal,\n",
      "            -- ‚úÖ NUEVA L√ìGICA: Bonus para el perfil \"Coche de Ciudad\"\n",
      "            (\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_perfil = TRUE AND sd.largo < 3300 -- 330 cm = 3300 mm\n",
      "                    THEN 5 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "                +\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_perfil = TRUE AND sd.peso < 950 \n",
      "                    THEN 2 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "            ) as dbg_bonus_coche_ciudad,\n",
      "            -- ‚úÖ NUEVA L√ìGICA: Bonus para el perfil \"Coche de Ciudad 2\"\n",
      "            (\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_2_perfil = TRUE AND sd.largo < 3900 -- 390 cm = 3900 mm\n",
      "                    THEN 5 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "                +\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_2_perfil = TRUE AND sd.peso < 1000 \n",
      "                    THEN 2 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "            ) as dbg_bonus_coche_ciudad_2,\n",
      "            (CASE WHEN @km_anuales_estimados > 0 AND @km_anuales_estimados < 10000 THEN (CASE WHEN sd.tipo_mecanica IN ('GASOLINA', 'MHEVG', 'HEVG') THEN 8 ELSE 0 END) + (CASE WHEN COALESCE(sd.km_ocasion, 0) > 250000 THEN -5 ELSE 0 END) WHEN @km_anuales_estimados >= 10000 AND @km_anuales_estimados < 30000 THEN (CASE WHEN COALESCE(sd.km_ocasion, 0) > 120000 THEN -10 ELSE 0 END) WHEN @km_anuales_estimados >= 30000 AND @km_anuales_estimados < 60000 THEN (CASE WHEN sd.tipo_mecanica IN ('DIESEL', 'MHEVD', 'HEVD', 'GLP', 'GNV') THEN 10 ELSE 0 END) + (CASE WHEN COALESCE(sd.km_ocasion, 0) > 80000 THEN -10 ELSE 0 END) WHEN @km_anuales_estimados >= 60000 THEN (CASE sd.tipo_mecanica WHEN 'BEV' THEN 5 WHEN 'REEV' THEN 5 WHEN 'HEVD' THEN 10 WHEN 'DIESEL' THEN 10 WHEN 'MHEVD' THEN 10 WHEN 'PHEVD' THEN 3 WHEN 'GLP' THEN 3 WHEN 'GNV' THEN 3 ELSE 0.0 END) + (CASE WHEN COALESCE(sd.km_ocasion, 0) > 20000 THEN -20 ELSE 0 END) ELSE 0.0 END) as dbg_ajuste_km_anuales\n",
      "        FROM ScaledData sd\n",
      "        WHERE 1=1  AND sd.plazas >= @plazas_min AND sd.tipo_mecanica IN UNNEST(@tipos_mecanica) AND (COALESCE(sd.precio_compra_contado, 0) * 0.0140625) <= @cuota_maxima\n",
      "    ),\n",
      "    -- Este CTE suma los componentes para obtener los scores finales\n",
      "    IntermediateScores AS (\n",
      "        SELECT \n",
      "            *,\n",
      "            (\n",
      "                dbg_score_estetica + dbg_score_premium + dbg_score_singular + dbg_score_altura_libre +\n",
      "                dbg_score_batalla + dbg_score_altura_interior + dbg_score_ancho +\n",
      "                dbg_score_devaluacion + dbg_score_maletero_min + dbg_score_maletero_max + dbg_score_largo  +\n",
      "                dbg_score_bajo_peso  + dbg_score_par_remolque + dbg_score_remolque_cf + dbg_score_remolque_sf + dbg_score_menor_superficie +\n",
      "                dbg_score_menor_giro + dbg_score_menor_largo + dbg_score_menor_ancho + dbg_score_menor_alto +\n",
      "                dbg_score_deportividad + dbg_score_menor_rel_peso_pot + dbg_score_potencia + dbg_score_par_deportivo +\n",
      "                dbg_score_autonomia_max + dbg_score_autonomia_2nd + dbg_score_menor_t_carga +\n",
      "                dbg_score_pot_carga_ac + dbg_score_pot_carga_dc + dbg_score_menor_aceleracion + dbg_pen_bev_lifestyle\n",
      "            ) AS puntuacion_base,\n",
      "            (\n",
      "                dbg_pen_km_extremo + dbg_pen_puertas + dbg_pen_low_cost_comodidad + dbg_pen_deportividad_comodidad +\n",
      "                dbg_pen_antiguedad + dbg_ajuste_distintivo + dbg_bonus_ocasion_ambiental + dbg_ajuste_zbe +\n",
      "                dbg_pen_bev_reev_avent_ocas + dbg_pen_phev_avent_ocas + dbg_pen_electrif_avent_extr +\n",
      "                dbg_bonus_car_montana + dbg_bonus_car_comercial + dbg_bonus_car_pasajeros + dbg_pen_car_no_aventura +\n",
      "                dbg_bonus_suv_avent_ocas + dbg_bonus_tt_avent_extr + dbg_bonus_pickup_avent_extr + \n",
      "                dbg_ajuste_objetos_especiales + dbg_bonus_car_confort + dbg_bonus_ocasion_uso_ocas +\n",
      "                dbg_pen_electrif_uso_ocas + dbg_bonus_bev_uso_definido + dbg_pen_phev_uso_intensivo +\n",
      "                dbg_bonus_punto_carga + dbg_ajuste_awd_aventura + dbg_bonus_awd_nieve + dbg_bonus_awd_montana +\n",
      "                dbg_bonus_reductoras + dbg_ajuste_diesel_ciudad + dbg_ajuste_km_anuales + dbg_bonus_seguridad  +\n",
      "                dbg_bonus_fiabilidad + dbg_bonus_durabilidad + dbg_bonus_bajo_consumo + dbg_bonus_coste_uso +\n",
      "                dbg_bonus_coste_mantenimiento + dbg_pen_antiguedad_general + dbg_pen_tamano_no_compacto + dbg_bonus_lifestyle + \n",
      "                dbg_ajuste_deportividad_lifestyle + dbg_ajuste_maletero_personal + dbg_bonus_coche_ciudad + dbg_bonus_coche_ciudad_2\n",
      "            ) AS ajustes_experto\n",
      "        FROM DebugScores\n",
      "    ),\n",
      "    DeduplicatedData AS (\n",
      "        SELECT\n",
      "            *,\n",
      "            (puntuacion_base + ajustes_experto) AS score_total,\n",
      "            ROW_NUMBER() OVER(\n",
      "                PARTITION BY modelo, tipo_mecanica\n",
      "                ORDER BY (puntuacion_base + ajustes_experto) DESC, precio_compra_contado ASC\n",
      "            ) as rn\n",
      "        FROM \n",
      "            IntermediateScores\n",
      "    ),\n",
      "    BrandRankedData AS (\n",
      "        SELECT\n",
      "            *,\n",
      "            ROW_NUMBER() OVER(\n",
      "                PARTITION BY marca\n",
      "                ORDER BY score_total DESC\n",
      "            ) as brand_rank\n",
      "        FROM \n",
      "            DeduplicatedData\n",
      "        WHERE \n",
      "            rn = 1\n",
      "    )\n",
      "    SELECT\n",
      "        -- Columnas principales\n",
      "        nombre, ID, marca, modelo, score_total, puntuacion_base, ajustes_experto, foto,\n",
      "        \n",
      "        -- Desglose completo para depuraci√≥n\n",
      "        * EXCEPT (nombre, ID, marca, modelo, score_total, puntuacion_base, ajustes_experto, rn, brand_rank)\n",
      "\n",
      "    FROM \n",
      "        BrandRankedData\n",
      "    WHERE \n",
      "        brand_rank <= 2\n",
      "    ORDER BY \n",
      "        score_total DESC\n",
      "    LIMIT @k \n",
      "    \n",
      "-------------------------------------------------\n",
      "\n",
      "--- üì¶ Parameters Enviados a BigQuery ---\n",
      "[{'name': 'peso_estetica', 'value': 0.011146989179411032, 'type': 'FLOAT64'}, {'name': 'peso_premium', 'value': 0.05607514201165278, 'type': 'FLOAT64'}, {'name': 'peso_singular', 'value': 0.007993920225103791, 'type': 'FLOAT64'}, {'name': 'peso_altura', 'value': 0.024228974743024313, 'type': 'FLOAT64'}, {'name': 'peso_batalla', 'value': 0.017660870061544116, 'type': 'FLOAT64'}, {'name': 'peso_indice_altura', 'value': 0.01933995902823216, 'type': 'FLOAT64'}, {'name': 'peso_ancho_general_score', 'value': 0.02014278563439438, 'type': 'FLOAT64'}, {'name': 'penalizar_puertas', 'value': False, 'type': 'BOOL'}, {'name': 'peso_rating_durabilidad', 'value': 0.017261497624915988, 'type': 'FLOAT64'}, {'name': 'peso_rating_fiabilidad', 'value': 0.02806017284021492, 'type': 'FLOAT64'}, {'name': 'peso_rating_seguridad', 'value': 0.013559027539499384, 'type': 'FLOAT64'}, {'name': 'peso_rating_impacto_ambiental', 'value': 0.0, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_coste_uso_directo', 'value': 0.02240743445215318, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_coste_mantenimiento_directo', 'value': 0.012231664076710065, 'type': 'FLOAT64'}, {'name': 'peso_rating_tecnologia_conectividad', 'value': 0.004642682691250487, 'type': 'FLOAT64'}, {'name': 'peso_devaluacion', 'value': 0.007637011728092174, 'type': 'FLOAT64'}, {'name': 'peso_maletero_minimo_score', 'value': 0.024385460598356182, 'type': 'FLOAT64'}, {'name': 'peso_maletero_maximo_score', 'value': 0.019697234483283782, 'type': 'FLOAT64'}, {'name': 'peso_largo_vehiculo_score', 'value': 0.013179678770329481, 'type': 'FLOAT64'}, {'name': 'peso_autonomia_vehiculo', 'value': 0.03056879261724704, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_peso', 'value': 0.010917129664064273, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_consumo', 'value': 0.014108939393471303, 'type': 'FLOAT64'}, {'name': 'peso_par_motor_remolque_score', 'value': 0.007637011728092174, 'type': 'FLOAT64'}, {'name': 'peso_cap_remolque_cf_score', 'value': 0.008649092613837577, 'type': 'FLOAT64'}, {'name': 'peso_cap_remolque_sf_score', 'value': 0.009353390946738307, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_superficie_planta', 'value': 0.011809754898288548, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_diametro_giro', 'value': 0.2378167275490145, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_largo_garage', 'value': 0.017113960751125548, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_ancho_garage', 'value': 0.13833049785188234, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_alto_garage', 'value': 0.015315472714090426, 'type': 'FLOAT64'}, {'name': 'peso_deportividad_style_score', 'value': 0.007383780358805474, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_rel_peso_potencia_score', 'value': 0.023859850172924583, 'type': 'FLOAT64'}, {'name': 'peso_potencia_maxima_style_score', 'value': 0.017444164062369785, 'type': 'FLOAT64'}, {'name': 'peso_par_motor_style_score', 'value': 0.013512191380413617, 'type': 'FLOAT64'}, {'name': 'peso_autonomia_uso_principal', 'value': 0.0, 'type': 'FLOAT64'}, {'name': 'peso_autonomia_uso_2nd_drive', 'value': 0.013559027539499384, 'type': 'FLOAT64'}, {'name': 'peso_menor_tiempo_carga_min', 'value': 0.021892252150930606, 'type': 'FLOAT64'}, {'name': 'peso_potencia_maxima_carga_AC', 'value': 0.012127562914844934, 'type': 'FLOAT64'}, {'name': 'peso_potencia_maxima_carga_DC', 'value': 0.016043257740984647, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_aceleracion_score', 'value': 0.02136465047110086, 'type': 'FLOAT64'}, {'name': 'flag_penalizar_low_cost_comodidad', 'value': False, 'type': 'BOOL'}, {'name': 'flag_penalizar_deportividad_comodidad', 'value': False, 'type': 'BOOL'}, {'name': 'flag_penalizar_antiguo_tec', 'value': False, 'type': 'BOOL'}, {'name': 'flag_aplicar_logica_distintivo', 'value': True, 'type': 'BOOL'}, {'name': 'flag_es_municipio_zbe', 'value': True, 'type': 'BOOL'}, {'name': 'flag_pen_bev_reev_avent_ocas', 'value': False, 'type': 'BOOL'}, {'name': 'flag_pen_phev_avent_ocas', 'value': False, 'type': 'BOOL'}, {'name': 'flag_pen_electrif_avent_extr', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_car_montana', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_car_comercial', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_car_pasajeros_pro', 'value': False, 'type': 'BOOL'}, {'name': 'flag_desfav_car_no_aventura', 'value': True, 'type': 'BOOL'}, {'name': 'flag_fav_suv_aventura_ocasional', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_pickup_todoterreno_aventura_extrema', 'value': False, 'type': 'BOOL'}, {'name': 'flag_aplicar_logica_objetos_especiales', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_carroceria_confort', 'value': False, 'type': 'BOOL'}, {'name': 'flag_logica_uso_ocasional', 'value': False, 'type': 'BOOL'}, {'name': 'flag_favorecer_bev_uso_definido', 'value': False, 'type': 'BOOL'}, {'name': 'flag_penalizar_phev_uso_intensivo', 'value': False, 'type': 'BOOL'}, {'name': 'flag_favorecer_electrificados_por_punto_carga', 'value': False, 'type': 'BOOL'}, {'name': 'penalizar_awd_ninguna_aventura', 'value': True, 'type': 'BOOL'}, {'name': 'favorecer_awd_aventura_ocasional', 'value': False, 'type': 'BOOL'}, {'name': 'favorecer_awd_aventura_extrema', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_awd_nieve', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_awd_montana', 'value': False, 'type': 'BOOL'}, {'name': 'flag_logica_reductoras_aventura', 'value': False, 'type': 'STRING'}, {'name': 'flag_bonus_awd_clima_adverso', 'value': False, 'type': 'BOOL'}, {'name': 'flag_logica_diesel_ciudad', 'value': 'PENALIZAR', 'type': 'STRING'}, {'name': 'flag_bonus_seguridad_critico', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_seguridad_fuerte', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_fiab_dur_critico', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_fiab_dur_fuerte', 'value': True, 'type': 'BOOL'}, {'name': 'flag_bonus_costes_critico', 'value': False, 'type': 'BOOL'}, {'name': 'km_anuales_estimados', 'value': 5200, 'type': 'INT64'}, {'name': 'flag_penalizar_tamano_no_compacto', 'value': True, 'type': 'BOOL'}, {'name': 'flag_bonus_singularidad_lifestyle', 'value': True, 'type': 'BOOL'}, {'name': 'flag_deportividad_lifestyle', 'value': False, 'type': 'BOOL'}, {'name': 'flag_ajuste_maletero_personal', 'value': False, 'type': 'BOOL'}, {'name': 'flag_coche_ciudad_perfil', 'value': False, 'type': 'BOOL'}, {'name': 'flag_coche_ciudad_2_perfil', 'value': False, 'type': 'BOOL'}, {'name': 'flag_es_conductor_urbano', 'value': True, 'type': 'BOOL'}, {'name': 'k', 'value': 5, 'type': 'INT64'}, {'name': 'plazas_min', 'value': 1, 'type': 'INT64'}, {'name': 'tipos_mecanica', 'value': ['BEV', 'REEV'], 'type': 'ARRAY<STRING>'}, {'name': 'cuota_maxima', 'value': 395.8333333333333, 'type': 'FLOAT64'}]\n",
      "-------------------------------------------------\n",
      "INFO (BQ Logger) ‚ñ∫ Log para '1' guardado en BQ.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬°Listo! Basado en todo lo que hablamos, aqu√≠ tienes 4 coche(s) que podr√≠an interesarte:\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"45.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"pago a contado\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"maximo 30 mil euros\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 1\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"economia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"pagar al contado\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"20.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¬°Listo! Basado en todo lo que hablamos, aqu√≠ tienes 4 coche(s) que podr√≠an interesarte:\n",
      "\n",
      "--- üïµÔ∏è Datos Estructurados (lo que procesa el frontend) üïµÔ∏è ---\n",
      "Tipo de Payload: car_recommendation\n",
      "\n",
      "Se encontraron 4 coches en el payload:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>specs</th>\n",
       "      <th>imageUrl</th>\n",
       "      <th>price</th>\n",
       "      <th>score</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. smart fortwo coup√© EQ</td>\n",
       "      <td>[BEV, 2022, RWD]</td>\n",
       "      <td>https://assets.adac.de/image/upload/v1/Autodat...</td>\n",
       "      <td>11.500‚Ç¨</td>\n",
       "      <td>77.84 pts</td>\n",
       "      <td>An√°lisis detallado de la recomendaci√≥n pendien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Peugeot e-208 136 GT</td>\n",
       "      <td>[BEV, 2021, FWD]</td>\n",
       "      <td>https://assets.adac.de/image/upload/v1/Autodat...</td>\n",
       "      <td>14.900‚Ç¨</td>\n",
       "      <td>70.14 pts</td>\n",
       "      <td>An√°lisis detallado de la recomendaci√≥n pendien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Toyota bZ4X</td>\n",
       "      <td>[BEV, 2023, FWD]</td>\n",
       "      <td>https://a.ccdn.es/cnet/2025/07/14/61026908/204...</td>\n",
       "      <td>25.500‚Ç¨</td>\n",
       "      <td>67.35 pts</td>\n",
       "      <td>An√°lisis detallado de la recomendaci√≥n pendien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Tesla Model 3</td>\n",
       "      <td>[BEV, 2019, RWD]</td>\n",
       "      <td>https://assets.adac.de/image/upload/v1/Autodat...</td>\n",
       "      <td>20.900‚Ç¨</td>\n",
       "      <td>62.11 pts</td>\n",
       "      <td>An√°lisis detallado de la recomendaci√≥n pendien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name             specs  \\\n",
       "0  1. smart fortwo coup√© EQ   [BEV, 2022, RWD]   \n",
       "1    2. Peugeot e-208 136 GT  [BEV, 2021, FWD]   \n",
       "2            3. Toyota bZ4X   [BEV, 2023, FWD]   \n",
       "3          4. Tesla Model 3   [BEV, 2019, RWD]   \n",
       "\n",
       "                                            imageUrl    price      score  \\\n",
       "0  https://assets.adac.de/image/upload/v1/Autodat...  11.500‚Ç¨  77.84 pts   \n",
       "1  https://assets.adac.de/image/upload/v1/Autodat...  14.900‚Ç¨  70.14 pts   \n",
       "2  https://a.ccdn.es/cnet/2025/07/14/61026908/204...  25.500‚Ç¨  67.35 pts   \n",
       "3  https://assets.adac.de/image/upload/v1/Autodat...  20.900‚Ç¨  62.11 pts   \n",
       "\n",
       "                                            analysis  \n",
       "0  An√°lisis detallado de la recomendaci√≥n pendien...  \n",
       "1  An√°lisis detallado de la recomendaci√≥n pendien...  \n",
       "2  An√°lisis detallado de la recomendaci√≥n pendien...  \n",
       "3  An√°lisis detallado de la recomendaci√≥n pendien...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_message = output['messages'][-1] if output.get('messages') else None\n",
    "final_message.pretty_print()\n",
    "if final_message.additional_kwargs and 'payload' in final_message.additional_kwargs:\n",
    "            print(\"\\n--- üïµÔ∏è Datos Estructurados (lo que procesa el frontend) üïµÔ∏è ---\")\n",
    "            payload = final_message.additional_kwargs['payload']\n",
    "            \n",
    "            # Verificamos si es una recomendaci√≥n de coches\n",
    "            if payload and payload.get('type') == 'car_recommendation':\n",
    "                print(f\"Tipo de Payload: {payload.get('type')}\")\n",
    "                \n",
    "                coches_recomendados = payload.get('cars', [])\n",
    "                if coches_recomendados:\n",
    "                    print(f\"\\nSe encontraron {len(coches_recomendados)} coches en el payload:\")\n",
    "                    # Usamos Pandas para una visualizaci√≥n bonita de los datos\n",
    "                    df = pd.DataFrame(coches_recomendados)\n",
    "                    display(df)\n",
    "                else:\n",
    "                    print(\"‚ö†Ô∏è El payload no conten√≠a coches.\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è El payload no es del tipo 'car_recommendation' o est√° vac√≠o.\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"contado hasta 9000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"10\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"contado hasta 20.000 euros\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"frecuentemente\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"dos ni≈Ños de 14 a≈Ños y mi mujer\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"un adulto y un ni≈Ño\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ahorros hasta 45.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"8 a√±os\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "coches_recomendados = output[('coches_recomendados')]\n",
    "\n",
    "df_resultados = pd.DataFrame(coches_recomendados)\n",
    "        \n",
    "#  OPCI√ìN 1: Imprimir el DataFrame directamente (Pandas usar√° las opciones de display)\n",
    "# print(\"\\n--- Vista DataFrame (Pandas Display Options) ---\")\n",
    "# display(df_resultados) # 'display()' suele dar mejor formato en notebooks que 'print(df)'\n",
    "\n",
    "#OPCI√ìN 2: Convertir a Markdown (como en tu nodo, pero para consola)\n",
    "print(\"\\n--- Vista Markdown ---\")\n",
    "columnas_deseadas = [ # Lista completa de columnas que seleccionas en BQ\n",
    "            'nombre', 'ID', 'marca', 'modelo', 'score_total',\n",
    "            'puntuacion_base',      # <-- NUEVA\n",
    "            'ajustes_experto',      # <-- NUEVA\n",
    "            'cambio_automatico', 'tipo_mecanica', \n",
    "            'tipo_carroceria', 'indice_altura_interior', 'batalla', 'estetica', \n",
    "            'premium', 'singular', 'altura_libre_suelo', 'ancho', 'traccion', \n",
    "            'reductoras', 'puertas', 'plazas', 'precio_compra_contado',\n",
    "            'fiabilidad', 'durabilidad', 'seguridad', 'comodidad', 'acceso_low_cost', \n",
    "            'deportividad', 'tecnologia', 'devaluacion', 'maletero_minimo', \n",
    "            'maletero_maximo', 'largo', 'autonomia_uso_maxima', \n",
    "            'distintivo_ambiental', 'anos_vehiculo', 'ocasion',\n",
    "            'peso_original_kg', 'consumo_original', 'foto'\n",
    "        ]\n",
    "columnas_existentes = [col for col in columnas_deseadas if col in df_resultados.columns]\n",
    "if columnas_existentes:\n",
    "            if 'score_total' in df_resultados.columns: # Formatear score para legibilidad\n",
    "                df_resultados['score_total'] = df_resultados['score_total'].apply(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x)\n",
    "            print(df_resultados[columnas_existentes].to_markdown(index=False))\n",
    "else:\n",
    "            print(\"WARN: No se encontraron columnas esperadas para mostrar en formato tabla.\")\n",
    "            print(\"Resultados crudos (lista de dicts):\", coches_recomendados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"muestrame mas opciones manteniendo las mismas condiciones\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"cambia el presupuesto a 18.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"mismas condiciones pero baja fiabilidad = 3\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complejidad de la Explicaci√≥n: La plantilla actual es simple (\"Destaca porque [X] ya que [Y], y tambi√©n por [Z] ya que [W]\"). Puedes hacerla m√°s sofisticada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Vista JSON ---\")\n",
    "tabla_resumen = output[('tabla_resumen_criterios')]\n",
    "print(tabla_resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['codigo_postal_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['info_clima_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['preferencias_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['filtros_inferidos'])\n",
    "print('-----------------------')\n",
    "print(output['info_pasajeros'])\n",
    "print('-----------------------')\n",
    "print(output['economia'])\n",
    "print('-----------------------')\n",
    "print(output['pesos'])\n",
    "print('-----------------------')\n",
    "print(\"info_pasajeros:\",output['info_pasajeros'])\n",
    "print('-----------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"flag_penalizar_deportividad_comodidad:\", output['flag_penalizar_deportividad_comodidad'])\n",
    "print('-----------------------')\n",
    "print(\"flag_penalizar_low_cost_comodidad:\", output['flag_penalizar_low_cost_comodidad'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_puertas_bajas:\" , output['penalizar_puertas_bajas'])\n",
    "print('-----------------------')\n",
    "print(\"flag_penalizar_antiguo_por_tecnologia:\" , output['flag_penalizar_antiguo_por_tecnologia'])\n",
    "print('-----------------------')\n",
    "print(\"aplicar_logica_distintivo_ambiental:\" ,  output['aplicar_logica_distintivo_ambiental'])\n",
    "print('-----------------------')\n",
    "print(\"es municipio_zbe: \" , output['es_municipio_zbe'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_electrificados_aventura_extrema: \" , output['penalizar_electrificados_aventura_extrema'])\n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_montana', output['favorecer_carroceria_montana'])\n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_comercial', output['favorecer_carroceria_comercial'])\n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_pasajeros_pro:', output['favorecer_carroceria_pasajeros_pro'])\n",
    "print('-----------------------')\n",
    "print('aplicar_logica_objetos_especiales:', output['aplicar_logica_objetos_especiales'])#OK \n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_confort:', output['favorecer_carroceria_confort']) #OK\n",
    "print('-----------------------')\n",
    "print('flag_logica_uso_ocasional:' , output['flag_logica_uso_ocasional'])\n",
    "print('-----------------------')\n",
    "print('flag_favorecer_bev_uso_definido:' , output['flag_favorecer_bev_uso_definido'])\n",
    "print('-----------------------')\n",
    "print('flag_penalizar_phev_uso_intensivo:' , output['flag_penalizar_phev_uso_intensivo'])\n",
    "print('-----------------------')\n",
    "print('flag_favorecer_electrificados_por_punto_carga:' , output['flag_favorecer_electrificados_por_punto_carga'])\n",
    "print('-----------------------')\n",
    "print('km_anuales_estimados:' , output['km_anuales_estimados'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('desfavorecer_carroceria_no_aventura:', output['desfavorecer_carroceria_no_aventura']) #Aventura nula y no en monta√±a desfavorece PICKUP/TODOTERRENO\n",
    "print('-----------------------')\n",
    "print('favorecer_suv_aventura_ocasional:', output['favorecer_suv_aventura_ocasional']) #OK\n",
    "print('-----------------------')\n",
    "print('favorecer_pickup_todoterreno_aventura_extrema:', output['favorecer_pickup_todoterreno_aventura_extrema'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_bev_reev_aventura_ocasional: \" , output['penalizar_bev_reev_aventura_ocasional'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_phev_aventura_ocasional: \" , output['penalizar_phev_aventura_ocasional'])\n",
    "print('-----------------------')\n",
    "print('penalizar_awd_ninguna_aventura:' , output['penalizar_awd_ninguna_aventura'])\n",
    "print('-----------------------')\n",
    "print('favorecer_awd_aventura_ocasional:' , output['favorecer_awd_aventura_ocasional'])\n",
    "print('-----------------------')\n",
    "print('favorecer_awd_aventura_extrema:' , output['favorecer_awd_aventura_extrema'])\n",
    "print('-----------------------')\n",
    "print('flag_bonus_awd_nieve:' , output['flag_bonus_awd_nieve'])\n",
    "print('-----------------------')\n",
    "print('flag_bonus_awd_montana:' , output['flag_bonus_awd_montana'])\n",
    "print('-----------------------')\n",
    "print('flag_logica_reductoras_aventura:' , output['flag_logica_reductoras_aventura'])\n",
    "print('-----------------------')\n",
    "print('flag_logica_diesel_ciudad:' , output['flag_logica_diesel_ciudad'])\n",
    "print('-----------------------')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Quiero un coche mido 1.93. Peso 80 kg\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si, lo soy\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ambos\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ocasional\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "# print(output['filtros_inferidos']) \n",
    "# print('---------------------------------------------------------------------')\n",
    "# #print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"9\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"5\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"siete\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"9\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"8\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"6\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"8\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ocasionalmente\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"10\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "# print(output['filtros_inferidos']) \n",
    "print('---------------------------------------------------------------------')\n",
    "# print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si, llevo 2 acompa√±antes\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos']) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"ninos no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"pago total al contado maximo de 22.000 euros\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"6.000 ahorrados\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"5 a√±os\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['economia'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config).values\n",
    "for m in state['messages']:\n",
    "    m.pretty_print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revisar las reglas de altura "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hola, dime quien eres?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tienes motos?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar todo el estado acumulado\n",
    "state = graph.get_state(config).values\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Quiero un coche elegante que usar√© para trabajar todos los d√≠as. Me gustan los dise√±os llamativos. Mido 1.94\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si electrico estaria perfecto\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"automatico y peso menos de 100kg\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si me apasionan los coches\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Dime quien eres\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tienes motos para recomendarme?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config).values\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "Crear un nuevo nodo en LangGraph llamado analizar_perfil_usuario que:\n",
    "\n",
    "Reciba el mensaje del usuario.\n",
    "\n",
    "Llame a un LLM con un SystemMessage especializado.\n",
    "\n",
    "Devuelva un dict con tres secciones:\n",
    "\n",
    "\"perfil_usuario\" ‚Üí altura, peso, uso, gustos, etc.\n",
    "\n",
    "\"filtros_inferidos\" ‚Üí potencia_min, plazas_min, etc.\n",
    "\n",
    "\"mensaje_validacion\"\n",
    "\n",
    "Este resultado lo guardaremos en el state para luego usarlo al llamar buscar_producto_bd()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configurar el cliente de BigQuery\n",
    "client = bigquery.Client(project=\"thecarmentor-mvp2\")\n",
    "\n",
    "@tool\n",
    "def buscar_producto_bd(consulta: str, filtros: dict = None):\n",
    "    \"\"\"\n",
    "    Busca productos en la base de datos utilizando una consulta sem√°ntica en BigQuery.\n",
    "    Tu objetivo es proporcionar respuestas precisas para ayudar en la b√∫squeda en el inventario de coches disponibles.\n",
    "    \n",
    "    Args:\n",
    "        consulta (str): Consulta de texto para buscar productos similares.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: Resultados formateados como una lista de diccionarios con detalles de los productos m√°s relevantes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not consulta.strip():\n",
    "        raise ValueError(\"La consulta no puede estar vac√≠a.\")\n",
    "\n",
    "    # Normalizar la consulta para que coincida con el formato de los embeddings.\n",
    "    consulta_normalizada = normalize_text_sql(consulta)\n",
    "    logging.debug(f\"Consulta normalizada: {consulta_normalizada}\")\n",
    "    \n",
    "    try:\n",
    "        base_query = \"\"\"\n",
    "        WITH resultados_vector AS (\n",
    "            SELECT \n",
    "                base.content AS nombre_coche,\n",
    "                base.mecanica,\n",
    "                base.price,\n",
    "                base.KM,\n",
    "                base.year,\n",
    "                base.image_url,\n",
    "                search_result.distance\n",
    "            FROM VECTOR_SEARCH(\n",
    "                TABLE `web_cars.coches_embeddingsV1`,\n",
    "                'ml_generate_embedding_result',\n",
    "                (SELECT * FROM ML.GENERATE_EMBEDDING(\n",
    "                    MODEL `thecarmentor-mvp2.mymodel.modelembedding`,\n",
    "                    (SELECT @consulta AS content),\n",
    "                    STRUCT(TRUE AS flatten_json_output, 'SEMANTIC_SIMILARITY' AS task_type, 768 AS output_dimensionality)\n",
    "                )),\n",
    "                'ml_generate_embedding_result',\n",
    "                top_k => 6\n",
    "            ) AS search_result\n",
    "        )\n",
    "        SELECT * FROM resultados_vector\n",
    "        WHERE 1=1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Inicializar lista de condiciones y par√°metros\n",
    "        query_conditions = []\n",
    "        # Usamos la consulta normalizada para la generaci√≥n del embedding\n",
    "        query_parameters = [bigquery.ScalarQueryParameter(\"consulta\", \"STRING\", consulta_normalizada)]\n",
    "        \n",
    "        # Agregar condiciones din√°micamente seg√∫n los filtros proporcionados\n",
    "        if filtros:\n",
    "            if 'precio_max' in filtros:\n",
    "                query_conditions.append(\"price <= @precio_max\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"precio_max\", \"INT64\", filtros[\"precio_max\"]))\n",
    "            if 'precio_min' in filtros:\n",
    "                query_conditions.append(\"price >= @precio_min\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"precio_min\", \"INT64\", filtros[\"precio_min\"]))\n",
    "            if 'year_min' in filtros:\n",
    "                query_conditions.append(\"year >= @year_min\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"year_min\", \"INT64\", filtros[\"year_min\"]))\n",
    "            if 'km_max' in filtros:\n",
    "                query_conditions.append(\"KM <= @km_max\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"km_max\", \"INT64\", filtros[\"km_max\"]))\n",
    "\n",
    "        # Si hay filtros, agregarlos a la consulta\n",
    "        # if query_conditions:\n",
    "        #     base_query += \" AND \" + \" AND \".join(query_conditions)\n",
    "        if query_conditions:\n",
    "            base_query += \" \" + \" AND \".join(query_conditions)\n",
    "\n",
    "\n",
    "        logging.debug(f\"Consulta SQL generada: {base_query}\")\n",
    "        logging.debug(f\"Par√°metros de consulta: {query_parameters}\")\n",
    "\n",
    "        # Ejecutar la consulta\n",
    "        query_job = client.query(\n",
    "            base_query, \n",
    "            job_config=bigquery.QueryJobConfig(query_parameters=query_parameters)\n",
    "        )\n",
    "        results = query_job.result().to_dataframe()\n",
    "        # Ordenar los resultados por similitud\n",
    "        if not results.empty:\n",
    "            results = results.sort_values(by=\"distance\", ascending=True)\n",
    "\n",
    "        if results.empty:\n",
    "            return [{\"error\": \"No se encontraron resultados para la consulta y los filtros aplicados.\"}]\n",
    "            \n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"nombre_coche\": row[\"nombre_coche\"],\n",
    "                \"mecanica\": row[\"mecanica\"],\n",
    "                \"precio\": row[\"price\"],\n",
    "                \"kilometros\": row[\"KM\"],\n",
    "                \"a√±o\": row[\"year\"],\n",
    "                \"imagen\": row[\"image_url\"],\n",
    "                \"similitud\": round(row[\"distance\"], 2)\n",
    "            }\n",
    "            for _, row in results.iterrows()\n",
    "        ]\n",
    "        return formatted_results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al ejecutar la consulta: {e}\", exc_info=True)\n",
    "        return [{\"error\": \"No se pudieron encontrar resultados.\"}]\n",
    "\n",
    "# Definir herramientas\n",
    "# tools = [buscar_producto_bd]\n",
    "\n",
    "\n",
    "\n",
    "# Actualizar lista de herramientas\n",
    "tools = [buscar_producto_bd]\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys_msg = SystemMessage(content=\"\"\"Eres Mentor, un util y experto en la busqueda de coches.\n",
    "INSTRUCCIONES IMPORTANTES:\n",
    "**Antes de hacer una b√∫squeda en la base de datos, analiza la consulta y extrae solo la informaci√≥n clave.**  \n",
    "   - Si el usuario menciona un coche, filtra la consulta para obtener solo **la marca, modelo, versi√≥n, tipo de motorizaci√≥n y a√±o**.\n",
    "   - **No incluyas frases completas del usuario como b√∫squeda.**  \n",
    "   - **No pases palabras como \"quiero\", \"busco\", \"auto\", \"coche\", \"modelo\", \"a√±o\" si no son parte del nombre oficial del coche.**\n",
    "   - **Ejemplo:**  \n",
    "     - Entrada: `\"quiero coche bmw serie 1 120d hibrido a√±o 2024\"`  \n",
    "     - **Consulta que debes generar:** `\"bmw serie 1 120d hibrido 2024\"`\n",
    "\n",
    "**Definiendo Preferencias**\n",
    "   - Para dar recomendaciones acertadas, puedes pedir al usuario que proporcione detalles sobre lo que busca:\n",
    "     ‚Ä¢ ¬øTienes una **marca** preferida?\n",
    "     ‚Ä¢ ¬øCu√°l es tu **presupuesto m√°ximo**? (Opcional)\n",
    "     ‚Ä¢ ¬øTe importa el **kilometraje m√°ximo**? (Opcional)\n",
    "     ‚Ä¢ ¬øQu√© **a√±os de antig√ºedad** son aceptables? (Opcional)\n",
    "\n",
    "**Presentaci√≥n de Resultados**\n",
    "    - Aplica los filtros pero muestra tambi√©n alguna alternativa fuera de los filtros si es muy relevante\n",
    "    Usa este formato para cada coche encontrado: \n",
    "    ### [Modelo]\n",
    "    ![Imagen del veh√≠culo]([url_imagen])\n",
    "     - **Precio:** [precio]‚Ç¨\n",
    "     - **Kil√≥metros:** [km] km\n",
    "     - **Mec√°nica:** [tipo]\n",
    "     - **A√±o:** [year]\n",
    "     - **Similitud con tu b√∫squeda:** [score]\n",
    " \n",
    "** Ajustes**\n",
    "   - Si no encuentras lo que buscas, dime si quieres:\n",
    "   - Aumentar el **presupuesto** para ver modelos m√°s recientes.\n",
    "   - Ampliar el **kilometraje permitido** para m√°s opciones.\n",
    "   - Incluir **otros a√±os** para expandir la b√∫squeda.\n",
    "   \n",
    "**Informaci√≥n Adicional**\n",
    "   -usa la herramienta `buscar_info_adicional` para obtener informaci√≥n actualizada sobre un modelo espec√≠fico de coche.\n",
    "   - **Ejemplo:** `buscar_info_adicional(\"que caracteristicas tiene el BMW 320d 2019\")`\n",
    "\"\"\")\n",
    "# - Tambi√©n puedo **comparar dos coches** si tienes modelos espec√≠ficos en mente.\n",
    "def assistant(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Funci√≥n principal del asistente invocando una b√∫squeda.\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "#    user_input = state[\"messages\"][-1].content  # √öltimo mensaje del usuario\n",
    "# if detect_comparison_intent(user_input):\n",
    "#         car1, car2 = extract_car_models_llm(user_input)\n",
    "#         if car1 and car2:\n",
    "#             car1_data, car2_data = obtener_datos_comparacion(car1, car2)\n",
    "#             return {\"messages\": [comparar_coches_llm(car1_data, car2_data)]}\n",
    "#         else:\n",
    "#             return {\"messages\": [\"No pude identificar claramente los coches a comparar. ¬øPodr√≠as mencionarlos nuevamente?\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "# Graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "graph.add_node(\"assistant\", assistant)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "graph.add_edge(START, \"assistant\")\n",
    "graph.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    lambda state: logging.debug(f\"tools_condition eval√∫a: {tools_condition(state)}\") or tools_condition(state)\n",
    ")\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "#     tools_condition,\n",
    "# )\n",
    "graph.add_edge(\"tools\", \"assistant\")\n",
    "graph = graph.compile(checkpointer=memory)\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"quiero coche bmw serie 1 120d hibrido a√±o 2024\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"kilometraje 50.000 y presupuesto no importa, muestrame todas las opciones\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"podrias darme las caracteristicas del bmw serie 1 118i 2024 diesel\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"si, dame las caracteristicas del El 118i a gasolina\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"quiero un coche kia sportage a gasolina, puede ser a√±o 2011 a 2020 y no importa el kilometraje\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"maximo 25.000 euros\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"Mentor quiero un coche familiar, me podrias recomendar alguno?\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"segun tu conocimiento que me recomiendas?\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"pues SUV estaria bien y presupuesto hasta  12.000\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"diesel o gasolina esta bien\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"vale maximo 10 a√±os\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_env (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
