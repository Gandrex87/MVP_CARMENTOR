{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion del Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. CONFIGURACIÓN INICIAL (Tu código actual) ---\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage\n",
    "from IPython.display import Image, display\n",
    "from graph.perfil.builder import build_sequential_agent_graph # Ajusta la ruta si es necesario\n",
    "import logging\n",
    "\n",
    "# Configuración del logging para ver todo el detalle\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Construir el grafo\n",
    "graph = build_sequential_agent_graph()\n",
    "\n",
    "# --- 2. DEFINE EL 'CONFIG MAESTRO' PARA LA CONVERSACIÓN ---\n",
    "# Usamos tu 'thread_id' fijo y añadimos la clave 'interrupt_after'.\n",
    "# Este config se reutilizará en todas las llamadas para esta conversación.\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"1\", # Usando tu thread_id\n",
    "    },\n",
    "    \"interrupt_after\": [\n",
    "        \"generar_mensaje_transicion_perfil\",\n",
    "        \"generar_mensaje_transicion_pasajeros\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"✅ Configuración lista. Iniciando la prueba de conversación.\")\n",
    "print(f\"   ID de Conversación (thread_id): {config['configurable']['thread_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- TURNO 1: CP ---\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'HumanMessage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# --- TURNO 1: El usuario da su Código Postal ---\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- TURNO 1: CP ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m input_message_1 = \u001b[43mHumanMessage\u001b[49m(content=\u001b[33m\"\u001b[39m\u001b[33mmi cp es 46009\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m output_1 = graph.invoke({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [input_message_1]}, config) \n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Imprimimos la respuesta del agente\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'HumanMessage' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- TURNO 1: El usuario da su Código Postal ---\n",
    "print(\"\\n\\n--- TURNO 1: CP ---\")\n",
    "input_message_1 = HumanMessage(content=\"mi cp es 46009\")\n",
    "output_1 = graph.invoke({\"messages\": [input_message_1]}, config) \n",
    "# Imprimimos la respuesta del agente\n",
    "if output_1['messages'][-1]:\n",
    "    output_1['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- TURNO 1: El usuario da su Código Postal ---\n",
    "print(\"\\n\\n--- TURNO 1: CP ---\")\n",
    "input_message_1 = HumanMessage(content=\"si\")\n",
    "output_1 = graph.invoke({\"messages\": [input_message_1]}, config) \n",
    "# Imprimimos la respuesta del agente\n",
    "if output_1['messages'][-1]:\n",
    "    output_1['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- TURNO 1: El usuario da su Código Postal ---\n",
    "print(\"\\n\\n--- TURNO 1: CP ---\")\n",
    "input_message_1 = HumanMessage(content=\"7\")\n",
    "output_1 = graph.invoke({\"messages\": [input_message_1]}, config) \n",
    "# Imprimimos la respuesta del agente\n",
    "if output_1['messages'][-1]:\n",
    "    output_1['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Esta es la llamada que activará la interrupción.\n",
    "print(\"\\n\\n--- TURNO CLAVE: El usuario completa el perfil ---\")\n",
    "input_message_final_perfil = HumanMessage(content=\"un 8, le doy mucha importancia\")\n",
    "\n",
    "# LLAMADA 1: El grafo se ejecutará y se detendrá después del mensaje de transición.\n",
    "output_transicion = graph.invoke({\"messages\": [input_message_final_perfil]}, config)\n",
    "\n",
    "# Imprimimos el último mensaje. Debería ser el mensaje de transición.\n",
    "print(\"\\n================================== Ai Message (TRANSICIÓN) ================================\")\n",
    "if output_transicion['messages'][-1]:\n",
    "    output_transicion['messages'][-1].pretty_print()\n",
    "print(\"========================================================================================\\n\")\n",
    "print(\"ℹ️ El grafo se ha detenido después del mensaje de transición, como se esperaba.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLAMADA 2: El grafo continúa desde la interrupción.\n",
    "output_continuacion = graph.invoke(None, config)\n",
    "\n",
    "# Imprimimos el último mensaje. Ahora debería ser la primera pregunta sobre pasajeros.\n",
    "print(\"\\n================================== Ai Message (CONTINUACIÓN) ==============================\")\n",
    "if output_continuacion['messages'][-1]:\n",
    "    output_continuacion['messages'][-1].pretty_print()\n",
    "print(\"========================================================================================\\n\")\n",
    "print(\"✅ ¡Éxito! El agente ha formulado la siguiente pregunta de la nueva etapa.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno local detectado. Verificando GOOGLE_APPLICATION_CREDENTIALS del archivo .env...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from IPython.display import Image, display\n",
    "from graph.perfil.builder import build_sequential_agent_graph\n",
    "import logging\n",
    "\n",
    "# --- CONFIGURACIÓN DEL LOGGING ---\n",
    "\n",
    "# logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "#logging.getLogger().setLevel(level=logging.DEBUG)\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG) #o level=logging.DEBUG\n",
    "\n",
    "\n",
    "# Construir el grafo\n",
    "graph = build_sequential_agent_graph()\n",
    "#display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? False\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_cp (Etapa CP no completada)\n",
      "--- Ejecutando Nodo: buscar_info_clima_node ---\n",
      "DEBUG (Clima) ► Buscando datos climáticos para CP: 46009\n",
      "DEBUG (BQ Clima) ► Query: \n",
      "        SELECT\n",
      "            EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE MUNICIPIO_ZBE = @cp_param) AS MUNICIPIO_ZBE,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_LLUVIAS = @cp_param) AS ZONA_LLUVIAS,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_NIEBLAS = @cp_param) AS ZONA_NIEBLAS,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_NIEVE = @cp_param) AS ZONA_NIEVE,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_CLIMA_MONTA = @cp_param) AS ZONA_CLIMA_MONTA,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_GLP = @cp_param) AS ZONA_GLP,\n",
      "       EXISTS(SELECT 1 FROM `thecarmentor-mvp2.web_cars.zonas_climas` WHERE ZONA_GNV = @cp_param) AS ZONA_GNV\n",
      "        \n",
      "DEBUG (BQ Clima) ► Params: 46009\n",
      "DEBUG (Clima) ► Datos climáticos encontrados: {'MUNICIPIO_ZBE': True, 'ZONA_LLUVIAS': False, 'ZONA_NIEBLAS': False, 'ZONA_NIEVE': False, 'ZONA_CLIMA_MONTA': False, 'ZONA_GLP': True, 'ZONA_GNV': True, 'cp_valido_encontrado': True, 'codigo_postal_consultado': '46009'}\n",
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Los coches son una de tus grandes aficiones?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"46009\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿El aspecto del coche influye mucho en tu elección, o no tanto?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Este será el coche que más vas a utilizar en el día a día?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"el aspecto no influye mucho\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Con qué frecuencia usarás el coche?\n",
      "* 💨 A diario (incluso varias veces al día)\n",
      "* 🔄 Frecuentemente (varias veces por semana)\n",
      "* 🕐 Ocasionalmente (pocas veces al mes)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Cuántos kilómetros haces, por lo general, en un trayecto típico?\n",
      "* 🟣 Hasta 10 km\n",
      "* 🟡 10-50 km\n",
      "* 🟠 51-150 km\n",
      "* 🔵 Más de 150 km\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"a diario\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Pensando en viajes más largos, ¿realizas recorridos de más de 150 km de vez en cuando?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hasta 10km\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Tu uso principal del coche es en ciudad?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Lo emplearás principalmente como coche de uso particular o como herramienta de trabajo?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Lo emplearás principalmente como coche de uso particular o como herramienta de trabajo?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"sera de uso particular\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Eres de los que conducen para diferenciarse o prefieres no destacar demasiado?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"particular\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Superas el 1,90 m de altura? Esto influye en el espacio del coche que elijamos.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"prefiero no destacar\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Acostumbras a viajar con el maletero muy cargado?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿El coche que buscas debería poder tirar de una caravana o remolque sin problemas?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no llevo nada en el maletero\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Con qué tipo de terreno se enfrentará tu coche? :\n",
      "* 🛣️ Solo asfalto\n",
      "* 🌲 También por pistas sin asfaltar, de forma ocasional\n",
      "* 🏔️ Frecuentemente por terrenos complicados o en condiciones extremas\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Conduces de forma relajada o prefieres sensaciones más deportivas?\n",
      "* 🚗 Relajada\n",
      "* 🏁 Deportiva\n",
      "* ⚖️ Depende del día, mixto\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"asfalto\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hablemos un poco de dónde aparcarás. ¿Tienes garaje o plaza de aparcamiento propia?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la primera\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"preferencias_usuario\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Genial lo del garaje/plaza! Y dime, ¿el espacio que tienes es amplio y te permite aparcar un coche de cualquier tamaño con comodidad?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Comprendo que el espacio es ajustado. ¿Cuál es la principal limitación de dimensión?\n",
      " ↔️ Ancho\n",
      " ↕️ Alto\n",
      " ⬅️➡️ Largo\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿cuentas con un punto de carga para vehículo eléctrico en tu domicilio o lugar de trabajo habitual?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tengo un garaje muy angosto\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apasionado_motor='sí' valora_estetica='no' coche_principal_hogar='sí' frecuencia_uso=<FrecuenciaUso.DIARIO: 'diario'> distancia_trayecto=<DistanciaTrayecto.MENOS_10_KM: 'no supera los 10 km'> realiza_viajes_largos='no' frecuencia_viajes_largos=None circula_principalmente_ciudad='sí' uso_profesional='no' tipo_uso_profesional=None prefiere_diseno_exclusivo='no' altura_mayor_190='no' transporta_carga_voluminosa='no' necesita_espacio_objetos_especiales=None arrastra_remolque='no' tiene_garage='sí' problemas_aparcar_calle=None espacio_sobra_garage='no' problema_dimension_garage=[<DimensionProblematica.ANCHO: 'ancho'>] tiene_punto_carga_propio=None aventura=<NivelAventura.ninguna: 'ninguna'> estilo_conduccion=<EstiloConduccion.TRANQUILO: 'tranquilo'> solo_electricos=None prioriza_baja_depreciacion=None transmision_preferida=None rating_fiabilidad_durabilidad=None rating_seguridad=None rating_comodidad=None rating_impacto_ambiental=None rating_tecnologia_conectividad=None rating_costes_uso=None\n"
     ]
    }
   ],
   "source": [
    "print(output['preferencias_usuario'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Tu elección se centra solo en coches eléctricos?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "DEBUG (PostProc Perfil) ► Aplicando regla: solo_electricos='sí' y sin transmision -> asignando AUTOMATICO\n",
      "DEBUG (PostProc Perfil) ► Perfil tras post-procesamiento: apasionado_motor='sí' valora_estetica='no' coche_principal_hogar='sí' frecuencia_uso=<FrecuenciaUso.DIARIO: 'diario'> distancia_trayecto=<DistanciaTrayecto.MENOS_10_KM: 'no supera los 10 km'> realiza_viajes_largos='no' frecuencia_viajes_largos=None circula_principalmente_ciudad='sí' uso_profesional='no' tipo_uso_profesional=None prefiere_diseno_exclusivo='no' altura_mayor_190='no' transporta_carga_voluminosa='no' necesita_espacio_objetos_especiales=None arrastra_remolque='no' tiene_garage='sí' problemas_aparcar_calle=None espacio_sobra_garage='no' problema_dimension_garage=[<DimensionProblematica.ANCHO: 'ancho'>] tiene_punto_carga_propio='no' aventura=<NivelAventura.ninguna: 'ninguna'> estilo_conduccion=<EstiloConduccion.TRANQUILO: 'tranquilo'> solo_electricos='sí' prioriza_baja_depreciacion=None transmision_preferida=<Transmision.AUTOMATICO: 'automático'> rating_fiabilidad_durabilidad=None rating_seguridad=None rating_comodidad=None rating_impacto_ambiental=None rating_tecnologia_conectividad=None rating_costes_uso=None\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Te importa que el coche mantenga bien su valor con el tiempo?\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Cuánto valoras que el coche sea fiable y dure muchos años sin dar problemas?\n",
      "📊 0 (nada importante) ———— 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Qué nivel de prioridad le das a la seguridad frente a otros aspectos del coche?\n",
      "📊 0 (nada importante) ———— 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Y en cuanto a la comodidad y confort del vehiculo como de importante es que sea elevado?\n",
      "📊 0 (nada importante) ———— 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Qué importancia le das a reducir las emisiones y cuidar el medio ambiente con tu coche?\n",
      "📊 0 (nada importante) ———— 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"4\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Cuánto te importa que el coche sea barato de mantener y eficiente en consumo?\n",
      "📊 0 (nada importante) ———— 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"8\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "-> Perfil incompleto. Transición a 'preguntar_preferencias'.\n",
      "--- Ejecutando Nodo: preguntar_preferencias_node ---\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Y para terminar con las valoraciones, ¿Qué importancia le das a la tecnología de a bordo y sistemas multimedia del vehículo??\n",
      "📊 0 (nada importante) ———— 10 (extremadamente importante)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"3\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? False\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_preferencias\n",
      "--- [Edge/Perfil] Decidiendo siguiente paso del perfil ---\n",
      "✅ Perfil completo. Pasando a 'generar_mensaje_transicion'.\n",
      "--- Ejecutando Nodo: generar_mensaje_transicion_perfil ---\n",
      "INFO: Añadido mensaje de transición: '¡Estupendo! Ya tengo una idea muy clara de tus gustos y preferencias. Ahora, para asegurarnos de que el coche se adapte perfectamente a quienes viajarán contigo, hablemos un poco sobre los pasajeros.'\n",
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_info_pasajeros\n",
      "--- [Edge/Pasajeros] Decidiendo siguiente paso de pasajeros ---\n",
      "❌ Info Pasajeros incompleta. Transición a 'preguntar_info_pasajeros'.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Sueles viajar con acompañantes en el coche habitualmente?\n",
      "\n",
      "* ✅ Sí\n",
      "* ❌ No\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? False\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_info_pasajeros\n",
      "--- [Edge/Pasajeros] Decidiendo siguiente paso de pasajeros ---\n",
      "✅ Info Pasajeros completa. Pasando a 'generar_mensaje_transicion_pasajeros'.\n",
      "--- Ejecutando Nodo: generar_mensaje_transicion_pasajeros ---\n",
      "INFO: Añadido mensaje de transición de pasajeros: '¡Genial! Con esto terminamos la sección de pasajeros. Ahora, si te parece, continuamos con el apartado económico para acotar la búsqueda.'\n",
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_economia\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Para definir tu presupuesto, ¿qué prefieres?\n",
      "\n",
      "* 1️⃣ Prefiero que me aconsejes con criterios de inteligencia financiera.\n",
      "* 2️⃣ Prefiero indicar yo mismo cuánto y cómo gastar.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_economia\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¿Cuáles son tus ingresos netos anuales aproximados? Este dato es clave para darte una recomendación financiera sólida.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"1\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_economia\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Gracias. Ahora, ¿de cuántos ahorros dispones para la compra del vehículo?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"mis ingresos son de 50.000 al año\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Ejecutando Nodo: route_based_on_state_node ---\n",
      "\n",
      "--- DEBUG: Evaluating Routing Decision ---\n",
      "DEBUG Router: Codigo Postal OK? True\n",
      "DEBUG Router: Prefs OK? True\n",
      "DEBUG Router: Pasajeros OK? True\n",
      "DEBUG Router: Economía OK? False\n",
      "DEBUG Router: Pesos Calculados? False\n",
      "DEBUG Router: Coches Buscados? False\n",
      "DEBUG Router: Decisión -> recopilar_economia\n",
      "--- Ejecutando Nodo: construir_filtros_node ---\n",
      "DEBUG (Filtros) ► Preferencias e info_clima disponibles. Construyendo filtros...\n",
      "DEBUG (Filtros) ► Filtros finales construidos: tipo_mecanica=[<TipoMecanica.BEV: 'BEV'>, <TipoMecanica.REEV: 'REEV'>] tipo_carroceria=None modo_adquisicion_recomendado='Financiado' precio_max_contado_recomendado=None cuota_max_calculada=395.8333333333333 plazas_min=1\n",
      "--- Ejecutando Nodo: calcular_km_anuales_postprocessing_node ---\n",
      "a: 10\n",
      "b: 10 -> 52 * 10 * 10\n",
      "--- Ejecutando Nodo: calcular_flags_dinamicos_node ---\n",
      "DEBUG contenido de los objetos:  preferencias_obj: apasionado_motor='sí' valora_estetica='no' coche_principal_hogar='sí' frecuencia_uso=<FrecuenciaUso.DIARIO: 'diario'> distancia_trayecto=<DistanciaTrayecto.MENOS_10_KM: 'no supera los 10 km'> realiza_viajes_largos='no' frecuencia_viajes_largos=None circula_principalmente_ciudad='sí' uso_profesional='no' tipo_uso_profesional=None prefiere_diseno_exclusivo='no' altura_mayor_190='no' transporta_carga_voluminosa='no' necesita_espacio_objetos_especiales=None arrastra_remolque='no' tiene_garage='sí' problemas_aparcar_calle=None espacio_sobra_garage='no' problema_dimension_garage=[<DimensionProblematica.ANCHO: 'ancho'>] tiene_punto_carga_propio='no' aventura=<NivelAventura.ninguna: 'ninguna'> estilo_conduccion=<EstiloConduccion.TRANQUILO: 'tranquilo'> solo_electricos='sí' prioriza_baja_depreciacion='no' transmision_preferida=<Transmision.AUTOMATICO: 'automático'> rating_fiabilidad_durabilidad=7 rating_seguridad=2 rating_comodidad=4 rating_impacto_ambiental=8 rating_tecnologia_conectividad=2 rating_costes_uso=3 - pasajeros suele_llevar_acompanantes=False frecuencia_viaje_con_acompanantes=None num_ninos_silla=None num_otros_pasajeros=None - clima MUNICIPIO_ZBE=True ZONA_LLUVIAS=False ZONA_NIEBLAS=False ZONA_NIEVE=False ZONA_CLIMA_MONTA=False ZONA_GLP=True ZONA_GNV=True cp_valido_encontrado=True codigo_postal_consultado='46009'\n",
      "DEBUG (CalcFlags) ► Valor de preferencias_obj.aventura: NivelAventura.ninguna (Tipo: <enum 'NivelAventura'>)\n",
      "--- Ejecutando Nodo: calcular_pesos_finales_node ---\n",
      "DEBUG_MIO (info_pasajeros_o     bj): suele_llevar_acompanantes=False frecuencia_viaje_con_acompanantes=None num_ninos_silla=None num_otros_pasajeros=None\n",
      "DEBUG_MIO_2: (km_anuales_val): 5200\n",
      "DEBUG (Garaje) ► Detectado: 'espacio_sobra_garage' es NO.\n",
      "DEBUG (Garaje) ► Valor de 'problema_dimension_garage': ['ancho']\n",
      "DEBUG (Garaje) ► ¡CONDICIÓN ANCHO CUMPLIDA! Aplicando multiplicador.\n",
      "DEBUG (compute_raw_weights) ►► Pesos Crudos Finales (listos para normalizar): {'estetica': 0.09899494936611665, 'premium': 0.4979959839195493, 'singular': 0.0709929573971954, 'deportividad_style_score': 0.06557438524302, 'fav_menor_rel_peso_potencia_score': 0.21189620100417092, 'potencia_maxima_style_score': 0.15491933384829668, 'par_motor_style_score': 0.12, 'fav_menor_aceleracion_score': 0.18973665961010275, 'fav_bajo_consumo': 0.12529964086141668, 'fav_bajo_coste_uso_directo': 0.198997487421324, 'fav_bajo_coste_mantenimiento_directo': 0.10862780491200216, 'devaluacion': 0.06782329983125268, 'fav_bajo_peso': 0.09695359714832658, 'par_motor_remolque_score': 0.06782329983125268, 'cap_remolque_cf_score': 0.07681145747868608, 'cap_remolque_sf_score': 0.08306623862918075, 'maletero_minimo_score': 0.21656407827707713, 'maletero_maximo_score': 0.17492855684535902, 'largo_vehiculo_score': 0.11704699910719625, 'fav_menor_largo_garage': 0.15198684153570663, 'fav_menor_ancho_garage': 1.228495014234897, 'fav_menor_alto_garage': 0.13601470508735444, 'fav_menor_superficie_planta': 0.10488088481701516, 'altura_libre_suelo': 0.21517434791350012, 'fav_menor_diametro_giro': 2.1120191760493086, 'batalla': 0.15684387141358122, 'indice_altura_interior': 0.17175564037317667, 'ancho': 0.17888543819998318, 'indice_habitabilidad': 0.22181073012818833, 'autonomia_uso_maxima': 0.27147743920996453, 'autonomia_uso_2nd_drive': 0.12041594578792296, 'menor_tiempo_carga_min': 0.1944222209522358, 'potencia_maxima_carga_AC': 0.10770329614269007, 'potencia_maxima_carga_DC': 0.14247806848775008, 'rating_fiabilidad': 0.24919871588754225, 'rating_durabilidad': 0.1532970971675589, 'rating_comodidad': 0.058309518948453, 'rating_tecnologia_conectividad': 0.0412310562561766, 'rating_seguridad': 0.12041594578792296}\n",
      "DEBUG (Normalize Weights) ► Pesos Normalizados: {'estetica': 0.011146989179411032, 'premium': 0.05607514201165278, 'singular': 0.007993920225103791, 'deportividad_style_score': 0.007383780358805474, 'fav_menor_rel_peso_potencia_score': 0.023859850172924583, 'potencia_maxima_style_score': 0.017444164062369785, 'par_motor_style_score': 0.013512191380413617, 'fav_menor_aceleracion_score': 0.02136465047110086, 'fav_bajo_consumo': 0.014108939393471303, 'fav_bajo_coste_uso_directo': 0.02240743445215318, 'fav_bajo_coste_mantenimiento_directo': 0.012231664076710065, 'devaluacion': 0.007637011728092174, 'fav_bajo_peso': 0.010917129664064273, 'par_motor_remolque_score': 0.007637011728092174, 'cap_remolque_cf_score': 0.008649092613837577, 'cap_remolque_sf_score': 0.009353390946738307, 'maletero_minimo_score': 0.024385460598356182, 'maletero_maximo_score': 0.019697234483283782, 'largo_vehiculo_score': 0.013179678770329481, 'fav_menor_largo_garage': 0.017113960751125548, 'fav_menor_ancho_garage': 0.13833049785188234, 'fav_menor_alto_garage': 0.015315472714090426, 'fav_menor_superficie_planta': 0.011809754898288548, 'altura_libre_suelo': 0.024228974743024313, 'fav_menor_diametro_giro': 0.2378167275490145, 'batalla': 0.017660870061544116, 'indice_altura_interior': 0.01933995902823216, 'ancho': 0.02014278563439438, 'indice_habitabilidad': 0.024976241964344646, 'autonomia_uso_maxima': 0.03056879261724704, 'autonomia_uso_2nd_drive': 0.013559027539499384, 'menor_tiempo_carga_min': 0.021892252150930606, 'potencia_maxima_carga_AC': 0.012127562914844934, 'potencia_maxima_carga_DC': 0.016043257740984647, 'rating_fiabilidad': 0.02806017284021492, 'rating_durabilidad': 0.017261497624915988, 'rating_comodidad': 0.00656574482776126, 'rating_tecnologia_conectividad': 0.004642682691250487, 'rating_seguridad': 0.013559027539499384}\n",
      "--- Ejecutando Nodo: formatear_tabla_resumen_node ---\n",
      "--- 🧠 SQL Query Template Enviada a BigQuery ---\n",
      "\n",
      "    WITH ScaledData AS (\n",
      "        SELECT\n",
      "            *,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(estetica, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS estetica_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(premium, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS premium_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(singular, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS singular_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(altura_libre_suelo, 79.0) - 79.0, NULLIF(314.0 - 79.0, 0)), 0) AS altura_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(batalla, 1650.0) - 1650.0, NULLIF(4035.0 - 1650.0, 0)), 0) AS batalla_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(indice_altura_interior, 0.9) - 0.9, NULLIF(2.7 - 0.9, 0)), 0) AS indice_altura_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(ancho, 1410.0) - 1410.0, NULLIF(2164.0 - 1410.0, 0)), 0) AS ancho_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(fiabilidad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS fiabilidad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(durabilidad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS durabilidad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(seguridad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS seguridad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(comodidad, 0.0) - 0.0, NULLIF(10.0 - 0.0, 0)), 0) AS comodidad_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(31.0 - COALESCE(costes_de_uso, 31.0), NULLIF(31.0 - 3.0, 0)), 0) AS costes_de_uso_bajo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(10.0 - COALESCE(costes_mantenimiento, 10.0), NULLIF(10.0 - 1.0, 0)), 0) AS costes_mantenimiento_bajo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(tecnologia, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS tecnologia_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(acceso_low_cost, 0.0) - 0.0, NULLIF(10.0 - 0.0, 0)), 0) AS acceso_low_cost_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(deportividad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS deportividad_bq_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(devaluacion, 0.0) - 0.0, NULLIF(10.0 - 0.0, 0)), 0) AS devaluacion_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(maletero_minimo, 11.0) - 11.0, NULLIF(15000.0 - 11.0, 0)), 0) AS maletero_minimo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(maletero_maximo, 11.0) - 11.0, NULLIF(15000.0 - 11.0, 0)), 0) AS maletero_maximo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(largo, 2450.0) - 2450.0, NULLIF(6400.0 - 2450.0, 0)), 0) AS largo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(autonomia_uso_maxima, 30.8) - 30.8, NULLIF(1582.4 - 30.8, 0)), 0) AS autonomia_uso_maxima_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(3500.0 - COALESCE(peso, 3500.0), NULLIF(3500.0 - 470.0, 0)), 0) AS bajo_peso_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(133.0 - COALESCE(indice_consumo_energia, 133.0), NULLIF(133.0 - 7.4, 0)), 0) AS bajo_consumo_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(par, 41.0) - 41.0, NULLIF(967.0 - 41.0, 0)), 0) AS par_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(capacidad_remolque_con_freno, 100.0) - 100.0, NULLIF(3600.0 - 100.0, 0)), 0) AS cap_remolque_cf_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(capacidad_remolque_sin_freno, 35.0) - 35.0, NULLIF(1250.0 - 35.0, 0)), 0) AS cap_remolque_sf_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(14.0 - COALESCE(superficie_planta, 14.0), NULLIF(14.0 - 2.9, 0)), 0) AS menor_superficie_planta_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(15.6 - COALESCE(diametro_giro, 15.6), NULLIF(15.6 - 7.0, 0)), 0) AS menor_diametro_giro_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(6400.0 - COALESCE(largo, 6400.0), NULLIF(6400.0 - 2450.0, 0)), 0) AS menor_largo_garage_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(2164.0 - COALESCE(ancho, 2164.0), NULLIF(2164.0 - 1410.0, 0)), 0) AS menor_ancho_garage_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(2940.0 - COALESCE(alto, 2940.0), NULLIF(2940.0 - 1052.0, 0)), 0) AS menor_alto_garage_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(deportividad, 1.0) - 1.0, NULLIF(10.0 - 1.0, 0)), 0) AS deportividad_style_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(28.3 - COALESCE(relacion_peso_potencia, 28.3), NULLIF(28.3 - 1.8, 0)), 0) AS menor_rel_peso_potencia_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(potencia_maxima, 41.0) - 41.0, NULLIF(789.0 - 41.0, 0)), 0) AS potencia_maxima_style_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(34.0 - COALESCE(aceleracion_0_100, 34.0), NULLIF(34.0 - 2.5, 0)), 0) AS menor_aceleracion_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(autonomia_uso_principal, 21.8) - 21.8, NULLIF(1480.6 - 21.8, 0)), 0) AS autonomia_uso_principal_scaled,\n",
      "            COALESCE(SAFE_DIVIDE(COALESCE(autonomia_uso_2nd_drive, 0.0) - 0.0, NULLIF(936.4 - 0.0, 0)), 0) AS autonomia_uso_2nd_drive_scaled, \n",
      "            (CASE WHEN COALESCE(tiempo_carga_min, 0) = 0 THEN 0.0 ELSE COALESCE(SAFE_DIVIDE(640.1 - tiempo_carga_min, NULLIF(640.1 - 18.0, 0)), 0) END) AS menor_tiempo_carga_min_scaled,\n",
      "            (CASE WHEN COALESCE(potencia_maxima_carga_AC, 0) = 0 THEN 0.0 ELSE COALESCE(SAFE_DIVIDE(potencia_maxima_carga_AC - 2.3, NULLIF(22.0 - 2.3, 0)), 0) END) AS potencia_maxima_carga_AC_scaled,\n",
      "            (CASE WHEN COALESCE(potencia_maxima_carga_DC, 0) = 0 THEN 0.0 ELSE COALESCE(SAFE_DIVIDE(potencia_maxima_carga_DC - 1.0, NULLIF(270.0 - 1.0, 0)), 0) END) AS potencia_maxima_carga_DC_scaled,\n",
      "            \n",
      "        FROM\n",
      "            `thecarmentor-mvp2.web_cars.coches_prueba_2`\n",
      "            --`thecarmentor-mvp2.web_cars.match_coches_pruebas`\n",
      "    ),      \n",
      "    -- ESTE ES EL CTE CLAVE CON TODOS LOS DESGLOSES\n",
      "    DebugScores AS (\n",
      "        SELECT\n",
      "            sd.*,\n",
      "            \n",
      "            -- Desglose de puntuacion_base\n",
      "            (sd.estetica_scaled * @peso_estetica * 100.0) AS dbg_score_estetica,\n",
      "            (sd.premium_scaled * @peso_premium * 100.0) AS dbg_score_premium,\n",
      "            (sd.singular_scaled * @peso_singular * 100.0) AS dbg_score_singular,\n",
      "            (sd.altura_scaled * @peso_altura * 100.0) AS dbg_score_altura_libre,\n",
      "            (sd.batalla_scaled * @peso_batalla * 100.0) AS dbg_score_batalla,\n",
      "            (sd.indice_altura_scaled * @peso_indice_altura * 100.0) AS dbg_score_altura_interior,\n",
      "            (sd.ancho_scaled * @peso_ancho_general_score * 100.0) AS dbg_score_ancho,\n",
      "            (sd.devaluacion_scaled * @peso_devaluacion * 100.0) AS dbg_score_devaluacion,\n",
      "            (sd.maletero_minimo_scaled * @peso_maletero_minimo_score * 100.0) AS dbg_score_maletero_min,\n",
      "            (sd.maletero_maximo_scaled * @peso_maletero_maximo_score * 100.0) AS dbg_score_maletero_max,\n",
      "            (sd.largo_scaled * @peso_largo_vehiculo_score * 100.0) AS dbg_score_largo,\n",
      "            (sd.autonomia_uso_maxima_scaled * @peso_autonomia_vehiculo * 100.0) AS dbg_score_autonomia_max,\n",
      "            (sd.bajo_peso_scaled * @peso_fav_bajo_peso * 100.0) AS dbg_score_bajo_peso,\n",
      "            (sd.par_scaled * @peso_par_motor_remolque_score * 100.0) AS dbg_score_par_remolque,\n",
      "            (sd.cap_remolque_cf_scaled * @peso_cap_remolque_cf_score * 100.0) AS dbg_score_remolque_cf,\n",
      "            (sd.cap_remolque_sf_scaled * @peso_cap_remolque_sf_score * 100.0) AS dbg_score_remolque_sf,\n",
      "            (sd.menor_superficie_planta_scaled * @peso_fav_menor_superficie_planta * 100.0) AS dbg_score_menor_superficie,\n",
      "            (sd.menor_diametro_giro_scaled * @peso_fav_menor_diametro_giro * 100.0) AS dbg_score_menor_giro,\n",
      "            (sd.menor_largo_garage_scaled * @peso_fav_menor_largo_garage * 100.0) AS dbg_score_menor_largo,\n",
      "            (sd.menor_ancho_garage_scaled * @peso_fav_menor_ancho_garage * 100.0) AS dbg_score_menor_ancho,\n",
      "            (sd.menor_alto_garage_scaled * @peso_fav_menor_alto_garage * 100.0) AS dbg_score_menor_alto,\n",
      "            (sd.deportividad_style_scaled * @peso_deportividad_style_score * 100.0) AS dbg_score_deportividad,\n",
      "            (sd.menor_rel_peso_potencia_scaled * @peso_fav_menor_rel_peso_potencia_score * 100.0) AS dbg_score_menor_rel_peso_pot,\n",
      "            (sd.potencia_maxima_style_scaled * @peso_potencia_maxima_style_score * 100.0) AS dbg_score_potencia,\n",
      "            (sd.par_scaled * @peso_par_motor_style_score * 100.0) AS dbg_score_par_deportivo,\n",
      "            --(sd.autonomia_uso_principal_scaled * @peso_autonomia_uso_principal * 100.0) AS dbg_score_autonomia_principal,\n",
      "            (sd.autonomia_uso_2nd_drive_scaled * @peso_autonomia_uso_2nd_drive * 100.0) AS dbg_score_autonomia_2nd,\n",
      "            (sd.menor_tiempo_carga_min_scaled * @peso_menor_tiempo_carga_min * 100.0) AS dbg_score_menor_t_carga,\n",
      "            (sd.potencia_maxima_carga_AC_scaled * @peso_potencia_maxima_carga_AC * 100.0) AS dbg_score_pot_carga_ac,\n",
      "            (sd.potencia_maxima_carga_DC_scaled * @peso_potencia_maxima_carga_DC * 100.0) AS dbg_score_pot_carga_dc,\n",
      "            (sd.menor_aceleracion_scaled * @peso_fav_menor_aceleracion_score * 100.0) AS dbg_score_menor_aceleracion, \n",
      "            -- Desglose de ajustes_experto --\n",
      "            ( (sd.seguridad_scaled * @peso_rating_seguridad) * (CASE WHEN @flag_bonus_seguridad_critico = TRUE THEN 6.0 WHEN @flag_bonus_seguridad_fuerte = TRUE THEN 3.0 ELSE 1.0 END) * 100.0 ) as dbg_bonus_seguridad,\n",
      "                -- Bonus Acumulativo para Fiabilidad\n",
      "            ( (sd.fiabilidad_scaled * @peso_rating_fiabilidad) * ((CASE WHEN @flag_aplicar_logica_distintivo = TRUE THEN 1.2 ELSE 1.0 END) * (CASE WHEN @flag_bonus_fiab_dur_critico = TRUE THEN 2.5 WHEN @flag_bonus_fiab_dur_fuerte = TRUE THEN 1.2 ELSE 1.0 END)) * 100.0 ) as dbg_bonus_fiabilidad,  \n",
      "                -- Bonus Acumulativo para Durabilidad\n",
      "            ( (sd.durabilidad_scaled * @peso_rating_durabilidad) * ((CASE WHEN @flag_aplicar_logica_distintivo = TRUE THEN 1.2 ELSE 1.0 END) * (CASE WHEN @flag_bonus_fiab_dur_critico = TRUE THEN 2.5 WHEN @flag_bonus_fiab_dur_fuerte = TRUE THEN 1.2 ELSE 1.0 END)) * 100.0) as dbg_bonus_durabilidad,\n",
      "            -- ✅ NUEVA LÓGICA: Bonus proporcional para características de COSTE\n",
      "            ( (sd.bajo_consumo_scaled * @peso_fav_bajo_consumo) * (CASE WHEN @flag_bonus_costes_critico = TRUE THEN 4.0 ELSE 1.0 END) * 100.0 )  as dbg_bonus_bajo_consumo,\n",
      "            ( (sd.costes_de_uso_bajo_scaled * @peso_fav_bajo_coste_uso_directo) * (CASE WHEN @flag_bonus_costes_critico = TRUE THEN 4.0 ELSE 1.0 END) * 100.0 )  as dbg_bonus_coste_uso,\n",
      "            ( (sd.costes_mantenimiento_bajo_scaled * @peso_fav_bajo_coste_mantenimiento_directo) * (CASE WHEN @flag_bonus_costes_critico = TRUE THEN 4.0 ELSE 1.0 END) * 100.0 )  as dbg_bonus_coste_mantenimiento,\n",
      "            (CASE WHEN COALESCE(sd.km_ocasion, 0) >= 250000 THEN -25 ELSE 0.0 END) as dbg_pen_km_extremo,\n",
      "            (CASE WHEN @penalizar_puertas = TRUE AND puertas <= 3 THEN -8 ELSE 0.0 END) as dbg_pen_puertas,\n",
      "            (CASE WHEN @flag_penalizar_low_cost_comodidad = TRUE THEN (sd.acceso_low_cost_scaled * -1.5) ELSE 0.0 END) as dbg_pen_low_cost_comodidad,\n",
      "            (CASE WHEN @flag_penalizar_deportividad_comodidad = TRUE THEN (sd.deportividad_bq_scaled * -1.5) ELSE 0.0 END) as dbg_pen_deportividad_comodidad,\n",
      "            (CASE WHEN @flag_penalizar_antiguo_tec = TRUE THEN CASE\n",
      "                WHEN sd.anos_vehiculo > 15 THEN -25\n",
      "                WHEN sd.anos_vehiculo > 10 THEN -20 \n",
      "                WHEN sd.anos_vehiculo > 7  THEN -15 \n",
      "                WHEN sd.anos_vehiculo > 5  THEN -7 \n",
      "            ELSE 0.0 END ELSE 0.0 END) as dbg_pen_antiguedad,\n",
      "            -- ✅ NUEVA LÓGICA: Penalización general por antigüedad\n",
      "            (CASE\n",
      "                WHEN sd.ano_unidad < 1990 THEN -50\n",
      "                WHEN sd.ano_unidad BETWEEN 1991 AND 1995 THEN -30\n",
      "                WHEN sd.ano_unidad BETWEEN 1996 AND 2000 THEN -20\n",
      "                WHEN sd.ano_unidad BETWEEN 2001 AND 2006 AND sd.tipo_mecanica = 'DIESEL' THEN -10\n",
      "                ELSE 0.0\n",
      "            END) as dbg_pen_antiguedad_general,\n",
      "            (CASE WHEN @flag_aplicar_logica_distintivo = TRUE THEN CASE WHEN UPPER(sd.distintivo_ambiental) IN ('CERO', '0', 'ECO', 'C') THEN 5 WHEN UPPER(sd.distintivo_ambiental) IN ('B', 'NA') THEN -8 ELSE 0.0 END ELSE 0.0 END) as dbg_ajuste_distintivo,\n",
      "            (CASE WHEN @flag_aplicar_logica_distintivo = TRUE AND COALESCE(sd.ocasion, FALSE) = TRUE THEN 8 ELSE 0.0 END) as dbg_bonus_ocasion_ambiental,\n",
      "            (CASE WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('CERO', '0', 'ECO') THEN 10 WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('C') THEN 8 WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('NA') THEN -10 WHEN @flag_es_municipio_zbe = TRUE AND UPPER(sd.distintivo_ambiental) IN ('B') THEN -8 ELSE 0.0 END) as dbg_ajuste_zbe,\n",
      "            (CASE WHEN @flag_pen_bev_reev_avent_ocas = TRUE AND sd.tipo_mecanica IN ('BEV', 'REEV') THEN -10 ELSE 0.0 END) as dbg_pen_bev_reev_avent_ocas,\n",
      "            (CASE WHEN @flag_pen_phev_avent_ocas = TRUE AND sd.tipo_mecanica IN ('PHEVD', 'PHEVG') THEN -5 ELSE 0.0 END) as dbg_pen_phev_avent_ocas,\n",
      "            (CASE WHEN @flag_pen_electrif_avent_extr = TRUE AND sd.tipo_mecanica IN ('BEV', 'REEV', 'PHEVD', 'PHEVG') THEN -25 ELSE 0.0 END) as dbg_pen_electrif_avent_extr,\n",
      "            (CASE WHEN @flag_fav_car_montana = TRUE AND sd.tipo_carroceria IN ('SUV', 'TODOTERRENO') THEN 5 ELSE 0.0 END) as dbg_bonus_car_montana,\n",
      "            (CASE WHEN @flag_fav_car_comercial = TRUE AND sd.tipo_carroceria IN ('COMERCIAL') THEN 20 ELSE 0.0 END) as dbg_bonus_car_comercial,\n",
      "            (CASE WHEN @flag_fav_car_pasajeros_pro = TRUE AND sd.tipo_carroceria IN ('3VOL', 'MONOVOLUMEN') THEN 20 ELSE 0.0 END) as dbg_bonus_car_pasajeros,\n",
      "            (CASE WHEN @flag_desfav_car_no_aventura = TRUE AND sd.tipo_carroceria IN ('PICKUP', 'TODOTERRENO') THEN -15 ELSE 0.0 END) as dbg_pen_car_no_aventura,\n",
      "            (CASE WHEN @flag_fav_suv_aventura_ocasional = TRUE AND sd.tipo_carroceria IN ('SUV') THEN 10 ELSE 0.0 END) as dbg_bonus_suv_avent_ocas,\n",
      "            (CASE WHEN @flag_fav_pickup_todoterreno_aventura_extrema = TRUE AND sd.tipo_carroceria IN ('TODOTERRENO') THEN 25 ELSE 0.0 END) as dbg_bonus_tt_avent_extr,\n",
      "            (CASE WHEN @flag_fav_pickup_todoterreno_aventura_extrema = TRUE AND sd.tipo_carroceria IN ('PICKUP') THEN 5 ELSE 0.0 END) as dbg_bonus_pickup_avent_extr,\n",
      "            (CASE WHEN @flag_aplicar_logica_objetos_especiales = TRUE THEN CASE WHEN sd.tipo_carroceria IN ('MONOVOLUMEN', 'FURGONETA', 'FAMILIAR', 'SUV') THEN 10 WHEN sd.tipo_carroceria IN ('3VOL', 'COUPE', 'DESCAPOTABLE') THEN -10 ELSE 0.0 END ELSE 0.0 END) as dbg_ajuste_objetos_especiales,\n",
      "            (CASE WHEN @flag_fav_carroceria_confort = TRUE AND sd.tipo_carroceria IN ('3VOL', '2VOL', 'SUV', 'FAMILIAR', 'MONOVOLUMEN') THEN 5 ELSE 0.0 END) as dbg_bonus_car_confort,\n",
      "            (CASE WHEN @flag_logica_uso_ocasional = TRUE AND COALESCE(sd.ocasion, FALSE) = TRUE THEN 3 ELSE 0.0 END) as dbg_bonus_ocasion_uso_ocas,\n",
      "            (CASE WHEN @flag_logica_uso_ocasional = TRUE AND sd.tipo_mecanica IN ('PHEVD', 'PHEVG', 'BEV', 'REEV') THEN -10 ELSE 0.0 END) as dbg_pen_electrif_uso_ocas,\n",
      "            (CASE WHEN @flag_favorecer_bev_uso_definido = TRUE AND sd.tipo_mecanica IN ('BEV', 'REEV') THEN 10 ELSE 0.0 END) as dbg_bonus_bev_uso_definido,\n",
      "            (CASE WHEN @flag_penalizar_phev_uso_intensivo = TRUE AND sd.tipo_mecanica IN ('PHEVD', 'PHEVG') THEN -15 ELSE 0.0 END) as dbg_pen_phev_uso_intensivo,\n",
      "            (CASE WHEN @flag_favorecer_electrificados_por_punto_carga = TRUE AND sd.tipo_mecanica IN ('BEV', 'PHEVD', 'PHEVG', 'REEV') THEN 10 ELSE 0.0 END) as dbg_bonus_punto_carga,\n",
      "            (CASE WHEN @flag_bonus_awd_clima_adverso = TRUE AND sd.traccion = 'ALL' THEN 10 WHEN @penalizar_awd_ninguna_aventura = TRUE AND sd.traccion = 'ALL' THEN -10 WHEN @favorecer_awd_aventura_ocasional = TRUE AND sd.traccion = 'ALL' THEN 10 WHEN @favorecer_awd_aventura_extrema = TRUE AND sd.traccion = 'ALL' THEN 20 ELSE 0.0 END) as dbg_ajuste_awd_aventura,\n",
      "            (CASE WHEN @flag_bonus_awd_nieve = TRUE AND sd.traccion = 'ALL' THEN 10 ELSE 0.0 END) as dbg_bonus_awd_nieve,\n",
      "            (CASE WHEN @flag_bonus_awd_montana = TRUE AND sd.traccion = 'ALL' THEN 5 ELSE 0.0 END) as dbg_bonus_awd_montana,\n",
      "            (CASE WHEN @flag_logica_reductoras_aventura = 'FAVORECER_OCASIONAL' AND COALESCE(sd.reductoras, FALSE) = TRUE THEN 10 WHEN @flag_logica_reductoras_aventura = 'FAVORECER_EXTREMA' AND COALESCE(sd.reductoras, FALSE) = TRUE THEN 25 ELSE 0.0 END) as dbg_bonus_reductoras,\n",
      "            (CASE WHEN @flag_logica_diesel_ciudad = 'PENALIZAR' AND sd.tipo_mecanica IN ('DIESEL', 'HEVD', 'MHEVD') THEN -15 WHEN @flag_logica_diesel_ciudad = 'BONIFICAR' AND sd.tipo_mecanica IN ('DIESEL', 'HEVD', 'MHEVD') THEN 20 ELSE 0.0 END) as dbg_ajuste_diesel_ciudad,\n",
      "            -- ✅ LÓGICA MEJORADA: Penalización por tamaño no compacto, AHORA CONTEXTUAL\n",
      "            (CASE \n",
      "                WHEN @flag_penalizar_tamano_no_compacto = TRUE AND\n",
      "                     (\n",
      "                        -- Si es conductor urbano, penaliza coches > 4.25m\n",
      "                        (@flag_es_conductor_urbano = TRUE AND sd.largo >= 4250) \n",
      "                        OR\n",
      "                        -- Si NO es conductor urbano, penaliza coches > 4.50m\n",
      "                        (@flag_es_conductor_urbano = FALSE AND sd.largo >= 4500)\n",
      "                     )\n",
      "                THEN -5 \n",
      "                ELSE 0.0 \n",
      "            END) as dbg_pen_tamano_no_compacto,\n",
      "             (CASE \n",
      "                WHEN @flag_bonus_singularidad_lifestyle = TRUE AND sd.tipo_carroceria = 'COUPE' THEN 5\n",
      "                WHEN @flag_bonus_singularidad_lifestyle = TRUE AND sd.tipo_carroceria = 'DESCAPOTABLE' THEN 4\n",
      "                ELSE 0.0 \n",
      "            END) as dbg_bonus_lifestyle,\n",
      "            (CASE\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'COUPE' THEN 4\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'DESCAPOTABLE' THEN 3\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'COMERCIAL' THEN -10\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'FURGONETA' THEN -7\n",
      "                WHEN @flag_deportividad_lifestyle = TRUE AND sd.tipo_carroceria = 'SUV' THEN -5\n",
      "                ELSE 0.0\n",
      "            END) as dbg_ajuste_deportividad_lifestyle,\n",
      "            (CASE \n",
      "                WHEN @flag_deportividad_lifestyle = TRUE \n",
      "                     AND sd.tipo_mecanica = 'BEV' \n",
      "                     AND sd.tipo_carroceria NOT IN ('COUPE', 'DESCAPOTABLE')\n",
      "                THEN -5\n",
      "                ELSE 0.0 \n",
      "            END) as dbg_pen_bev_lifestyle,\n",
      "            (CASE\n",
      "                WHEN @flag_ajuste_maletero_personal = TRUE THEN\n",
      "                    -- Sumamos las tres penalizaciones posibles\n",
      "                    (CASE \n",
      "                        WHEN sd.plazas <= 3 AND sd.maletero_minimo < 450 THEN -5\n",
      "                        WHEN sd.plazas > 3 AND sd.maletero_minimo < 550 THEN -5\n",
      "                        ELSE 0.0\n",
      "                    END)\n",
      "                    +\n",
      "                    (CASE\n",
      "                        WHEN sd.tipo_carroceria = 'COMERCIAL' THEN -10\n",
      "                        ELSE 0.0\n",
      "                    END)\n",
      "                ELSE 0.0 \n",
      "            END) as dbg_ajuste_maletero_personal,\n",
      "            -- ✅ NUEVA LÓGICA: Bonus para el perfil \"Coche de Ciudad\"\n",
      "            (\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_perfil = TRUE AND sd.largo < 3300 -- 330 cm = 3300 mm\n",
      "                    THEN 5 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "                +\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_perfil = TRUE AND sd.peso < 950 \n",
      "                    THEN 2 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "            ) as dbg_bonus_coche_ciudad,\n",
      "            -- ✅ NUEVA LÓGICA: Bonus para el perfil \"Coche de Ciudad 2\"\n",
      "            (\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_2_perfil = TRUE AND sd.largo < 3900 -- 390 cm = 3900 mm\n",
      "                    THEN 5 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "                +\n",
      "                (CASE \n",
      "                    WHEN @flag_coche_ciudad_2_perfil = TRUE AND sd.peso < 1000 \n",
      "                    THEN 2 \n",
      "                    ELSE 0.0 \n",
      "                END)\n",
      "            ) as dbg_bonus_coche_ciudad_2,\n",
      "            (CASE WHEN @km_anuales_estimados > 0 AND @km_anuales_estimados < 10000 THEN (CASE WHEN sd.tipo_mecanica IN ('GASOLINA', 'MHEVG', 'HEVG') THEN 8 ELSE 0 END) + (CASE WHEN COALESCE(sd.km_ocasion, 0) > 250000 THEN -5 ELSE 0 END) WHEN @km_anuales_estimados >= 10000 AND @km_anuales_estimados < 30000 THEN (CASE WHEN COALESCE(sd.km_ocasion, 0) > 120000 THEN -10 ELSE 0 END) WHEN @km_anuales_estimados >= 30000 AND @km_anuales_estimados < 60000 THEN (CASE WHEN sd.tipo_mecanica IN ('DIESEL', 'MHEVD', 'HEVD', 'GLP', 'GNV') THEN 10 ELSE 0 END) + (CASE WHEN COALESCE(sd.km_ocasion, 0) > 80000 THEN -10 ELSE 0 END) WHEN @km_anuales_estimados >= 60000 THEN (CASE sd.tipo_mecanica WHEN 'BEV' THEN 5 WHEN 'REEV' THEN 5 WHEN 'HEVD' THEN 10 WHEN 'DIESEL' THEN 10 WHEN 'MHEVD' THEN 10 WHEN 'PHEVD' THEN 3 WHEN 'GLP' THEN 3 WHEN 'GNV' THEN 3 ELSE 0.0 END) + (CASE WHEN COALESCE(sd.km_ocasion, 0) > 20000 THEN -20 ELSE 0 END) ELSE 0.0 END) as dbg_ajuste_km_anuales\n",
      "        FROM ScaledData sd\n",
      "        WHERE 1=1  AND sd.plazas >= @plazas_min AND sd.tipo_mecanica IN UNNEST(@tipos_mecanica) AND (COALESCE(sd.precio_compra_contado, 0) * 0.0140625) <= @cuota_maxima\n",
      "    ),\n",
      "    -- Este CTE suma los componentes para obtener los scores finales\n",
      "    IntermediateScores AS (\n",
      "        SELECT \n",
      "            *,\n",
      "            (\n",
      "                dbg_score_estetica + dbg_score_premium + dbg_score_singular + dbg_score_altura_libre +\n",
      "                dbg_score_batalla + dbg_score_altura_interior + dbg_score_ancho +\n",
      "                dbg_score_devaluacion + dbg_score_maletero_min + dbg_score_maletero_max + dbg_score_largo  +\n",
      "                dbg_score_bajo_peso  + dbg_score_par_remolque + dbg_score_remolque_cf + dbg_score_remolque_sf + dbg_score_menor_superficie +\n",
      "                dbg_score_menor_giro + dbg_score_menor_largo + dbg_score_menor_ancho + dbg_score_menor_alto +\n",
      "                dbg_score_deportividad + dbg_score_menor_rel_peso_pot + dbg_score_potencia + dbg_score_par_deportivo +\n",
      "                dbg_score_autonomia_max + dbg_score_autonomia_2nd + dbg_score_menor_t_carga +\n",
      "                dbg_score_pot_carga_ac + dbg_score_pot_carga_dc + dbg_score_menor_aceleracion + dbg_pen_bev_lifestyle\n",
      "            ) AS puntuacion_base,\n",
      "            (\n",
      "                dbg_pen_km_extremo + dbg_pen_puertas + dbg_pen_low_cost_comodidad + dbg_pen_deportividad_comodidad +\n",
      "                dbg_pen_antiguedad + dbg_ajuste_distintivo + dbg_bonus_ocasion_ambiental + dbg_ajuste_zbe +\n",
      "                dbg_pen_bev_reev_avent_ocas + dbg_pen_phev_avent_ocas + dbg_pen_electrif_avent_extr +\n",
      "                dbg_bonus_car_montana + dbg_bonus_car_comercial + dbg_bonus_car_pasajeros + dbg_pen_car_no_aventura +\n",
      "                dbg_bonus_suv_avent_ocas + dbg_bonus_tt_avent_extr + dbg_bonus_pickup_avent_extr + \n",
      "                dbg_ajuste_objetos_especiales + dbg_bonus_car_confort + dbg_bonus_ocasion_uso_ocas +\n",
      "                dbg_pen_electrif_uso_ocas + dbg_bonus_bev_uso_definido + dbg_pen_phev_uso_intensivo +\n",
      "                dbg_bonus_punto_carga + dbg_ajuste_awd_aventura + dbg_bonus_awd_nieve + dbg_bonus_awd_montana +\n",
      "                dbg_bonus_reductoras + dbg_ajuste_diesel_ciudad + dbg_ajuste_km_anuales + dbg_bonus_seguridad  +\n",
      "                dbg_bonus_fiabilidad + dbg_bonus_durabilidad + dbg_bonus_bajo_consumo + dbg_bonus_coste_uso +\n",
      "                dbg_bonus_coste_mantenimiento + dbg_pen_antiguedad_general + dbg_pen_tamano_no_compacto + dbg_bonus_lifestyle + \n",
      "                dbg_ajuste_deportividad_lifestyle + dbg_ajuste_maletero_personal + dbg_bonus_coche_ciudad + dbg_bonus_coche_ciudad_2\n",
      "            ) AS ajustes_experto\n",
      "        FROM DebugScores\n",
      "    ),\n",
      "    DeduplicatedData AS (\n",
      "        SELECT\n",
      "            *,\n",
      "            (puntuacion_base + ajustes_experto) AS score_total,\n",
      "            ROW_NUMBER() OVER(\n",
      "                PARTITION BY modelo, tipo_mecanica\n",
      "                ORDER BY (puntuacion_base + ajustes_experto) DESC, precio_compra_contado ASC\n",
      "            ) as rn\n",
      "        FROM \n",
      "            IntermediateScores\n",
      "    ),\n",
      "    BrandRankedData AS (\n",
      "        SELECT\n",
      "            *,\n",
      "            ROW_NUMBER() OVER(\n",
      "                PARTITION BY marca\n",
      "                ORDER BY score_total DESC\n",
      "            ) as brand_rank\n",
      "        FROM \n",
      "            DeduplicatedData\n",
      "        WHERE \n",
      "            rn = 1\n",
      "    )\n",
      "    SELECT\n",
      "        -- Columnas principales\n",
      "        nombre, ID, marca, modelo, score_total, puntuacion_base, ajustes_experto, foto,\n",
      "        \n",
      "        -- Desglose completo para depuración\n",
      "        * EXCEPT (nombre, ID, marca, modelo, score_total, puntuacion_base, ajustes_experto, rn, brand_rank)\n",
      "\n",
      "    FROM \n",
      "        BrandRankedData\n",
      "    WHERE \n",
      "        brand_rank <= 2\n",
      "    ORDER BY \n",
      "        score_total DESC\n",
      "    LIMIT @k \n",
      "    \n",
      "-------------------------------------------------\n",
      "\n",
      "--- 📦 Parameters Enviados a BigQuery ---\n",
      "[{'name': 'peso_estetica', 'value': 0.011146989179411032, 'type': 'FLOAT64'}, {'name': 'peso_premium', 'value': 0.05607514201165278, 'type': 'FLOAT64'}, {'name': 'peso_singular', 'value': 0.007993920225103791, 'type': 'FLOAT64'}, {'name': 'peso_altura', 'value': 0.024228974743024313, 'type': 'FLOAT64'}, {'name': 'peso_batalla', 'value': 0.017660870061544116, 'type': 'FLOAT64'}, {'name': 'peso_indice_altura', 'value': 0.01933995902823216, 'type': 'FLOAT64'}, {'name': 'peso_ancho_general_score', 'value': 0.02014278563439438, 'type': 'FLOAT64'}, {'name': 'penalizar_puertas', 'value': False, 'type': 'BOOL'}, {'name': 'peso_rating_durabilidad', 'value': 0.017261497624915988, 'type': 'FLOAT64'}, {'name': 'peso_rating_fiabilidad', 'value': 0.02806017284021492, 'type': 'FLOAT64'}, {'name': 'peso_rating_seguridad', 'value': 0.013559027539499384, 'type': 'FLOAT64'}, {'name': 'peso_rating_impacto_ambiental', 'value': 0.0, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_coste_uso_directo', 'value': 0.02240743445215318, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_coste_mantenimiento_directo', 'value': 0.012231664076710065, 'type': 'FLOAT64'}, {'name': 'peso_rating_tecnologia_conectividad', 'value': 0.004642682691250487, 'type': 'FLOAT64'}, {'name': 'peso_devaluacion', 'value': 0.007637011728092174, 'type': 'FLOAT64'}, {'name': 'peso_maletero_minimo_score', 'value': 0.024385460598356182, 'type': 'FLOAT64'}, {'name': 'peso_maletero_maximo_score', 'value': 0.019697234483283782, 'type': 'FLOAT64'}, {'name': 'peso_largo_vehiculo_score', 'value': 0.013179678770329481, 'type': 'FLOAT64'}, {'name': 'peso_autonomia_vehiculo', 'value': 0.03056879261724704, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_peso', 'value': 0.010917129664064273, 'type': 'FLOAT64'}, {'name': 'peso_fav_bajo_consumo', 'value': 0.014108939393471303, 'type': 'FLOAT64'}, {'name': 'peso_par_motor_remolque_score', 'value': 0.007637011728092174, 'type': 'FLOAT64'}, {'name': 'peso_cap_remolque_cf_score', 'value': 0.008649092613837577, 'type': 'FLOAT64'}, {'name': 'peso_cap_remolque_sf_score', 'value': 0.009353390946738307, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_superficie_planta', 'value': 0.011809754898288548, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_diametro_giro', 'value': 0.2378167275490145, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_largo_garage', 'value': 0.017113960751125548, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_ancho_garage', 'value': 0.13833049785188234, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_alto_garage', 'value': 0.015315472714090426, 'type': 'FLOAT64'}, {'name': 'peso_deportividad_style_score', 'value': 0.007383780358805474, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_rel_peso_potencia_score', 'value': 0.023859850172924583, 'type': 'FLOAT64'}, {'name': 'peso_potencia_maxima_style_score', 'value': 0.017444164062369785, 'type': 'FLOAT64'}, {'name': 'peso_par_motor_style_score', 'value': 0.013512191380413617, 'type': 'FLOAT64'}, {'name': 'peso_autonomia_uso_principal', 'value': 0.0, 'type': 'FLOAT64'}, {'name': 'peso_autonomia_uso_2nd_drive', 'value': 0.013559027539499384, 'type': 'FLOAT64'}, {'name': 'peso_menor_tiempo_carga_min', 'value': 0.021892252150930606, 'type': 'FLOAT64'}, {'name': 'peso_potencia_maxima_carga_AC', 'value': 0.012127562914844934, 'type': 'FLOAT64'}, {'name': 'peso_potencia_maxima_carga_DC', 'value': 0.016043257740984647, 'type': 'FLOAT64'}, {'name': 'peso_fav_menor_aceleracion_score', 'value': 0.02136465047110086, 'type': 'FLOAT64'}, {'name': 'flag_penalizar_low_cost_comodidad', 'value': False, 'type': 'BOOL'}, {'name': 'flag_penalizar_deportividad_comodidad', 'value': False, 'type': 'BOOL'}, {'name': 'flag_penalizar_antiguo_tec', 'value': False, 'type': 'BOOL'}, {'name': 'flag_aplicar_logica_distintivo', 'value': True, 'type': 'BOOL'}, {'name': 'flag_es_municipio_zbe', 'value': True, 'type': 'BOOL'}, {'name': 'flag_pen_bev_reev_avent_ocas', 'value': False, 'type': 'BOOL'}, {'name': 'flag_pen_phev_avent_ocas', 'value': False, 'type': 'BOOL'}, {'name': 'flag_pen_electrif_avent_extr', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_car_montana', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_car_comercial', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_car_pasajeros_pro', 'value': False, 'type': 'BOOL'}, {'name': 'flag_desfav_car_no_aventura', 'value': True, 'type': 'BOOL'}, {'name': 'flag_fav_suv_aventura_ocasional', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_pickup_todoterreno_aventura_extrema', 'value': False, 'type': 'BOOL'}, {'name': 'flag_aplicar_logica_objetos_especiales', 'value': False, 'type': 'BOOL'}, {'name': 'flag_fav_carroceria_confort', 'value': False, 'type': 'BOOL'}, {'name': 'flag_logica_uso_ocasional', 'value': False, 'type': 'BOOL'}, {'name': 'flag_favorecer_bev_uso_definido', 'value': False, 'type': 'BOOL'}, {'name': 'flag_penalizar_phev_uso_intensivo', 'value': False, 'type': 'BOOL'}, {'name': 'flag_favorecer_electrificados_por_punto_carga', 'value': False, 'type': 'BOOL'}, {'name': 'penalizar_awd_ninguna_aventura', 'value': True, 'type': 'BOOL'}, {'name': 'favorecer_awd_aventura_ocasional', 'value': False, 'type': 'BOOL'}, {'name': 'favorecer_awd_aventura_extrema', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_awd_nieve', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_awd_montana', 'value': False, 'type': 'BOOL'}, {'name': 'flag_logica_reductoras_aventura', 'value': False, 'type': 'STRING'}, {'name': 'flag_bonus_awd_clima_adverso', 'value': False, 'type': 'BOOL'}, {'name': 'flag_logica_diesel_ciudad', 'value': 'PENALIZAR', 'type': 'STRING'}, {'name': 'flag_bonus_seguridad_critico', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_seguridad_fuerte', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_fiab_dur_critico', 'value': False, 'type': 'BOOL'}, {'name': 'flag_bonus_fiab_dur_fuerte', 'value': True, 'type': 'BOOL'}, {'name': 'flag_bonus_costes_critico', 'value': False, 'type': 'BOOL'}, {'name': 'km_anuales_estimados', 'value': 5200, 'type': 'INT64'}, {'name': 'flag_penalizar_tamano_no_compacto', 'value': True, 'type': 'BOOL'}, {'name': 'flag_bonus_singularidad_lifestyle', 'value': True, 'type': 'BOOL'}, {'name': 'flag_deportividad_lifestyle', 'value': False, 'type': 'BOOL'}, {'name': 'flag_ajuste_maletero_personal', 'value': False, 'type': 'BOOL'}, {'name': 'flag_coche_ciudad_perfil', 'value': False, 'type': 'BOOL'}, {'name': 'flag_coche_ciudad_2_perfil', 'value': False, 'type': 'BOOL'}, {'name': 'flag_es_conductor_urbano', 'value': True, 'type': 'BOOL'}, {'name': 'k', 'value': 5, 'type': 'INT64'}, {'name': 'plazas_min', 'value': 1, 'type': 'INT64'}, {'name': 'tipos_mecanica', 'value': ['BEV', 'REEV'], 'type': 'ARRAY<STRING>'}, {'name': 'cuota_maxima', 'value': 395.8333333333333, 'type': 'FLOAT64'}]\n",
      "-------------------------------------------------\n",
      "INFO (BQ Logger) ► Log para '1' guardado en BQ.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Listo! Basado en todo lo que hablamos, aquí tienes 4 coche(s) que podrían interesarte:\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"45.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"pago a contado\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"maximo 30 mil euros\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 1\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"economia\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"pagar al contado\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"20.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Listo! Basado en todo lo que hablamos, aquí tienes 4 coche(s) que podrían interesarte:\n",
      "\n",
      "--- 🕵️ Datos Estructurados (lo que procesa el frontend) 🕵️ ---\n",
      "Tipo de Payload: car_recommendation\n",
      "\n",
      "Se encontraron 4 coches en el payload:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>specs</th>\n",
       "      <th>imageUrl</th>\n",
       "      <th>price</th>\n",
       "      <th>score</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. smart fortwo coupé EQ</td>\n",
       "      <td>[BEV, 2022, RWD]</td>\n",
       "      <td>https://assets.adac.de/image/upload/v1/Autodat...</td>\n",
       "      <td>11.500€</td>\n",
       "      <td>77.84 pts</td>\n",
       "      <td>Análisis detallado de la recomendación pendien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Peugeot e-208 136 GT</td>\n",
       "      <td>[BEV, 2021, FWD]</td>\n",
       "      <td>https://assets.adac.de/image/upload/v1/Autodat...</td>\n",
       "      <td>14.900€</td>\n",
       "      <td>70.14 pts</td>\n",
       "      <td>Análisis detallado de la recomendación pendien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. Toyota bZ4X</td>\n",
       "      <td>[BEV, 2023, FWD]</td>\n",
       "      <td>https://a.ccdn.es/cnet/2025/07/14/61026908/204...</td>\n",
       "      <td>25.500€</td>\n",
       "      <td>67.35 pts</td>\n",
       "      <td>Análisis detallado de la recomendación pendien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Tesla Model 3</td>\n",
       "      <td>[BEV, 2019, RWD]</td>\n",
       "      <td>https://assets.adac.de/image/upload/v1/Autodat...</td>\n",
       "      <td>20.900€</td>\n",
       "      <td>62.11 pts</td>\n",
       "      <td>Análisis detallado de la recomendación pendien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name             specs  \\\n",
       "0  1. smart fortwo coupé EQ   [BEV, 2022, RWD]   \n",
       "1    2. Peugeot e-208 136 GT  [BEV, 2021, FWD]   \n",
       "2            3. Toyota bZ4X   [BEV, 2023, FWD]   \n",
       "3          4. Tesla Model 3   [BEV, 2019, RWD]   \n",
       "\n",
       "                                            imageUrl    price      score  \\\n",
       "0  https://assets.adac.de/image/upload/v1/Autodat...  11.500€  77.84 pts   \n",
       "1  https://assets.adac.de/image/upload/v1/Autodat...  14.900€  70.14 pts   \n",
       "2  https://a.ccdn.es/cnet/2025/07/14/61026908/204...  25.500€  67.35 pts   \n",
       "3  https://assets.adac.de/image/upload/v1/Autodat...  20.900€  62.11 pts   \n",
       "\n",
       "                                            analysis  \n",
       "0  Análisis detallado de la recomendación pendien...  \n",
       "1  Análisis detallado de la recomendación pendien...  \n",
       "2  Análisis detallado de la recomendación pendien...  \n",
       "3  Análisis detallado de la recomendación pendien...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "final_message = output['messages'][-1] if output.get('messages') else None\n",
    "final_message.pretty_print()\n",
    "if final_message.additional_kwargs and 'payload' in final_message.additional_kwargs:\n",
    "            print(\"\\n--- 🕵️ Datos Estructurados (lo que procesa el frontend) 🕵️ ---\")\n",
    "            payload = final_message.additional_kwargs['payload']\n",
    "            \n",
    "            # Verificamos si es una recomendación de coches\n",
    "            if payload and payload.get('type') == 'car_recommendation':\n",
    "                print(f\"Tipo de Payload: {payload.get('type')}\")\n",
    "                \n",
    "                coches_recomendados = payload.get('cars', [])\n",
    "                if coches_recomendados:\n",
    "                    print(f\"\\nSe encontraron {len(coches_recomendados)} coches en el payload:\")\n",
    "                    # Usamos Pandas para una visualización bonita de los datos\n",
    "                    df = pd.DataFrame(coches_recomendados)\n",
    "                    display(df)\n",
    "                else:\n",
    "                    print(\"⚠️ El payload no contenía coches.\")\n",
    "            else:\n",
    "                print(\"⚠️ El payload no es del tipo 'car_recommendation' o está vacío.\")\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"contado hasta 9000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"10\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"contado hasta 20.000 euros\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"frecuentemente\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"dos nińos de 14 ańos y mi mujer\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"un adulto y un nińo\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ahorros hasta 45.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"8 años\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "coches_recomendados = output[('coches_recomendados')]\n",
    "\n",
    "df_resultados = pd.DataFrame(coches_recomendados)\n",
    "        \n",
    "#  OPCIÓN 1: Imprimir el DataFrame directamente (Pandas usará las opciones de display)\n",
    "# print(\"\\n--- Vista DataFrame (Pandas Display Options) ---\")\n",
    "# display(df_resultados) # 'display()' suele dar mejor formato en notebooks que 'print(df)'\n",
    "\n",
    "#OPCIÓN 2: Convertir a Markdown (como en tu nodo, pero para consola)\n",
    "print(\"\\n--- Vista Markdown ---\")\n",
    "columnas_deseadas = [ # Lista completa de columnas que seleccionas en BQ\n",
    "            'nombre', 'ID', 'marca', 'modelo', 'score_total',\n",
    "            'puntuacion_base',      # <-- NUEVA\n",
    "            'ajustes_experto',      # <-- NUEVA\n",
    "            'cambio_automatico', 'tipo_mecanica', \n",
    "            'tipo_carroceria', 'indice_altura_interior', 'batalla', 'estetica', \n",
    "            'premium', 'singular', 'altura_libre_suelo', 'ancho', 'traccion', \n",
    "            'reductoras', 'puertas', 'plazas', 'precio_compra_contado',\n",
    "            'fiabilidad', 'durabilidad', 'seguridad', 'comodidad', 'acceso_low_cost', \n",
    "            'deportividad', 'tecnologia', 'devaluacion', 'maletero_minimo', \n",
    "            'maletero_maximo', 'largo', 'autonomia_uso_maxima', \n",
    "            'distintivo_ambiental', 'anos_vehiculo', 'ocasion',\n",
    "            'peso_original_kg', 'consumo_original', 'foto'\n",
    "        ]\n",
    "columnas_existentes = [col for col in columnas_deseadas if col in df_resultados.columns]\n",
    "if columnas_existentes:\n",
    "            if 'score_total' in df_resultados.columns: # Formatear score para legibilidad\n",
    "                df_resultados['score_total'] = df_resultados['score_total'].apply(lambda x: f\"{x:.4f}\" if isinstance(x, float) else x)\n",
    "            print(df_resultados[columnas_existentes].to_markdown(index=False))\n",
    "else:\n",
    "            print(\"WARN: No se encontraron columnas esperadas para mostrar en formato tabla.\")\n",
    "            print(\"Resultados crudos (lista de dicts):\", coches_recomendados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"muestrame mas opciones manteniendo las mismas condiciones\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"cambia el presupuesto a 18.000\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"mismas condiciones pero baja fiabilidad = 3\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complejidad de la Explicación: La plantilla actual es simple (\"Destaca porque [X] ya que [Y], y también por [Z] ya que [W]\"). Puedes hacerla más sofisticada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Vista JSON ---\")\n",
    "tabla_resumen = output[('tabla_resumen_criterios')]\n",
    "print(tabla_resumen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['codigo_postal_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['info_clima_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['preferencias_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['filtros_inferidos'])\n",
    "print('-----------------------')\n",
    "print(output['info_pasajeros'])\n",
    "print('-----------------------')\n",
    "print(output['economia'])\n",
    "print('-----------------------')\n",
    "print(output['pesos'])\n",
    "print('-----------------------')\n",
    "print(\"info_pasajeros:\",output['info_pasajeros'])\n",
    "print('-----------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"flag_penalizar_deportividad_comodidad:\", output['flag_penalizar_deportividad_comodidad'])\n",
    "print('-----------------------')\n",
    "print(\"flag_penalizar_low_cost_comodidad:\", output['flag_penalizar_low_cost_comodidad'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_puertas_bajas:\" , output['penalizar_puertas_bajas'])\n",
    "print('-----------------------')\n",
    "print(\"flag_penalizar_antiguo_por_tecnologia:\" , output['flag_penalizar_antiguo_por_tecnologia'])\n",
    "print('-----------------------')\n",
    "print(\"aplicar_logica_distintivo_ambiental:\" ,  output['aplicar_logica_distintivo_ambiental'])\n",
    "print('-----------------------')\n",
    "print(\"es municipio_zbe: \" , output['es_municipio_zbe'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_electrificados_aventura_extrema: \" , output['penalizar_electrificados_aventura_extrema'])\n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_montana', output['favorecer_carroceria_montana'])\n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_comercial', output['favorecer_carroceria_comercial'])\n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_pasajeros_pro:', output['favorecer_carroceria_pasajeros_pro'])\n",
    "print('-----------------------')\n",
    "print('aplicar_logica_objetos_especiales:', output['aplicar_logica_objetos_especiales'])#OK \n",
    "print('-----------------------')\n",
    "print('favorecer_carroceria_confort:', output['favorecer_carroceria_confort']) #OK\n",
    "print('-----------------------')\n",
    "print('flag_logica_uso_ocasional:' , output['flag_logica_uso_ocasional'])\n",
    "print('-----------------------')\n",
    "print('flag_favorecer_bev_uso_definido:' , output['flag_favorecer_bev_uso_definido'])\n",
    "print('-----------------------')\n",
    "print('flag_penalizar_phev_uso_intensivo:' , output['flag_penalizar_phev_uso_intensivo'])\n",
    "print('-----------------------')\n",
    "print('flag_favorecer_electrificados_por_punto_carga:' , output['flag_favorecer_electrificados_por_punto_carga'])\n",
    "print('-----------------------')\n",
    "print('km_anuales_estimados:' , output['km_anuales_estimados'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('desfavorecer_carroceria_no_aventura:', output['desfavorecer_carroceria_no_aventura']) #Aventura nula y no en montaña desfavorece PICKUP/TODOTERRENO\n",
    "print('-----------------------')\n",
    "print('favorecer_suv_aventura_ocasional:', output['favorecer_suv_aventura_ocasional']) #OK\n",
    "print('-----------------------')\n",
    "print('favorecer_pickup_todoterreno_aventura_extrema:', output['favorecer_pickup_todoterreno_aventura_extrema'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_bev_reev_aventura_ocasional: \" , output['penalizar_bev_reev_aventura_ocasional'])\n",
    "print('-----------------------')\n",
    "print(\"penalizar_phev_aventura_ocasional: \" , output['penalizar_phev_aventura_ocasional'])\n",
    "print('-----------------------')\n",
    "print('penalizar_awd_ninguna_aventura:' , output['penalizar_awd_ninguna_aventura'])\n",
    "print('-----------------------')\n",
    "print('favorecer_awd_aventura_ocasional:' , output['favorecer_awd_aventura_ocasional'])\n",
    "print('-----------------------')\n",
    "print('favorecer_awd_aventura_extrema:' , output['favorecer_awd_aventura_extrema'])\n",
    "print('-----------------------')\n",
    "print('flag_bonus_awd_nieve:' , output['flag_bonus_awd_nieve'])\n",
    "print('-----------------------')\n",
    "print('flag_bonus_awd_montana:' , output['flag_bonus_awd_montana'])\n",
    "print('-----------------------')\n",
    "print('flag_logica_reductoras_aventura:' , output['flag_logica_reductoras_aventura'])\n",
    "print('-----------------------')\n",
    "print('flag_logica_diesel_ciudad:' , output['flag_logica_diesel_ciudad'])\n",
    "print('-----------------------')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Quiero un coche mido 1.93. Peso 80 kg\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si, lo soy\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ambos\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ocasional\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "# print(output['filtros_inferidos']) \n",
    "# print('---------------------------------------------------------------------')\n",
    "# #print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"9\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"5\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"siete\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"9\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"8\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"6\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"8\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"ocasionalmente\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"7\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"10\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "# print(output['filtros_inferidos']) \n",
    "print('---------------------------------------------------------------------')\n",
    "# print(output['economia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si, llevo 2 acompañantes\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos']) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"ninos no\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"la 2\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"pago total al contado maximo de 22.000 euros\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"6.000 ahorrados\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"5 años\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['economia'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config).values\n",
    "for m in state['messages']:\n",
    "    m.pretty_print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revisar las reglas de altura "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hola, dime quien eres?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tienes motos?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar todo el estado acumulado\n",
    "state = graph.get_state(config).values\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Quiero un coche elegante que usaré para trabajar todos los días. Me gustan los diseños llamativos. Mido 1.94\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si electrico estaria perfecto\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"automatico y peso menos de 100kg\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si me apasionan los coches\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Dime quien eres\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tienes motos para recomendarme?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config).values\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "Crear un nuevo nodo en LangGraph llamado analizar_perfil_usuario que:\n",
    "\n",
    "Reciba el mensaje del usuario.\n",
    "\n",
    "Llame a un LLM con un SystemMessage especializado.\n",
    "\n",
    "Devuelva un dict con tres secciones:\n",
    "\n",
    "\"perfil_usuario\" → altura, peso, uso, gustos, etc.\n",
    "\n",
    "\"filtros_inferidos\" → potencia_min, plazas_min, etc.\n",
    "\n",
    "\"mensaje_validacion\"\n",
    "\n",
    "Este resultado lo guardaremos en el state para luego usarlo al llamar buscar_producto_bd()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configurar el cliente de BigQuery\n",
    "client = bigquery.Client(project=\"thecarmentor-mvp2\")\n",
    "\n",
    "@tool\n",
    "def buscar_producto_bd(consulta: str, filtros: dict = None):\n",
    "    \"\"\"\n",
    "    Busca productos en la base de datos utilizando una consulta semántica en BigQuery.\n",
    "    Tu objetivo es proporcionar respuestas precisas para ayudar en la búsqueda en el inventario de coches disponibles.\n",
    "    \n",
    "    Args:\n",
    "        consulta (str): Consulta de texto para buscar productos similares.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: Resultados formateados como una lista de diccionarios con detalles de los productos más relevantes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not consulta.strip():\n",
    "        raise ValueError(\"La consulta no puede estar vacía.\")\n",
    "\n",
    "    # Normalizar la consulta para que coincida con el formato de los embeddings.\n",
    "    consulta_normalizada = normalize_text_sql(consulta)\n",
    "    logging.debug(f\"Consulta normalizada: {consulta_normalizada}\")\n",
    "    \n",
    "    try:\n",
    "        base_query = \"\"\"\n",
    "        WITH resultados_vector AS (\n",
    "            SELECT \n",
    "                base.content AS nombre_coche,\n",
    "                base.mecanica,\n",
    "                base.price,\n",
    "                base.KM,\n",
    "                base.year,\n",
    "                base.image_url,\n",
    "                search_result.distance\n",
    "            FROM VECTOR_SEARCH(\n",
    "                TABLE `web_cars.coches_embeddingsV1`,\n",
    "                'ml_generate_embedding_result',\n",
    "                (SELECT * FROM ML.GENERATE_EMBEDDING(\n",
    "                    MODEL `thecarmentor-mvp2.mymodel.modelembedding`,\n",
    "                    (SELECT @consulta AS content),\n",
    "                    STRUCT(TRUE AS flatten_json_output, 'SEMANTIC_SIMILARITY' AS task_type, 768 AS output_dimensionality)\n",
    "                )),\n",
    "                'ml_generate_embedding_result',\n",
    "                top_k => 6\n",
    "            ) AS search_result\n",
    "        )\n",
    "        SELECT * FROM resultados_vector\n",
    "        WHERE 1=1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Inicializar lista de condiciones y parámetros\n",
    "        query_conditions = []\n",
    "        # Usamos la consulta normalizada para la generación del embedding\n",
    "        query_parameters = [bigquery.ScalarQueryParameter(\"consulta\", \"STRING\", consulta_normalizada)]\n",
    "        \n",
    "        # Agregar condiciones dinámicamente según los filtros proporcionados\n",
    "        if filtros:\n",
    "            if 'precio_max' in filtros:\n",
    "                query_conditions.append(\"price <= @precio_max\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"precio_max\", \"INT64\", filtros[\"precio_max\"]))\n",
    "            if 'precio_min' in filtros:\n",
    "                query_conditions.append(\"price >= @precio_min\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"precio_min\", \"INT64\", filtros[\"precio_min\"]))\n",
    "            if 'year_min' in filtros:\n",
    "                query_conditions.append(\"year >= @year_min\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"year_min\", \"INT64\", filtros[\"year_min\"]))\n",
    "            if 'km_max' in filtros:\n",
    "                query_conditions.append(\"KM <= @km_max\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"km_max\", \"INT64\", filtros[\"km_max\"]))\n",
    "\n",
    "        # Si hay filtros, agregarlos a la consulta\n",
    "        # if query_conditions:\n",
    "        #     base_query += \" AND \" + \" AND \".join(query_conditions)\n",
    "        if query_conditions:\n",
    "            base_query += \" \" + \" AND \".join(query_conditions)\n",
    "\n",
    "\n",
    "        logging.debug(f\"Consulta SQL generada: {base_query}\")\n",
    "        logging.debug(f\"Parámetros de consulta: {query_parameters}\")\n",
    "\n",
    "        # Ejecutar la consulta\n",
    "        query_job = client.query(\n",
    "            base_query, \n",
    "            job_config=bigquery.QueryJobConfig(query_parameters=query_parameters)\n",
    "        )\n",
    "        results = query_job.result().to_dataframe()\n",
    "        # Ordenar los resultados por similitud\n",
    "        if not results.empty:\n",
    "            results = results.sort_values(by=\"distance\", ascending=True)\n",
    "\n",
    "        if results.empty:\n",
    "            return [{\"error\": \"No se encontraron resultados para la consulta y los filtros aplicados.\"}]\n",
    "            \n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"nombre_coche\": row[\"nombre_coche\"],\n",
    "                \"mecanica\": row[\"mecanica\"],\n",
    "                \"precio\": row[\"price\"],\n",
    "                \"kilometros\": row[\"KM\"],\n",
    "                \"año\": row[\"year\"],\n",
    "                \"imagen\": row[\"image_url\"],\n",
    "                \"similitud\": round(row[\"distance\"], 2)\n",
    "            }\n",
    "            for _, row in results.iterrows()\n",
    "        ]\n",
    "        return formatted_results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al ejecutar la consulta: {e}\", exc_info=True)\n",
    "        return [{\"error\": \"No se pudieron encontrar resultados.\"}]\n",
    "\n",
    "# Definir herramientas\n",
    "# tools = [buscar_producto_bd]\n",
    "\n",
    "\n",
    "\n",
    "# Actualizar lista de herramientas\n",
    "tools = [buscar_producto_bd]\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys_msg = SystemMessage(content=\"\"\"Eres Mentor, un util y experto en la busqueda de coches.\n",
    "INSTRUCCIONES IMPORTANTES:\n",
    "**Antes de hacer una búsqueda en la base de datos, analiza la consulta y extrae solo la información clave.**  \n",
    "   - Si el usuario menciona un coche, filtra la consulta para obtener solo **la marca, modelo, versión, tipo de motorización y año**.\n",
    "   - **No incluyas frases completas del usuario como búsqueda.**  \n",
    "   - **No pases palabras como \"quiero\", \"busco\", \"auto\", \"coche\", \"modelo\", \"año\" si no son parte del nombre oficial del coche.**\n",
    "   - **Ejemplo:**  \n",
    "     - Entrada: `\"quiero coche bmw serie 1 120d hibrido año 2024\"`  \n",
    "     - **Consulta que debes generar:** `\"bmw serie 1 120d hibrido 2024\"`\n",
    "\n",
    "**Definiendo Preferencias**\n",
    "   - Para dar recomendaciones acertadas, puedes pedir al usuario que proporcione detalles sobre lo que busca:\n",
    "     • ¿Tienes una **marca** preferida?\n",
    "     • ¿Cuál es tu **presupuesto máximo**? (Opcional)\n",
    "     • ¿Te importa el **kilometraje máximo**? (Opcional)\n",
    "     • ¿Qué **años de antigüedad** son aceptables? (Opcional)\n",
    "\n",
    "**Presentación de Resultados**\n",
    "    - Aplica los filtros pero muestra también alguna alternativa fuera de los filtros si es muy relevante\n",
    "    Usa este formato para cada coche encontrado: \n",
    "    ### [Modelo]\n",
    "    ![Imagen del vehículo]([url_imagen])\n",
    "     - **Precio:** [precio]€\n",
    "     - **Kilómetros:** [km] km\n",
    "     - **Mecánica:** [tipo]\n",
    "     - **Año:** [year]\n",
    "     - **Similitud con tu búsqueda:** [score]\n",
    " \n",
    "** Ajustes**\n",
    "   - Si no encuentras lo que buscas, dime si quieres:\n",
    "   - Aumentar el **presupuesto** para ver modelos más recientes.\n",
    "   - Ampliar el **kilometraje permitido** para más opciones.\n",
    "   - Incluir **otros años** para expandir la búsqueda.\n",
    "   \n",
    "**Información Adicional**\n",
    "   -usa la herramienta `buscar_info_adicional` para obtener información actualizada sobre un modelo específico de coche.\n",
    "   - **Ejemplo:** `buscar_info_adicional(\"que caracteristicas tiene el BMW 320d 2019\")`\n",
    "\"\"\")\n",
    "# - También puedo **comparar dos coches** si tienes modelos específicos en mente.\n",
    "def assistant(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Función principal del asistente invocando una búsqueda.\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "#    user_input = state[\"messages\"][-1].content  # Último mensaje del usuario\n",
    "# if detect_comparison_intent(user_input):\n",
    "#         car1, car2 = extract_car_models_llm(user_input)\n",
    "#         if car1 and car2:\n",
    "#             car1_data, car2_data = obtener_datos_comparacion(car1, car2)\n",
    "#             return {\"messages\": [comparar_coches_llm(car1_data, car2_data)]}\n",
    "#         else:\n",
    "#             return {\"messages\": [\"No pude identificar claramente los coches a comparar. ¿Podrías mencionarlos nuevamente?\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "# Graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "graph.add_node(\"assistant\", assistant)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "graph.add_edge(START, \"assistant\")\n",
    "graph.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    lambda state: logging.debug(f\"tools_condition evalúa: {tools_condition(state)}\") or tools_condition(state)\n",
    ")\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "#     tools_condition,\n",
    "# )\n",
    "graph.add_edge(\"tools\", \"assistant\")\n",
    "graph = graph.compile(checkpointer=memory)\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"quiero coche bmw serie 1 120d hibrido año 2024\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"kilometraje 50.000 y presupuesto no importa, muestrame todas las opciones\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"podrias darme las caracteristicas del bmw serie 1 118i 2024 diesel\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"si, dame las caracteristicas del El 118i a gasolina\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"quiero un coche kia sportage a gasolina, puede ser año 2011 a 2020 y no importa el kilometraje\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"maximo 25.000 euros\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"Mentor quiero un coche familiar, me podrias recomendar alguno?\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"segun tu conocimiento que me recomiendas?\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"pues SUV estaria bien y presupuesto hasta  12.000\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"diesel o gasolina esta bien\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"vale maximo 10 años\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_env (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
