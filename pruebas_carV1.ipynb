{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# LLM base\n",
    "llm = init_chat_model(\"openai:gpt-4o-mini\", temperature=0.2)\n",
    "print(llm.invoke(\"Hola, ¿quién eres?\").content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.llm import llm_validacion\n",
    "\n",
    "print(llm_validacion.invoke(\"Hola, ¿quién eres?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.llm import llm_validacion , prompt_validacion\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "respuesta = llm_validacion.invoke([\n",
    "    SystemMessage(content=prompt_validacion),\n",
    "    HumanMessage(content=\"Hola, ¿quién eres?\")\n",
    "])\n",
    "print(respuesta.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.llm import prompt_validacion\n",
    "\n",
    "print(prompt_validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.conversion import get_enum_names\n",
    "from utils.enums import TipoCarroceria, TipoMecanica\n",
    "\n",
    "#get_enum_names([TipoCarroceria.COMERCIAL, TipoCarroceria.PICKUP])\n",
    "\n",
    "#Dos maneras de obtener los nombres de las clases enums\n",
    "print(\"totalidad tipo carroceria:\" , list(TipoCarroceria))\n",
    "print(\"totalidad mecanica\" , get_enum_names(list(TipoMecanica)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creacion del Grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "# Importar el constructor del grafo\n",
    "from IPython.display import Image, display\n",
    "from graph.perfil.builder import build_perfil_graph\n",
    "# Construir el grafo\n",
    "graph = build_perfil_graph()\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ► respuesta.raw: preferencias_usuario=PerfilUsuario(altura_mayor_190=None, peso_mayor_100=None, uso_profesional=None, valora_estetica=None, solo_electricos=None, cambio_automatico=None, apasionado_motor=None, aventura=None) filtros_inferidos=FiltrosInferidos(batalla_min=None, indice_altura_interior_min=None, estetica_min=None, tipo_mecanica=None, premium_min=None, singular_min=None) mensaje_validacion='¿Qué tipo de coche prefieres: compacto, SUV, eléctrico? Y, ¿tienes alguna preferencia en cuanto a la estética o el tipo de transmisión?'\n",
      "DEBUG ► response.preferencias_usuario: altura_mayor_190=None peso_mayor_100=None uso_profesional=None valora_estetica=None solo_electricos=None cambio_automatico=None apasionado_motor=None aventura=None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Para ayudarte mejor, me gustaría saber si valoras la estética del coche. Además, ¿prefieres que solo busquemos vehículos eléctricos o no es un requisito?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"oye busco un coche para la ciudad\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ► respuesta.raw: preferencias_usuario=PerfilUsuario(altura_mayor_190=None, peso_mayor_100=None, uso_profesional=None, valora_estetica='sí', solo_electricos='sí', cambio_automatico=None, apasionado_motor=None, aventura=None) filtros_inferidos=FiltrosInferidos(batalla_min=None, indice_altura_interior_min=None, estetica_min=7.0, tipo_mecanica=[<TipoMecanica.BEV: 'BEV'>], premium_min=None, singular_min=None) mensaje_validacion='¿Me puedes confirmar si prefieres vehículos con cambio automático? Y, ¿tienes alguna preferencia en cuanto a la aventura que buscas con el coche?'\n",
      "DEBUG ► response.preferencias_usuario: altura_mayor_190=None peso_mayor_100=None uso_profesional=None valora_estetica='sí' solo_electricos='sí' cambio_automatico=None apasionado_motor=None aventura=None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Perfecto, ya tenemos claro que valoras la estética y buscas un coche eléctrico con cambio automático. Ahora, ¿usarás el coche principalmente para trabajo o para uso personal? Y, para conocer tu espíritu aventurero, ¿cuál describe mejor tu estilo? \n",
      "\n",
      "1) Solo asfalto (ninguna)  \n",
      "2) Salidas off-road de vez en cuando (ocasional)  \n",
      "3) Aventurero extremo en terrenos difíciles (extrema)\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si valoro la estetica y quiero que sea electrico esta bien \")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ► respuesta.raw: preferencias_usuario=PerfilUsuario(altura_mayor_190=None, peso_mayor_100=None, uso_profesional='sí', valora_estetica='sí', solo_electricos='sí', cambio_automatico=None, apasionado_motor=None, aventura='extrema') filtros_inferidos=FiltrosInferidos(batalla_min=None, indice_altura_interior_min=None, estetica_min=7.0, tipo_mecanica=[<TipoMecanica.BEV: 'BEV'>], premium_min=None, singular_min=None) mensaje_validacion='¿Prefieres que busquemos solo vehículos con cambio automático? Y, ¿te consideras apasionado del motor?'\n",
      "DEBUG ► response.preferencias_usuario: altura_mayor_190=None peso_mayor_100=None uso_profesional='sí' valora_estetica='sí' solo_electricos='sí' cambio_automatico=None apasionado_motor=None aventura='extrema'\n",
      "Query partes: ['eléctrico', 'diseño', 'profesional', 'profesional', 'entregas', 'transporte', 'carga', 'comercio', 'aventura extrema', 'off-road', 'terrenos difíciles', 'extrema', 'tracción 4x4']\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Gracias por la información. Solo necesito un par de detalles más: ¿mides más de 1.90 m? Y, ¿pesas más de 100 kg? Esto me ayudará a encontrar opciones que se adapten perfectamente a ti.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"lo usare para trabajo y con la 3 aventurero\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'altura_mayor_190': None, 'peso_mayor_100': None, 'uso_profesional': 'sí', 'valora_estetica': 'sí', 'solo_electricos': 'sí', 'cambio_automatico': 'si', 'apasionado_motor': None, 'aventura': 'extrema'}\n",
      "-----------------------\n",
      "{'batalla_min': None, 'indice_altura_interior_min': None, 'estetica_min': 5.0, 'tipo_mecanica': ['BEV'], 'premium_min': 1.0, 'singular_min': 1.0, 'tipo_carroceria': ['TODOTERRENO', 'SUV', 'PICKUP', 'DESCAPOTABLE']}\n"
     ]
    }
   ],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ► respuesta.raw: preferencias_usuario=PerfilUsuario(altura_mayor_190='sí', peso_mayor_100='no', uso_profesional='sí', valora_estetica='sí', solo_electricos='sí', cambio_automatico='sí', apasionado_motor='null', aventura='extrema') filtros_inferidos=FiltrosInferidos(batalla_min=2800, indice_altura_interior_min=5000, estetica_min=7.0, tipo_mecanica=[<TipoMecanica.BEV: 'BEV'>], premium_min=1.0, singular_min=1.0) mensaje_validacion='¿Te consideras apasionado del motor?'\n",
      "DEBUG ► response.preferencias_usuario: altura_mayor_190='sí' peso_mayor_100='no' uso_profesional='sí' valora_estetica='sí' solo_electricos='sí' cambio_automatico='sí' apasionado_motor='null' aventura='extrema'\n",
      "Query partes: ['eléctrico', 'diseño', 'profesional', 'profesional', 'entregas', 'transporte', 'carga', 'comercio', 'aventura extrema', 'off-road', 'terrenos difíciles', 'extrema', 'tracción 4x4']\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "¡Gracias por la información! Solo me queda una última pregunta: ¿te consideras apasionado del motor? Esto me ayudará a encontrar opciones que realmente te entusiasmen.\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"mido1.92 y peso 80kg\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'altura_mayor_190': 'sí', 'peso_mayor_100': 'no', 'uso_profesional': 'sí', 'valora_estetica': 'sí', 'solo_electricos': 'sí', 'cambio_automatico': 'sí', 'apasionado_motor': 'null', 'aventura': 'extrema'}\n",
      "-----------------------\n",
      "{'batalla_min': 2800, 'indice_altura_interior_min': 5000, 'estetica_min': 5.0, 'tipo_mecanica': ['BEV'], 'premium_min': 1.0, 'singular_min': 1.0, 'tipo_carroceria': ['TODOTERRENO', 'SUV', 'PICKUP', 'DESCAPOTABLE']}\n"
     ]
    }
   ],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG ► respuesta.raw: preferencias_usuario=PerfilUsuario(altura_mayor_190='sí', peso_mayor_100='no', uso_profesional='sí', valora_estetica='sí', solo_electricos='sí', cambio_automatico='sí', apasionado_motor='sí', aventura='extrema') filtros_inferidos=FiltrosInferidos(batalla_min=2800, indice_altura_interior_min=5000, estetica_min=7.0, tipo_mecanica=[<TipoMecanica.BEV: 'BEV'>], premium_min=1.0, singular_min=1.0) mensaje_validacion='Con toda esta información, puedo buscar opciones ideales para ti. ¿Te gustaría que incluyera algún otro criterio o preferencia?'\n",
      "DEBUG ► response.preferencias_usuario: altura_mayor_190='sí' peso_mayor_100='no' uso_profesional='sí' valora_estetica='sí' solo_electricos='sí' cambio_automatico='sí' apasionado_motor='sí' aventura='extrema'\n",
      "Query partes: ['eléctrico', 'diseño', 'profesional', 'profesional', 'entregas', 'transporte', 'carga', 'comercio', 'aventura extrema', 'off-road', 'terrenos difíciles', 'extrema', 'tracción 4x4']\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "✅ He entendido lo siguiente sobre tus preferencias:     \n",
      "\n",
      "| Preferencia             | Valor                      |\n",
      "|-------------------------|----------------------------|\n",
      "| Tipo de coche           | Eléctrico \n",
      "| Uso                     | Uso profesional           \n",
      "| Altura                  | Mayor a 1.90 m       \n",
      "| Peso                    | Menor a 100 kg         \n",
      "| Estética                | Importante                                                                                                       \n",
      "| Cambio                  | Automático                  \n",
      "| Apasionado del motor    | Sí                               \n",
      "| Aventura con tu vehiculo| Extrema             \n",
      "\n",
      "\n",
      "🎯 Filtros técnicos inferidos:\n",
      "\n",
      "| Filtro técnico        | Valor                            |\n",
      "|-----------------------|----------------------------------|\n",
      "| Tipo de mecánica     | BEV\n",
      "| Tipo de carrocería   | TODOTERRENO, SUV, PICKUP, DESCAPOTABLE\n",
      "| Estética mínima      | 5.0\n",
      "| Premium mínima       | 5.0\n",
      "| Singularidad mínima  | 5.0\n",
      "\n",
      "¿Hay algo que quieras ajustar o añadir?\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si soy un apasionado del motor\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'altura_mayor_190': 'sí', 'peso_mayor_100': 'no', 'uso_profesional': 'sí', 'valora_estetica': 'sí', 'solo_electricos': 'sí', 'cambio_automatico': 'sí', 'apasionado_motor': 'sí', 'aventura': 'extrema'}\n",
      "-----------------------\n",
      "{'batalla_min': 2800, 'indice_altura_interior_min': 5000, 'estetica_min': 5.0, 'tipo_mecanica': [<TipoMecanica.BEV: 'BEV'>], 'premium_min': 5.0, 'singular_min': 5.0, 'tipo_carroceria': ['TODOTERRENO', 'SUV', 'PICKUP', 'DESCAPOTABLE']}\n",
      "-----------------------\n",
      "{'estetica': 0.14285714285714285, 'premium': 0.14285714285714285, 'singular': 0.14285714285714285, 'altura_libre_suelo': 0.05714285714285714, 'traccion': 0.2857142857142857, 'reductoras': 0.22857142857142856}\n"
     ]
    }
   ],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['filtros_inferidos'])\n",
    "print('-----------------------')\n",
    "print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "#config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si soy apasionado del motor\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"la 3\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(output['preferencias_usuario'])\n",
    "print('-----------------------')\n",
    "print(output['filtros_inferidos'])\n",
    "# print('-----------------------')\n",
    "# print(output['pesos'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OJO corregir: reductoras es un boolean por lo cual se debe enregar al otro agente de esa manera. altura como se esta gestionando, en la bd es alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config).values\n",
    "print(state[\"mensaje_validacion\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Quiero un coche mido 1.93. Peso 80 kg\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"no, electrico no y con la 3, circular en condiciones extremas\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos']) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si para trabajo y puede ser tanto automatico como manual\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos']) \n",
    "print('---------------------------------------------------------------------')\n",
    "#print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si soy apasionado del motor y no me importa mucho la estetica\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "input_message = HumanMessage(content=\"vale manual entonces\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['pesos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config).values\n",
    "for m in state['messages']:\n",
    "    m.pretty_print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hola, dime quien eres?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tienes motos?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultar todo el estado acumulado\n",
    "state = graph.get_state(config).values\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Quiero un coche elegante que usaré para trabajar todos los días. Me gustan los diseños llamativos. Mido 1.94\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si electrico estaria perfecto\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"automatico y peso menos de 100kg\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si me apasionan los coches\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output['preferencias_usuario'])\n",
    "print('---------------------------------------------------------------------')\n",
    "print(output['filtros_inferidos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"si\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"Dime quien eres\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"5\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"tienes motos para recomendarme?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config).values\n",
    "for m in state[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo\n",
    "Crear un nuevo nodo en LangGraph llamado analizar_perfil_usuario que:\n",
    "\n",
    "Reciba el mensaje del usuario.\n",
    "\n",
    "Llame a un LLM con un SystemMessage especializado.\n",
    "\n",
    "Devuelva un dict con tres secciones:\n",
    "\n",
    "\"perfil_usuario\" → altura, peso, uso, gustos, etc.\n",
    "\n",
    "\"filtros_inferidos\" → potencia_min, plazas_min, etc.\n",
    "\n",
    "\"mensaje_validacion\"\n",
    "\n",
    "Este resultado lo guardaremos en el state para luego usarlo al llamar buscar_producto_bd()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configurar el cliente de BigQuery\n",
    "client = bigquery.Client(project=\"thecarmentor-mvp2\")\n",
    "\n",
    "@tool\n",
    "def buscar_producto_bd(consulta: str, filtros: dict = None):\n",
    "    \"\"\"\n",
    "    Busca productos en la base de datos utilizando una consulta semántica en BigQuery.\n",
    "    Tu objetivo es proporcionar respuestas precisas para ayudar en la búsqueda en el inventario de coches disponibles.\n",
    "    \n",
    "    Args:\n",
    "        consulta (str): Consulta de texto para buscar productos similares.\n",
    "    \n",
    "    Returns:\n",
    "        list[dict]: Resultados formateados como una lista de diccionarios con detalles de los productos más relevantes.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not consulta.strip():\n",
    "        raise ValueError(\"La consulta no puede estar vacía.\")\n",
    "\n",
    "    # Normalizar la consulta para que coincida con el formato de los embeddings.\n",
    "    consulta_normalizada = normalize_text_sql(consulta)\n",
    "    logging.debug(f\"Consulta normalizada: {consulta_normalizada}\")\n",
    "    \n",
    "    try:\n",
    "        base_query = \"\"\"\n",
    "        WITH resultados_vector AS (\n",
    "            SELECT \n",
    "                base.content AS nombre_coche,\n",
    "                base.mecanica,\n",
    "                base.price,\n",
    "                base.KM,\n",
    "                base.year,\n",
    "                base.image_url,\n",
    "                search_result.distance\n",
    "            FROM VECTOR_SEARCH(\n",
    "                TABLE `web_cars.coches_embeddingsV1`,\n",
    "                'ml_generate_embedding_result',\n",
    "                (SELECT * FROM ML.GENERATE_EMBEDDING(\n",
    "                    MODEL `thecarmentor-mvp2.mymodel.modelembedding`,\n",
    "                    (SELECT @consulta AS content),\n",
    "                    STRUCT(TRUE AS flatten_json_output, 'SEMANTIC_SIMILARITY' AS task_type, 768 AS output_dimensionality)\n",
    "                )),\n",
    "                'ml_generate_embedding_result',\n",
    "                top_k => 6\n",
    "            ) AS search_result\n",
    "        )\n",
    "        SELECT * FROM resultados_vector\n",
    "        WHERE 1=1\n",
    "        \"\"\"\n",
    "        \n",
    "        # Inicializar lista de condiciones y parámetros\n",
    "        query_conditions = []\n",
    "        # Usamos la consulta normalizada para la generación del embedding\n",
    "        query_parameters = [bigquery.ScalarQueryParameter(\"consulta\", \"STRING\", consulta_normalizada)]\n",
    "        \n",
    "        # Agregar condiciones dinámicamente según los filtros proporcionados\n",
    "        if filtros:\n",
    "            if 'precio_max' in filtros:\n",
    "                query_conditions.append(\"price <= @precio_max\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"precio_max\", \"INT64\", filtros[\"precio_max\"]))\n",
    "            if 'precio_min' in filtros:\n",
    "                query_conditions.append(\"price >= @precio_min\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"precio_min\", \"INT64\", filtros[\"precio_min\"]))\n",
    "            if 'year_min' in filtros:\n",
    "                query_conditions.append(\"year >= @year_min\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"year_min\", \"INT64\", filtros[\"year_min\"]))\n",
    "            if 'km_max' in filtros:\n",
    "                query_conditions.append(\"KM <= @km_max\")\n",
    "                query_parameters.append(bigquery.ScalarQueryParameter(\"km_max\", \"INT64\", filtros[\"km_max\"]))\n",
    "\n",
    "        # Si hay filtros, agregarlos a la consulta\n",
    "        # if query_conditions:\n",
    "        #     base_query += \" AND \" + \" AND \".join(query_conditions)\n",
    "        if query_conditions:\n",
    "            base_query += \" \" + \" AND \".join(query_conditions)\n",
    "\n",
    "\n",
    "        logging.debug(f\"Consulta SQL generada: {base_query}\")\n",
    "        logging.debug(f\"Parámetros de consulta: {query_parameters}\")\n",
    "\n",
    "        # Ejecutar la consulta\n",
    "        query_job = client.query(\n",
    "            base_query, \n",
    "            job_config=bigquery.QueryJobConfig(query_parameters=query_parameters)\n",
    "        )\n",
    "        results = query_job.result().to_dataframe()\n",
    "        # Ordenar los resultados por similitud\n",
    "        if not results.empty:\n",
    "            results = results.sort_values(by=\"distance\", ascending=True)\n",
    "\n",
    "        if results.empty:\n",
    "            return [{\"error\": \"No se encontraron resultados para la consulta y los filtros aplicados.\"}]\n",
    "            \n",
    "        formatted_results = [\n",
    "            {\n",
    "                \"nombre_coche\": row[\"nombre_coche\"],\n",
    "                \"mecanica\": row[\"mecanica\"],\n",
    "                \"precio\": row[\"price\"],\n",
    "                \"kilometros\": row[\"KM\"],\n",
    "                \"año\": row[\"year\"],\n",
    "                \"imagen\": row[\"image_url\"],\n",
    "                \"similitud\": round(row[\"distance\"], 2)\n",
    "            }\n",
    "            for _, row in results.iterrows()\n",
    "        ]\n",
    "        return formatted_results\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error al ejecutar la consulta: {e}\", exc_info=True)\n",
    "        return [{\"error\": \"No se pudieron encontrar resultados.\"}]\n",
    "\n",
    "# Definir herramientas\n",
    "# tools = [buscar_producto_bd]\n",
    "\n",
    "\n",
    "\n",
    "# Actualizar lista de herramientas\n",
    "tools = [buscar_producto_bd]\n",
    "llm_with_tools = llm.bind_tools(tools, parallel_tool_calls=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys_msg = SystemMessage(content=\"\"\"Eres Mentor, un util y experto en la busqueda de coches.\n",
    "INSTRUCCIONES IMPORTANTES:\n",
    "**Antes de hacer una búsqueda en la base de datos, analiza la consulta y extrae solo la información clave.**  \n",
    "   - Si el usuario menciona un coche, filtra la consulta para obtener solo **la marca, modelo, versión, tipo de motorización y año**.\n",
    "   - **No incluyas frases completas del usuario como búsqueda.**  \n",
    "   - **No pases palabras como \"quiero\", \"busco\", \"auto\", \"coche\", \"modelo\", \"año\" si no son parte del nombre oficial del coche.**\n",
    "   - **Ejemplo:**  \n",
    "     - Entrada: `\"quiero coche bmw serie 1 120d hibrido año 2024\"`  \n",
    "     - **Consulta que debes generar:** `\"bmw serie 1 120d hibrido 2024\"`\n",
    "\n",
    "**Definiendo Preferencias**\n",
    "   - Para dar recomendaciones acertadas, puedes pedir al usuario que proporcione detalles sobre lo que busca:\n",
    "     • ¿Tienes una **marca** preferida?\n",
    "     • ¿Cuál es tu **presupuesto máximo**? (Opcional)\n",
    "     • ¿Te importa el **kilometraje máximo**? (Opcional)\n",
    "     • ¿Qué **años de antigüedad** son aceptables? (Opcional)\n",
    "\n",
    "**Presentación de Resultados**\n",
    "    - Aplica los filtros pero muestra también alguna alternativa fuera de los filtros si es muy relevante\n",
    "    Usa este formato para cada coche encontrado: \n",
    "    ### [Modelo]\n",
    "    ![Imagen del vehículo]([url_imagen])\n",
    "     - **Precio:** [precio]€\n",
    "     - **Kilómetros:** [km] km\n",
    "     - **Mecánica:** [tipo]\n",
    "     - **Año:** [year]\n",
    "     - **Similitud con tu búsqueda:** [score]\n",
    " \n",
    "** Ajustes**\n",
    "   - Si no encuentras lo que buscas, dime si quieres:\n",
    "   - Aumentar el **presupuesto** para ver modelos más recientes.\n",
    "   - Ampliar el **kilometraje permitido** para más opciones.\n",
    "   - Incluir **otros años** para expandir la búsqueda.\n",
    "   \n",
    "**Información Adicional**\n",
    "   -usa la herramienta `buscar_info_adicional` para obtener información actualizada sobre un modelo específico de coche.\n",
    "   - **Ejemplo:** `buscar_info_adicional(\"que caracteristicas tiene el BMW 320d 2019\")`\n",
    "\"\"\")\n",
    "# - También puedo **comparar dos coches** si tienes modelos específicos en mente.\n",
    "def assistant(state: MessagesState):\n",
    "    \"\"\"\n",
    "    Función principal del asistente invocando una búsqueda.\n",
    "    \"\"\"\n",
    "    return {\"messages\": [llm_with_tools.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "\n",
    "#    user_input = state[\"messages\"][-1].content  # Último mensaje del usuario\n",
    "# if detect_comparison_intent(user_input):\n",
    "#         car1, car2 = extract_car_models_llm(user_input)\n",
    "#         if car1 and car2:\n",
    "#             car1_data, car2_data = obtener_datos_comparacion(car1, car2)\n",
    "#             return {\"messages\": [comparar_coches_llm(car1_data, car2_data)]}\n",
    "#         else:\n",
    "#             return {\"messages\": [\"No pude identificar claramente los coches a comparar. ¿Podrías mencionarlos nuevamente?\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "\n",
    "# Graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# Define nodes: these do the work\n",
    "graph.add_node(\"assistant\", assistant)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Define edges: these determine how the control flow moves\n",
    "graph.add_edge(START, \"assistant\")\n",
    "graph.add_conditional_edges(\n",
    "    \"assistant\",\n",
    "    lambda state: logging.debug(f\"tools_condition evalúa: {tools_condition(state)}\") or tools_condition(state)\n",
    ")\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "#     tools_condition,\n",
    "# )\n",
    "graph.add_edge(\"tools\", \"assistant\")\n",
    "graph = graph.compile(checkpointer=memory)\n",
    "# Show\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"quiero coche bmw serie 1 120d hibrido año 2024\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"kilometraje 50.000 y presupuesto no importa, muestrame todas las opciones\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"podrias darme las caracteristicas del bmw serie 1 118i 2024 diesel\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"si, dame las caracteristicas del El 118i a gasolina\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"quiero un coche kia sportage a gasolina, puede ser año 2011 a 2020 y no importa el kilometraje\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation\n",
    "config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"maximo 25.000 euros\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"Mentor quiero un coche familiar, me podrias recomendar alguno?\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"segun tu conocimiento que me recomiendas?\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"pues SUV estaria bien y presupuesto hasta  12.000\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"diesel o gasolina esta bien\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start conversation, again\n",
    "config = {\"configurable\": {\"thread_id\": \"3\"}}\n",
    "\n",
    "# Specify an input\n",
    "input_message = HumanMessage(content=\"vale maximo 10 años\")\n",
    "output = graph.invoke({\"messages\": input_message}, config)\n",
    "\n",
    "# Mostrar los mensajes resultantes del primer paso\n",
    "for m in output[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
